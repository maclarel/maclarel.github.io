+++
title = "NorthSec 2025, or How I Learned to Steal a Cruise Ship"
tags = [
    "security",
    "nsec",
    "red team"
]
date = "2025-05-20"
toc = true
+++

# Overview

Another year, and another NorthSec in the books. 

Like every year prior, I continue to strongly recommend this conference to anyone and everyone in the cybersecurity space. NorthSec (nSec) is somewhat unique, in my experience, in that it caters to nearly all skill levels and strives to make itself as accessible to students (with reduced prices, too!) as to industry veterans.

Beyond the accessibility, for an event with two stages they manage every year to have a huge variety of topics covered. Even if you walk into the wrong talk, it's rare to not get nerd-sniped by something in it... This year I accidentally walked in on a talk about zero-knowledge proofs as it relates to identity and I somehow wound up with pages of notes for a topic I otherwise hadn't planned to attend.

While I submitted to the CFP again this year (and didn't make it in), I was graciously given the opportunity to host the machine learning block and Q&A panel toward the tail end of the event. Big thank you to [Hugo](https://www.linkedin.com/in/hugo-genesse-4a0bb079/) and the rest of the NorthSec crew for the invite even though I was going to be there anyway!

As always, the CTF was stellar. More on that later.

# Highlights

While there were specific talks that are worth highlighting, I encourage anyone reading this to flip through the [recorded live streams](https://www.youtube.com/watch?v=RT_-nSejLm0&list=PLuUtcRxSUZUrW9scJZqhbiuTBwZBJ-Qic) as everything - including the workshops - are recorded and made available for free.

## Snake Oil

[HD Moore](https://www.linkedin.com/in/hdmoore/) gave this years opening keynote, going into detail about the often overlapping, lagging, and in some cases non-existent state of vulnerability scanningtooling across the market. 

While I had already generally considered much of the tooling in this space to be snake oil after years of receiving the questionable report output presented as "legitimate findings of critical vulnerabilities" I was surprised to get a clearer understanding of just how bad this space actually is...

Two things outlined in this talk really stood out to me:
- Under the covers, a lot of the tooling out there shares the same common base - [Nuclei](https://projectdiscovery.io/nuclei).
- Most, if not all, proprietary tools in this space directly prevent benchmarking in their EULA.

While I'm a big fan of Nuclei, I had not realized that it had as many commercial applications as it does. Obviously this makes a lot of sense when considering how it works and how easy it is to extend, but it was still surprising.

The benchmarking scenario was a complete unknown to me. I've always had this question in the back of my mind as to why people continue to buy these products (outside of the industry-captured regulatory standards), but now I've got a better appreciation as to how they all get away with the lack of quality - they're all bad!

## Living off the Pipeline

Folowing the keynote, [Francois Proulx](https://www.linkedin.com/in/francoisp/) delivered an exciting overview of the state of supply chain security focusing on GitHub Actions.

Francois and his team have been working, I believe for years now, on [Poutine](https://boostsecurity.io/blog/unveiling-poutine-an-open-source-build-pipelines-security-scanner) and this gave us some further insight as to how it works and how they're able to detect supply chain attacks _using almost exclusively metadata from GitHub's Events API_.

Extremely impressive work, and I hope that further progress can be made in this space :eyes:

## Ethics of AI Red Teaming

The next highlight for me was delivered by the Ninja-Philosopher multi-classer [Jeremy Miller](https://www.linkedin.com/in/jeremy-miller-b6816987/) who discussed the mental shift that comes with red teaming AI models.

This talk, in addition to just being extremely engaging, outlined two areas that I greatly appreciated now focusing heavily in this area:
- What enables most security engineers to do their jobs isn't knowledge - it's the ability to rapidly gain knowledge. Curiosity and rigor are the main traits that drive success. As long as knowledge can be gained, problems and solutions can be found.
- "Red Teaming" AI brings a very non-traditional spin to engagements, as we're no longer specifically concerned about increased access, persistence, DoS, etc but also, perhaps equally so, on the _safety_ of the tooling. 

This one is absolutely worth a listen. Jeremy is a talented speaker, and this was a thought provoking talk.

## Stolen laptops

This talk blew my mind. You should [watch it](https://www.youtube.com/live/J4rGZBxUzYo?si=Jkgh1RMVq_S-YmjG&t=27342) and enjoy the rapid-fire dismantling of security protections that [Pierre-Nicolas Allard-Coutu](https://www.linkedin.com/in/pierre-nicolas-allard-coutu/) demonstrated.

While certain companies are touting the immense security benefits of TPM and the technologies it supports (e.g. BitLocker), this talk discussed _and demonstrated_ that physical access to a device made bypassing these largely trivial if you know what you were doing.

It's unclear how this ports over to the approaches that Apple uses (presumably their implementations are significantly stronger given everything we've seen in the news), but this certainly inspired me to learn more in the space.

I want to be clear that these are only _some_ of the highlights for me - there's simply too much to reasonably cover in a blog post. The recordings are worth the watch!

# CTF

This year's CTF knocked it out of the park. Again. Every year there's a theme for the event, and this year's was running a heist on a cruise ship. Every challenge was themed around it, the decorations were on point, the staff and volunteers were (largely) in costume, and all messaging fit the theme.I greatly appreciate the humour and levity that the team brings to these events as it's otherwise a very intense couple of days trying to solve their challenges!

I went in to this year's event with a goal of doing some of the non-code related challenges - electronics, RF, physical, and so on. I, of course, wound up staring at code for the better part of 48 hours :sweat_smile: 

One challenge this year stood out to me as a particularly fun one - it was the first time I had seen a machine learning focused challenge where the end goal was _not_ exploiting a product vulnerability for machine access but to actually poison a model! While there was a SQL injection vulnerability as the entry point, the real work was understanding how to craft data that would result in the model's training improperly labeling a specific piece of data. After some initial wrestling with the injection, the solution was very fun and it clearly demonstrated that a [somewhat trivial amount of bad data can drastically affect how a model works](https://arxiv.org/abs/2302.10149). Kudos for a great challenge.

Another theme that ran through some of the challenges was abusing [sandwich attacks](https://securingbits.com/uuid-sandwich-attacks) against UUIDv1 implementations. I came into these challenges without knowing about this technique, but after more reading about how UUIDs (v1 specifically) are generated I wound up coming to the same conclusion when identifying that some aspects of the generated response remained static. While my implementation of the solution was perhaps suboptimal (*cough* definitely suboptimal), it was very fun to learn about the technique _after_ discovering it for myself.

Of course, being 2025, my team also tried to leverage AI assistants for several of the challenges. To the designers credit, or perhaps to the detriment of all major AI models out there, these efforts proved to be largely useless beyond identifying otherwise trivial vulnerabilities like whitespaces breaking regex patterns. One area that they did stand out in was, with specific models, their ability to perform static analysis on basic binaries. I have nearly zero experience in this space, so the fact that I could prompt-engineer my way to flags by uploading a compiled binary was mindblowing to me. Obviously this didn't work for the more complex reverse engineering challenges, but it was still impressive.

I suspect you'll find many of this year's challenges up on [RingZer0](https://ringzer0ctf.com/) in the near future if you want to try them for yourself!

